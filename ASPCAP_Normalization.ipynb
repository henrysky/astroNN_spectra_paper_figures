{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile a training set using ASPCAP normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr is not provided, using default dr=14\n",
      "E:\\sdss_mirror\\dr14/apogee/spectro/redux/r8/stars/l31c/l31c.2/allStar-l31c.2.fits was found!\n",
      "Loading allStar DR14 catalog\n",
      "Total Combined Spectra after filtering:  33407\n",
      "Completed 1 of 33407, 0.14s elapsed\n",
      "Completed 101 of 33407, 0.75s elapsed\n",
      "Completed 201 of 33407, 1.40s elapsed\n",
      "Completed 301 of 33407, 2.10s elapsed\n",
      "Completed 401 of 33407, 2.82s elapsed\n",
      "Completed 501 of 33407, 3.57s elapsed\n",
      "Completed 601 of 33407, 4.31s elapsed\n",
      "Completed 701 of 33407, 5.05s elapsed\n",
      "Completed 801 of 33407, 5.82s elapsed\n",
      "Completed 901 of 33407, 6.55s elapsed\n",
      "Completed 1001 of 33407, 7.31s elapsed\n",
      "Completed 1101 of 33407, 8.04s elapsed\n",
      "Completed 1201 of 33407, 8.76s elapsed\n",
      "Completed 1301 of 33407, 9.43s elapsed\n",
      "Completed 1401 of 33407, 10.01s elapsed\n",
      "Completed 1501 of 33407, 10.78s elapsed\n",
      "Completed 1601 of 33407, 11.60s elapsed\n",
      "Completed 1701 of 33407, 12.41s elapsed\n",
      "Completed 1801 of 33407, 13.19s elapsed\n",
      "Completed 1901 of 33407, 13.99s elapsed\n",
      "Completed 2001 of 33407, 14.81s elapsed\n",
      "Completed 2101 of 33407, 15.66s elapsed\n",
      "Completed 2201 of 33407, 16.48s elapsed\n",
      "Completed 2301 of 33407, 17.28s elapsed\n",
      "Completed 2401 of 33407, 18.12s elapsed\n",
      "Completed 2501 of 33407, 18.96s elapsed\n",
      "Completed 2601 of 33407, 19.79s elapsed\n",
      "Completed 2701 of 33407, 20.62s elapsed\n",
      "Completed 2801 of 33407, 21.43s elapsed\n",
      "Completed 2901 of 33407, 22.26s elapsed\n",
      "Completed 3001 of 33407, 23.10s elapsed\n",
      "Completed 3101 of 33407, 23.96s elapsed\n",
      "Completed 3201 of 33407, 24.81s elapsed\n",
      "Completed 3301 of 33407, 25.66s elapsed\n",
      "Completed 3401 of 33407, 26.52s elapsed\n",
      "Completed 3501 of 33407, 27.33s elapsed\n",
      "Completed 3601 of 33407, 28.15s elapsed\n",
      "Completed 3701 of 33407, 28.98s elapsed\n",
      "Completed 3801 of 33407, 29.82s elapsed\n",
      "Completed 3901 of 33407, 30.69s elapsed\n",
      "Completed 4001 of 33407, 31.57s elapsed\n",
      "Completed 4101 of 33407, 32.41s elapsed\n",
      "Completed 4201 of 33407, 33.27s elapsed\n",
      "Completed 4301 of 33407, 34.10s elapsed\n",
      "Completed 4401 of 33407, 34.94s elapsed\n",
      "Completed 4501 of 33407, 35.77s elapsed\n",
      "Completed 4601 of 33407, 36.58s elapsed\n",
      "Completed 4701 of 33407, 37.40s elapsed\n",
      "Completed 4801 of 33407, 38.24s elapsed\n",
      "Completed 4901 of 33407, 39.05s elapsed\n",
      "Completed 5001 of 33407, 39.90s elapsed\n",
      "Completed 5101 of 33407, 40.72s elapsed\n",
      "Completed 5201 of 33407, 41.53s elapsed\n",
      "Completed 5301 of 33407, 42.33s elapsed\n",
      "Completed 5401 of 33407, 43.13s elapsed\n",
      "Completed 5501 of 33407, 43.96s elapsed\n",
      "Completed 5601 of 33407, 44.79s elapsed\n",
      "Completed 5701 of 33407, 45.63s elapsed\n",
      "Completed 5801 of 33407, 46.46s elapsed\n",
      "Completed 5901 of 33407, 47.30s elapsed\n",
      "Completed 6001 of 33407, 48.13s elapsed\n",
      "Completed 6101 of 33407, 48.98s elapsed\n",
      "Completed 6201 of 33407, 49.82s elapsed\n",
      "Completed 6301 of 33407, 50.65s elapsed\n",
      "Completed 6401 of 33407, 51.49s elapsed\n",
      "Completed 6501 of 33407, 52.33s elapsed\n",
      "Completed 6601 of 33407, 53.17s elapsed\n",
      "Completed 6701 of 33407, 54.01s elapsed\n",
      "Completed 6801 of 33407, 54.86s elapsed\n",
      "Completed 6901 of 33407, 55.70s elapsed\n",
      "Completed 7001 of 33407, 56.57s elapsed\n",
      "Completed 7101 of 33407, 57.41s elapsed\n",
      "Completed 7201 of 33407, 58.24s elapsed\n",
      "Completed 7301 of 33407, 59.07s elapsed\n",
      "Completed 7401 of 33407, 59.90s elapsed\n",
      "Completed 7501 of 33407, 60.74s elapsed\n",
      "Completed 7601 of 33407, 61.59s elapsed\n",
      "Completed 7701 of 33407, 62.43s elapsed\n",
      "Completed 7801 of 33407, 63.30s elapsed\n",
      "Completed 7901 of 33407, 64.16s elapsed\n",
      "Completed 8001 of 33407, 65.00s elapsed\n",
      "Completed 8101 of 33407, 65.83s elapsed\n",
      "Completed 8201 of 33407, 66.68s elapsed\n",
      "Completed 8301 of 33407, 67.52s elapsed\n",
      "Completed 8401 of 33407, 68.35s elapsed\n",
      "Completed 8501 of 33407, 69.21s elapsed\n",
      "Completed 8601 of 33407, 70.07s elapsed\n",
      "Completed 8701 of 33407, 70.93s elapsed\n",
      "Completed 8801 of 33407, 71.81s elapsed\n",
      "Completed 8901 of 33407, 72.70s elapsed\n",
      "Completed 9001 of 33407, 73.60s elapsed\n",
      "Completed 9101 of 33407, 74.52s elapsed\n",
      "Completed 9201 of 33407, 75.40s elapsed\n",
      "Completed 9301 of 33407, 76.38s elapsed\n",
      "Completed 9401 of 33407, 77.29s elapsed\n",
      "Completed 9501 of 33407, 78.13s elapsed\n",
      "Completed 9601 of 33407, 78.99s elapsed\n",
      "Completed 9701 of 33407, 79.87s elapsed\n",
      "Completed 9801 of 33407, 80.76s elapsed\n",
      "Completed 9901 of 33407, 81.66s elapsed\n",
      "Completed 10001 of 33407, 82.55s elapsed\n",
      "Completed 10101 of 33407, 83.40s elapsed\n",
      "Completed 10201 of 33407, 84.23s elapsed\n",
      "Completed 10301 of 33407, 85.08s elapsed\n",
      "Completed 10401 of 33407, 85.96s elapsed\n",
      "Completed 10501 of 33407, 86.83s elapsed\n",
      "Completed 10601 of 33407, 87.73s elapsed\n",
      "Completed 10701 of 33407, 88.64s elapsed\n",
      "Completed 10801 of 33407, 89.52s elapsed\n",
      "Completed 10901 of 33407, 90.41s elapsed\n",
      "Completed 11001 of 33407, 91.30s elapsed\n",
      "Completed 11101 of 33407, 92.20s elapsed\n",
      "Completed 11201 of 33407, 93.06s elapsed\n",
      "Completed 11301 of 33407, 94.01s elapsed\n",
      "Completed 11401 of 33407, 94.88s elapsed\n",
      "Completed 11501 of 33407, 95.76s elapsed\n",
      "Completed 11601 of 33407, 96.65s elapsed\n",
      "Completed 11701 of 33407, 97.51s elapsed\n",
      "Completed 11801 of 33407, 98.36s elapsed\n",
      "Completed 11901 of 33407, 99.22s elapsed\n",
      "Completed 12001 of 33407, 100.06s elapsed\n",
      "Completed 12101 of 33407, 100.94s elapsed\n",
      "Completed 12201 of 33407, 101.77s elapsed\n",
      "Completed 12301 of 33407, 102.60s elapsed\n",
      "Completed 12401 of 33407, 103.41s elapsed\n",
      "Completed 12501 of 33407, 104.24s elapsed\n",
      "Completed 12601 of 33407, 105.01s elapsed\n",
      "Completed 12701 of 33407, 105.80s elapsed\n",
      "Completed 12801 of 33407, 106.57s elapsed\n",
      "Completed 12901 of 33407, 107.38s elapsed\n",
      "Completed 13001 of 33407, 108.25s elapsed\n",
      "Completed 13101 of 33407, 109.38s elapsed\n",
      "Completed 13201 of 33407, 110.30s elapsed\n",
      "Completed 13301 of 33407, 111.15s elapsed\n",
      "Completed 13401 of 33407, 112.04s elapsed\n",
      "Completed 13501 of 33407, 113.04s elapsed\n",
      "Completed 13601 of 33407, 114.06s elapsed\n",
      "Completed 13701 of 33407, 115.30s elapsed\n",
      "Completed 13801 of 33407, 116.34s elapsed\n",
      "Completed 13901 of 33407, 117.17s elapsed\n",
      "Completed 14001 of 33407, 118.02s elapsed\n",
      "Completed 14101 of 33407, 118.87s elapsed\n",
      "Completed 14201 of 33407, 119.80s elapsed\n",
      "Completed 14301 of 33407, 120.60s elapsed\n",
      "Completed 14401 of 33407, 121.46s elapsed\n",
      "Completed 14501 of 33407, 122.31s elapsed\n",
      "Completed 14601 of 33407, 123.18s elapsed\n",
      "Completed 14701 of 33407, 124.03s elapsed\n",
      "Completed 14801 of 33407, 124.86s elapsed\n",
      "Completed 14901 of 33407, 125.65s elapsed\n",
      "Completed 15001 of 33407, 126.46s elapsed\n",
      "Completed 15101 of 33407, 127.25s elapsed\n",
      "Completed 15201 of 33407, 128.06s elapsed\n",
      "Completed 15301 of 33407, 128.84s elapsed\n",
      "Completed 15401 of 33407, 129.61s elapsed\n",
      "Completed 15501 of 33407, 130.42s elapsed\n",
      "Completed 15601 of 33407, 131.21s elapsed\n",
      "Completed 15701 of 33407, 132.04s elapsed\n",
      "Completed 15801 of 33407, 132.86s elapsed\n",
      "Completed 15901 of 33407, 133.63s elapsed\n",
      "Completed 16001 of 33407, 134.42s elapsed\n",
      "Completed 16101 of 33407, 135.25s elapsed\n",
      "Completed 16201 of 33407, 136.07s elapsed\n",
      "Completed 16301 of 33407, 136.86s elapsed\n",
      "Completed 16401 of 33407, 137.65s elapsed\n",
      "Completed 16501 of 33407, 138.49s elapsed\n",
      "Completed 16601 of 33407, 139.29s elapsed\n",
      "Completed 16701 of 33407, 140.19s elapsed\n",
      "Completed 16801 of 33407, 141.32s elapsed\n",
      "Completed 16901 of 33407, 142.28s elapsed\n",
      "Completed 17001 of 33407, 143.14s elapsed\n",
      "Completed 17101 of 33407, 143.93s elapsed\n",
      "Completed 17201 of 33407, 144.72s elapsed\n",
      "Completed 17301 of 33407, 145.53s elapsed\n",
      "Completed 17401 of 33407, 146.32s elapsed\n",
      "Completed 17501 of 33407, 147.11s elapsed\n",
      "Completed 17601 of 33407, 147.89s elapsed\n",
      "Completed 17701 of 33407, 148.68s elapsed\n",
      "Completed 17801 of 33407, 149.48s elapsed\n",
      "Completed 17901 of 33407, 150.31s elapsed\n",
      "Completed 18001 of 33407, 151.10s elapsed\n",
      "Completed 18101 of 33407, 151.89s elapsed\n",
      "Completed 18201 of 33407, 152.67s elapsed\n",
      "Completed 18301 of 33407, 153.45s elapsed\n",
      "Completed 18401 of 33407, 154.26s elapsed\n",
      "Completed 18501 of 33407, 155.04s elapsed\n",
      "Completed 18601 of 33407, 155.82s elapsed\n",
      "Completed 18701 of 33407, 156.61s elapsed\n",
      "Completed 18801 of 33407, 157.40s elapsed\n",
      "Completed 18901 of 33407, 158.19s elapsed\n",
      "Completed 19001 of 33407, 167.84s elapsed\n",
      "Completed 19101 of 33407, 171.47s elapsed\n",
      "Completed 19201 of 33407, 175.99s elapsed\n",
      "Completed 19301 of 33407, 181.41s elapsed\n",
      "Completed 19401 of 33407, 185.08s elapsed\n",
      "Completed 19501 of 33407, 190.10s elapsed\n",
      "Completed 19601 of 33407, 191.82s elapsed\n",
      "Completed 19701 of 33407, 196.30s elapsed\n",
      "Completed 19801 of 33407, 205.40s elapsed\n",
      "Completed 19901 of 33407, 208.91s elapsed\n",
      "Completed 20001 of 33407, 211.85s elapsed\n",
      "Completed 20101 of 33407, 215.57s elapsed\n",
      "Completed 20201 of 33407, 219.98s elapsed\n",
      "Completed 20301 of 33407, 223.49s elapsed\n",
      "Completed 20401 of 33407, 229.57s elapsed\n",
      "Completed 20501 of 33407, 230.43s elapsed\n",
      "Completed 20601 of 33407, 233.97s elapsed\n",
      "Completed 20701 of 33407, 238.39s elapsed\n",
      "Completed 20801 of 33407, 244.33s elapsed\n",
      "Completed 20901 of 33407, 246.36s elapsed\n",
      "Completed 21001 of 33407, 251.66s elapsed\n",
      "Completed 21101 of 33407, 254.22s elapsed\n",
      "Completed 21201 of 33407, 259.54s elapsed\n",
      "Completed 21301 of 33407, 266.29s elapsed\n",
      "Completed 21401 of 33407, 268.83s elapsed\n",
      "Completed 21501 of 33407, 272.33s elapsed\n",
      "Completed 21601 of 33407, 273.99s elapsed\n",
      "Completed 21701 of 33407, 280.19s elapsed\n",
      "Completed 21801 of 33407, 282.17s elapsed\n",
      "Completed 21901 of 33407, 284.94s elapsed\n",
      "Completed 22001 of 33407, 289.09s elapsed\n",
      "Completed 22101 of 33407, 292.89s elapsed\n",
      "Completed 22201 of 33407, 297.69s elapsed\n",
      "Completed 22301 of 33407, 303.95s elapsed\n",
      "Completed 22401 of 33407, 307.77s elapsed\n",
      "Completed 22501 of 33407, 312.20s elapsed\n",
      "Completed 22601 of 33407, 313.97s elapsed\n",
      "Completed 22701 of 33407, 318.28s elapsed\n",
      "Completed 22801 of 33407, 323.44s elapsed\n",
      "Completed 22901 of 33407, 328.16s elapsed\n",
      "Completed 23001 of 33407, 330.08s elapsed\n",
      "Completed 23101 of 33407, 331.87s elapsed\n",
      "Completed 23201 of 33407, 335.48s elapsed\n",
      "Completed 23301 of 33407, 338.16s elapsed\n",
      "Completed 23401 of 33407, 340.12s elapsed\n",
      "Completed 23501 of 33407, 342.86s elapsed\n",
      "Completed 23601 of 33407, 348.99s elapsed\n",
      "Completed 23701 of 33407, 350.94s elapsed\n",
      "Completed 23801 of 33407, 354.43s elapsed\n",
      "Completed 23901 of 33407, 358.91s elapsed\n",
      "Completed 24001 of 33407, 366.09s elapsed\n",
      "Completed 24101 of 33407, 367.84s elapsed\n",
      "Completed 24201 of 33407, 370.34s elapsed\n",
      "Completed 24301 of 33407, 372.88s elapsed\n",
      "Completed 24401 of 33407, 377.29s elapsed\n",
      "Completed 24501 of 33407, 382.28s elapsed\n",
      "Completed 24601 of 33407, 387.52s elapsed\n",
      "Completed 24701 of 33407, 396.16s elapsed\n",
      "Completed 24801 of 33407, 400.28s elapsed\n",
      "Completed 24901 of 33407, 409.90s elapsed\n",
      "Completed 25001 of 33407, 419.85s elapsed\n",
      "Completed 25101 of 33407, 426.70s elapsed\n",
      "Completed 25201 of 33407, 434.43s elapsed\n",
      "Completed 25301 of 33407, 440.29s elapsed\n",
      "Completed 25401 of 33407, 448.34s elapsed\n",
      "Completed 25501 of 33407, 451.51s elapsed\n",
      "Completed 25601 of 33407, 455.30s elapsed\n",
      "Completed 25701 of 33407, 457.88s elapsed\n",
      "Completed 25801 of 33407, 462.16s elapsed\n",
      "Completed 25901 of 33407, 465.59s elapsed\n",
      "Completed 26001 of 33407, 466.39s elapsed\n",
      "Completed 26101 of 33407, 468.14s elapsed\n",
      "Completed 26201 of 33407, 469.02s elapsed\n",
      "Completed 26301 of 33407, 470.78s elapsed\n",
      "Completed 26401 of 33407, 471.67s elapsed\n",
      "Completed 26501 of 33407, 474.64s elapsed\n",
      "Completed 26601 of 33407, 475.57s elapsed\n",
      "Completed 26701 of 33407, 479.09s elapsed\n",
      "Completed 26801 of 33407, 481.63s elapsed\n",
      "Completed 26901 of 33407, 483.27s elapsed\n",
      "Completed 27001 of 33407, 484.14s elapsed\n",
      "Completed 27101 of 33407, 487.71s elapsed\n",
      "Completed 27201 of 33407, 488.54s elapsed\n",
      "Completed 27301 of 33407, 490.27s elapsed\n",
      "Completed 27401 of 33407, 491.11s elapsed\n",
      "Completed 27501 of 33407, 492.79s elapsed\n",
      "Completed 27601 of 33407, 497.20s elapsed\n",
      "Completed 27701 of 33407, 498.09s elapsed\n",
      "Completed 27801 of 33407, 499.79s elapsed\n",
      "Completed 27901 of 33407, 500.66s elapsed\n",
      "Completed 28001 of 33407, 501.51s elapsed\n",
      "Completed 28101 of 33407, 503.44s elapsed\n",
      "Completed 28201 of 33407, 504.30s elapsed\n",
      "Completed 28301 of 33407, 505.15s elapsed\n",
      "Completed 28401 of 33407, 507.76s elapsed\n",
      "Completed 28501 of 33407, 509.54s elapsed\n",
      "Completed 28601 of 33407, 510.43s elapsed\n",
      "Completed 28701 of 33407, 512.17s elapsed\n",
      "Completed 28801 of 33407, 514.82s elapsed\n",
      "Completed 28901 of 33407, 516.81s elapsed\n",
      "Completed 29001 of 33407, 518.52s elapsed\n",
      "Completed 29101 of 33407, 519.37s elapsed\n",
      "Completed 29201 of 33407, 521.39s elapsed\n",
      "Completed 29301 of 33407, 522.28s elapsed\n",
      "Completed 29401 of 33407, 524.04s elapsed\n",
      "Completed 29501 of 33407, 524.94s elapsed\n",
      "Completed 29601 of 33407, 526.94s elapsed\n",
      "Completed 29701 of 33407, 528.87s elapsed\n",
      "Completed 29801 of 33407, 529.83s elapsed\n",
      "Completed 29901 of 33407, 531.71s elapsed\n",
      "Completed 30001 of 33407, 533.87s elapsed\n",
      "Completed 30101 of 33407, 535.58s elapsed\n",
      "Completed 30201 of 33407, 536.49s elapsed\n",
      "Completed 30301 of 33407, 537.39s elapsed\n",
      "Completed 30401 of 33407, 539.15s elapsed\n",
      "Completed 30501 of 33407, 540.87s elapsed\n",
      "Completed 30601 of 33407, 543.57s elapsed\n",
      "Completed 30701 of 33407, 547.08s elapsed\n",
      "Completed 30801 of 33407, 551.67s elapsed\n",
      "Completed 30901 of 33407, 554.11s elapsed\n",
      "Completed 31001 of 33407, 557.74s elapsed\n",
      "Completed 31101 of 33407, 561.22s elapsed\n",
      "Completed 31201 of 33407, 566.37s elapsed\n",
      "Completed 31301 of 33407, 567.25s elapsed\n",
      "Completed 31401 of 33407, 569.86s elapsed\n",
      "Completed 31501 of 33407, 573.67s elapsed\n",
      "Completed 31601 of 33407, 577.76s elapsed\n",
      "Completed 31701 of 33407, 582.85s elapsed\n",
      "Completed 31801 of 33407, 583.80s elapsed\n",
      "Completed 31901 of 33407, 585.65s elapsed\n",
      "Completed 32001 of 33407, 588.60s elapsed\n",
      "Completed 32101 of 33407, 594.27s elapsed\n",
      "Completed 32201 of 33407, 597.04s elapsed\n",
      "Completed 32301 of 33407, 597.88s elapsed\n",
      "Completed 32401 of 33407, 602.16s elapsed\n",
      "Completed 32501 of 33407, 604.03s elapsed\n",
      "Completed 32601 of 33407, 608.20s elapsed\n",
      "Completed 32701 of 33407, 612.17s elapsed\n",
      "Completed 32801 of 33407, 614.75s elapsed\n",
      "Completed 32901 of 33407, 617.11s elapsed\n",
      "Completed 33001 of 33407, 619.69s elapsed\n",
      "Completed 33101 of 33407, 622.30s elapsed\n",
      "Completed 33201 of 33407, 623.88s elapsed\n",
      "Completed 33301 of 33407, 624.73s elapsed\n",
      "Completed 33401 of 33407, 625.59s elapsed\n",
      "This is Gaia DR2 - APOGEE DR14 matched parallax, RA DEC in J2000, parallax in mas\n",
      "Please be advised that astroNN fakemag is parallax(mas) * 10 ** (0.2 * mag)\n",
      "Creating aspcap_norm_train.h5\n",
      "Successfully created aspcap_norm_train.h5 in D:\\University\\AST425\\astroNN_spectra_paper_figures\n"
     ]
    }
   ],
   "source": [
    "from utils_h5 import H5Compiler\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "\n",
    "# To create a astroNN compiler instance\n",
    "compiler_aspcap_train = H5Compiler()\n",
    "compiler_aspcap_train.teff_low = 4000  # Effective Temperature Upper\n",
    "compiler_aspcap_train.teff_high = 5500  # Effective Temperature Lower\n",
    "compiler_aspcap_train.vscattercut = 1  # Velocity Scattering Upper\n",
    "compiler_aspcap_train.starflagcut = True  # STARFLAG == 0\n",
    "compiler_aspcap_train.aspcapflagcut = True  # ASPCAPFALG == 0\n",
    "compiler_aspcap_train.ironlow = -10000.0  # [Fe/H] Lower\n",
    "compiler_aspcap_train.continuum = False  # use aspcap normalization\n",
    "compiler_aspcap_train.SNR_low = 200  # SNR Lower\n",
    "compiler_aspcap_train.SNR_high = 99999  # SNR Upper\n",
    "\n",
    "compiler_aspcap_train.filename = \"aspcap_norm_train\"\n",
    "\n",
    "# To compile a .h5 datasets, use .compile() method\n",
    "compiler_aspcap_train.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile a testing set using ASPCAP normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr is not provided, using default dr=14\n",
      "E:\\sdss_mirror\\dr14/apogee/spectro/redux/r8/stars/l31c/l31c.2/allStar-l31c.2.fits was found!\n",
      "Loading allStar DR14 catalog\n",
      "Total Combined Spectra after filtering:  28692\n",
      "Completed 1 of 28692, 0.16s elapsed\n",
      "Completed 101 of 28692, 0.97s elapsed\n",
      "Completed 201 of 28692, 1.83s elapsed\n",
      "Completed 301 of 28692, 2.70s elapsed\n",
      "Completed 401 of 28692, 3.61s elapsed\n",
      "Completed 501 of 28692, 4.52s elapsed\n",
      "Completed 601 of 28692, 5.41s elapsed\n",
      "Completed 701 of 28692, 6.33s elapsed\n",
      "Completed 801 of 28692, 7.25s elapsed\n",
      "Completed 901 of 28692, 8.13s elapsed\n",
      "Completed 1001 of 28692, 9.04s elapsed\n",
      "Completed 1101 of 28692, 9.94s elapsed\n",
      "Completed 1201 of 28692, 10.70s elapsed\n",
      "Completed 1301 of 28692, 11.47s elapsed\n",
      "Completed 1401 of 28692, 12.24s elapsed\n",
      "Completed 1501 of 28692, 12.98s elapsed\n",
      "Completed 1601 of 28692, 13.74s elapsed\n",
      "Completed 1701 of 28692, 14.51s elapsed\n",
      "Completed 1801 of 28692, 15.30s elapsed\n",
      "Completed 1901 of 28692, 16.11s elapsed\n",
      "Completed 2001 of 28692, 16.90s elapsed\n",
      "Completed 2101 of 28692, 17.69s elapsed\n",
      "Completed 2201 of 28692, 18.56s elapsed\n",
      "Completed 2301 of 28692, 19.43s elapsed\n",
      "Completed 2401 of 28692, 20.29s elapsed\n",
      "Completed 2501 of 28692, 21.12s elapsed\n",
      "Completed 2601 of 28692, 21.95s elapsed\n",
      "Completed 2701 of 28692, 22.77s elapsed\n",
      "Completed 2801 of 28692, 23.62s elapsed\n",
      "Completed 2901 of 28692, 24.48s elapsed\n",
      "Completed 3001 of 28692, 25.34s elapsed\n",
      "Completed 3101 of 28692, 26.22s elapsed\n",
      "Completed 3201 of 28692, 27.06s elapsed\n",
      "Completed 3301 of 28692, 27.90s elapsed\n",
      "Completed 3401 of 28692, 28.70s elapsed\n",
      "Completed 3501 of 28692, 29.58s elapsed\n",
      "Completed 3601 of 28692, 30.41s elapsed\n",
      "Completed 3701 of 28692, 31.26s elapsed\n",
      "Completed 3801 of 28692, 32.12s elapsed\n",
      "Completed 3901 of 28692, 32.97s elapsed\n",
      "Completed 4001 of 28692, 33.84s elapsed\n",
      "Completed 4101 of 28692, 34.72s elapsed\n",
      "Completed 4201 of 28692, 35.53s elapsed\n",
      "Completed 4301 of 28692, 36.37s elapsed\n",
      "Completed 4401 of 28692, 37.24s elapsed\n",
      "Completed 4501 of 28692, 38.12s elapsed\n",
      "Completed 4601 of 28692, 38.96s elapsed\n",
      "Completed 4701 of 28692, 39.82s elapsed\n",
      "Completed 4801 of 28692, 40.62s elapsed\n",
      "Completed 4901 of 28692, 41.46s elapsed\n",
      "Completed 5001 of 28692, 42.33s elapsed\n",
      "Completed 5101 of 28692, 43.21s elapsed\n",
      "Completed 5201 of 28692, 44.11s elapsed\n",
      "Completed 5301 of 28692, 44.96s elapsed\n",
      "Completed 5401 of 28692, 45.78s elapsed\n",
      "Completed 5501 of 28692, 46.61s elapsed\n",
      "Completed 5601 of 28692, 47.50s elapsed\n",
      "Completed 5701 of 28692, 48.36s elapsed\n",
      "Completed 5801 of 28692, 49.23s elapsed\n",
      "Completed 5901 of 28692, 50.10s elapsed\n",
      "Completed 6001 of 28692, 50.92s elapsed\n",
      "Completed 6101 of 28692, 53.75s elapsed\n",
      "Completed 6201 of 28692, 54.56s elapsed\n",
      "Completed 6301 of 28692, 55.38s elapsed\n",
      "Completed 6401 of 28692, 56.22s elapsed\n",
      "Completed 6501 of 28692, 57.10s elapsed\n",
      "Completed 6601 of 28692, 57.94s elapsed\n",
      "Completed 6701 of 28692, 58.75s elapsed\n",
      "Completed 6801 of 28692, 59.59s elapsed\n",
      "Completed 6901 of 28692, 60.44s elapsed\n",
      "Completed 7001 of 28692, 61.26s elapsed\n",
      "Completed 7101 of 28692, 62.12s elapsed\n",
      "Completed 7201 of 28692, 63.01s elapsed\n",
      "Completed 7301 of 28692, 63.86s elapsed\n",
      "Completed 7401 of 28692, 64.69s elapsed\n",
      "Completed 7501 of 28692, 65.51s elapsed\n",
      "Completed 7601 of 28692, 66.37s elapsed\n",
      "Completed 7701 of 28692, 67.20s elapsed\n",
      "Completed 7801 of 28692, 68.03s elapsed\n",
      "Completed 7901 of 28692, 68.86s elapsed\n",
      "Completed 8001 of 28692, 69.70s elapsed\n",
      "Completed 8101 of 28692, 70.55s elapsed\n",
      "Completed 8201 of 28692, 71.40s elapsed\n",
      "Completed 8301 of 28692, 72.23s elapsed\n",
      "Completed 8401 of 28692, 73.02s elapsed\n",
      "Completed 8501 of 28692, 73.85s elapsed\n",
      "Completed 8601 of 28692, 74.72s elapsed\n",
      "Completed 8701 of 28692, 75.56s elapsed\n",
      "Completed 8801 of 28692, 76.43s elapsed\n",
      "Completed 8901 of 28692, 77.32s elapsed\n",
      "Completed 9001 of 28692, 78.18s elapsed\n",
      "Completed 9101 of 28692, 79.04s elapsed\n",
      "Completed 9201 of 28692, 79.93s elapsed\n",
      "Completed 9301 of 28692, 80.79s elapsed\n",
      "Completed 9401 of 28692, 81.65s elapsed\n",
      "Completed 9501 of 28692, 82.52s elapsed\n",
      "Completed 9601 of 28692, 83.37s elapsed\n",
      "Completed 9701 of 28692, 84.20s elapsed\n",
      "Completed 9801 of 28692, 85.02s elapsed\n",
      "Completed 9901 of 28692, 85.82s elapsed\n",
      "Completed 10001 of 28692, 86.62s elapsed\n",
      "Completed 10101 of 28692, 87.43s elapsed\n",
      "Completed 10201 of 28692, 88.25s elapsed\n",
      "Completed 10301 of 28692, 89.07s elapsed\n",
      "Completed 10401 of 28692, 89.92s elapsed\n",
      "Completed 10501 of 28692, 90.74s elapsed\n",
      "Completed 10601 of 28692, 91.55s elapsed\n",
      "Completed 10701 of 28692, 92.37s elapsed\n",
      "Completed 10801 of 28692, 93.21s elapsed\n",
      "Completed 10901 of 28692, 94.05s elapsed\n",
      "Completed 11001 of 28692, 94.83s elapsed\n",
      "Completed 11101 of 28692, 95.63s elapsed\n",
      "Completed 11201 of 28692, 96.48s elapsed\n",
      "Completed 11301 of 28692, 97.27s elapsed\n",
      "Completed 11401 of 28692, 98.04s elapsed\n",
      "Completed 11501 of 28692, 98.82s elapsed\n",
      "Completed 11601 of 28692, 99.60s elapsed\n",
      "Completed 11701 of 28692, 100.40s elapsed\n",
      "Completed 11801 of 28692, 101.17s elapsed\n",
      "Completed 11901 of 28692, 101.91s elapsed\n",
      "Completed 12001 of 28692, 102.66s elapsed\n",
      "Completed 12101 of 28692, 103.41s elapsed\n",
      "Completed 12201 of 28692, 104.15s elapsed\n",
      "Completed 12301 of 28692, 104.94s elapsed\n",
      "Completed 12401 of 28692, 105.68s elapsed\n",
      "Completed 12501 of 28692, 106.41s elapsed\n",
      "Completed 12601 of 28692, 107.17s elapsed\n",
      "Completed 12701 of 28692, 107.92s elapsed\n",
      "Completed 12801 of 28692, 108.69s elapsed\n",
      "Completed 12901 of 28692, 109.47s elapsed\n",
      "Completed 13001 of 28692, 110.26s elapsed\n",
      "Completed 13101 of 28692, 111.07s elapsed\n",
      "Completed 13201 of 28692, 111.91s elapsed\n",
      "Completed 13301 of 28692, 112.74s elapsed\n",
      "Completed 13401 of 28692, 113.51s elapsed\n",
      "Completed 13501 of 28692, 114.26s elapsed\n",
      "Completed 13601 of 28692, 115.02s elapsed\n",
      "Completed 13701 of 28692, 117.52s elapsed\n",
      "Completed 13801 of 28692, 118.27s elapsed\n",
      "Completed 13901 of 28692, 119.04s elapsed\n",
      "Completed 14001 of 28692, 119.79s elapsed\n",
      "Completed 14101 of 28692, 121.41s elapsed\n",
      "Completed 14201 of 28692, 122.14s elapsed\n",
      "Completed 14301 of 28692, 122.91s elapsed\n",
      "Completed 14401 of 28692, 123.66s elapsed\n",
      "Completed 14501 of 28692, 124.41s elapsed\n",
      "Completed 14601 of 28692, 125.17s elapsed\n",
      "Completed 14701 of 28692, 125.91s elapsed\n",
      "Completed 14801 of 28692, 128.74s elapsed\n",
      "Completed 14901 of 28692, 129.48s elapsed\n",
      "Completed 15001 of 28692, 130.24s elapsed\n",
      "Completed 15101 of 28692, 131.03s elapsed\n",
      "Completed 15201 of 28692, 131.82s elapsed\n",
      "Completed 15301 of 28692, 133.50s elapsed\n",
      "Completed 15401 of 28692, 135.24s elapsed\n",
      "Completed 15501 of 28692, 135.97s elapsed\n",
      "Completed 15601 of 28692, 137.59s elapsed\n",
      "Completed 15701 of 28692, 138.36s elapsed\n",
      "Completed 15801 of 28692, 139.16s elapsed\n",
      "Completed 15901 of 28692, 140.80s elapsed\n",
      "Completed 16001 of 28692, 141.58s elapsed\n",
      "Completed 16101 of 28692, 142.35s elapsed\n",
      "Completed 16201 of 28692, 143.13s elapsed\n",
      "Completed 16301 of 28692, 143.88s elapsed\n",
      "Completed 16401 of 28692, 144.62s elapsed\n",
      "Completed 16501 of 28692, 146.47s elapsed\n",
      "Completed 16601 of 28692, 147.23s elapsed\n",
      "Completed 16701 of 28692, 148.01s elapsed\n",
      "Completed 16801 of 28692, 148.87s elapsed\n",
      "Completed 16901 of 28692, 149.68s elapsed\n",
      "Completed 17001 of 28692, 150.47s elapsed\n",
      "Completed 17101 of 28692, 151.25s elapsed\n",
      "Completed 17201 of 28692, 152.03s elapsed\n",
      "Completed 17301 of 28692, 152.84s elapsed\n",
      "Completed 17401 of 28692, 155.58s elapsed\n",
      "Completed 17501 of 28692, 156.46s elapsed\n",
      "Completed 17601 of 28692, 157.38s elapsed\n",
      "Completed 17701 of 28692, 158.24s elapsed\n",
      "Completed 17801 of 28692, 159.17s elapsed\n",
      "Completed 17901 of 28692, 160.03s elapsed\n",
      "Completed 18001 of 28692, 160.87s elapsed\n",
      "Completed 18101 of 28692, 161.73s elapsed\n",
      "Completed 18201 of 28692, 162.74s elapsed\n",
      "Completed 18301 of 28692, 163.64s elapsed\n",
      "Completed 18401 of 28692, 164.57s elapsed\n",
      "Completed 18501 of 28692, 165.42s elapsed\n",
      "Completed 18601 of 28692, 166.24s elapsed\n",
      "Completed 18701 of 28692, 167.02s elapsed\n",
      "Completed 18801 of 28692, 167.78s elapsed\n",
      "Completed 18901 of 28692, 168.55s elapsed\n",
      "Completed 19001 of 28692, 169.39s elapsed\n",
      "Completed 19101 of 28692, 170.21s elapsed\n",
      "Completed 19201 of 28692, 171.03s elapsed\n",
      "Completed 19301 of 28692, 171.88s elapsed\n",
      "Completed 19401 of 28692, 172.66s elapsed\n",
      "Completed 19501 of 28692, 173.47s elapsed\n",
      "Completed 19601 of 28692, 174.33s elapsed\n",
      "Completed 19701 of 28692, 176.04s elapsed\n",
      "Completed 19801 of 28692, 176.89s elapsed\n",
      "Completed 19901 of 28692, 177.70s elapsed\n",
      "Completed 20001 of 28692, 179.44s elapsed\n",
      "Completed 20101 of 28692, 180.27s elapsed\n",
      "Completed 20201 of 28692, 181.15s elapsed\n",
      "Completed 20301 of 28692, 182.00s elapsed\n",
      "Completed 20401 of 28692, 183.72s elapsed\n",
      "Completed 20501 of 28692, 184.58s elapsed\n",
      "Completed 20601 of 28692, 185.41s elapsed\n",
      "Completed 20701 of 28692, 186.27s elapsed\n",
      "Completed 20801 of 28692, 187.11s elapsed\n",
      "Completed 20901 of 28692, 187.99s elapsed\n",
      "Completed 21001 of 28692, 188.81s elapsed\n",
      "Completed 21101 of 28692, 189.68s elapsed\n",
      "Completed 21201 of 28692, 190.57s elapsed\n",
      "Completed 21301 of 28692, 191.41s elapsed\n",
      "Completed 21401 of 28692, 192.27s elapsed\n",
      "Completed 21501 of 28692, 193.13s elapsed\n",
      "Completed 21601 of 28692, 193.96s elapsed\n",
      "Completed 21701 of 28692, 194.76s elapsed\n",
      "Completed 21801 of 28692, 195.61s elapsed\n",
      "Completed 21901 of 28692, 196.47s elapsed\n",
      "Completed 22001 of 28692, 197.34s elapsed\n",
      "Completed 22101 of 28692, 198.17s elapsed\n",
      "Completed 22201 of 28692, 199.09s elapsed\n",
      "Completed 22301 of 28692, 199.92s elapsed\n",
      "Completed 22401 of 28692, 200.75s elapsed\n",
      "Completed 22501 of 28692, 201.63s elapsed\n",
      "Completed 22601 of 28692, 202.44s elapsed\n",
      "Completed 22701 of 28692, 203.29s elapsed\n",
      "Completed 22801 of 28692, 204.13s elapsed\n",
      "Completed 22901 of 28692, 204.97s elapsed\n",
      "Completed 23001 of 28692, 205.86s elapsed\n",
      "Completed 23101 of 28692, 206.72s elapsed\n",
      "Completed 23201 of 28692, 207.55s elapsed\n",
      "Completed 23301 of 28692, 208.36s elapsed\n",
      "Completed 23401 of 28692, 209.22s elapsed\n",
      "Completed 23501 of 28692, 210.11s elapsed\n",
      "Completed 23601 of 28692, 210.96s elapsed\n",
      "Completed 23701 of 28692, 211.83s elapsed\n",
      "Completed 23801 of 28692, 212.69s elapsed\n",
      "Completed 23901 of 28692, 213.54s elapsed\n",
      "Completed 24001 of 28692, 214.38s elapsed\n",
      "Completed 24101 of 28692, 215.24s elapsed\n",
      "Completed 24201 of 28692, 216.08s elapsed\n",
      "Completed 24301 of 28692, 216.93s elapsed\n",
      "Completed 24401 of 28692, 217.80s elapsed\n",
      "Completed 24501 of 28692, 218.68s elapsed\n",
      "Completed 24601 of 28692, 219.60s elapsed\n",
      "Completed 24701 of 28692, 220.48s elapsed\n",
      "Completed 24801 of 28692, 221.40s elapsed\n",
      "Completed 24901 of 28692, 222.30s elapsed\n",
      "Completed 25001 of 28692, 223.20s elapsed\n",
      "Completed 25101 of 28692, 224.16s elapsed\n",
      "Completed 25201 of 28692, 225.12s elapsed\n",
      "Completed 25301 of 28692, 226.05s elapsed\n",
      "Completed 25401 of 28692, 226.95s elapsed\n",
      "Completed 25501 of 28692, 227.85s elapsed\n",
      "Completed 25601 of 28692, 228.75s elapsed\n",
      "Completed 25701 of 28692, 229.61s elapsed\n",
      "Completed 25801 of 28692, 230.58s elapsed\n",
      "Completed 25901 of 28692, 231.43s elapsed\n",
      "Completed 26001 of 28692, 232.35s elapsed\n",
      "Completed 26101 of 28692, 233.15s elapsed\n",
      "Completed 26201 of 28692, 233.96s elapsed\n",
      "Completed 26301 of 28692, 234.77s elapsed\n",
      "Completed 26401 of 28692, 235.55s elapsed\n",
      "Completed 26501 of 28692, 236.37s elapsed\n",
      "Completed 26601 of 28692, 237.16s elapsed\n",
      "Completed 26701 of 28692, 237.99s elapsed\n",
      "Completed 26801 of 28692, 238.89s elapsed\n",
      "Completed 26901 of 28692, 239.76s elapsed\n",
      "Completed 27001 of 28692, 240.65s elapsed\n",
      "Completed 27101 of 28692, 241.55s elapsed\n",
      "Completed 27201 of 28692, 242.43s elapsed\n",
      "Completed 27301 of 28692, 243.27s elapsed\n",
      "Completed 27401 of 28692, 244.15s elapsed\n",
      "Completed 27501 of 28692, 245.04s elapsed\n",
      "Completed 27601 of 28692, 245.91s elapsed\n",
      "Completed 27701 of 28692, 246.77s elapsed\n",
      "Completed 27801 of 28692, 247.60s elapsed\n",
      "Completed 27901 of 28692, 248.42s elapsed\n",
      "Completed 28001 of 28692, 249.24s elapsed\n",
      "Completed 28101 of 28692, 250.09s elapsed\n",
      "Completed 28201 of 28692, 250.92s elapsed\n",
      "Completed 28301 of 28692, 251.71s elapsed\n",
      "Completed 28401 of 28692, 252.48s elapsed\n",
      "Completed 28501 of 28692, 253.37s elapsed\n",
      "Completed 28601 of 28692, 254.18s elapsed\n",
      "This is Gaia DR2 - APOGEE DR14 matched parallax, RA DEC in J2000, parallax in mas\n",
      "Please be advised that astroNN fakemag is parallax(mas) * 10 ** (0.2 * mag)\n",
      "Creating aspcap_norm_test.h5\n",
      "Successfully created aspcap_norm_test.h5 in D:\\University\\AST425\\astroNN_spectra_paper_figures\n"
     ]
    }
   ],
   "source": [
    "from utils_h5 import H5Compiler\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "\n",
    "# To create a astroNN compiler instance\n",
    "compiler_aspcap_test = H5Compiler()\n",
    "compiler_aspcap_test.teff_low = 4000  # Effective Temperature Upper\n",
    "compiler_aspcap_test.teff_high = 5500  # Effective Temperature Lower\n",
    "compiler_aspcap_test.vscattercut = 1  # Velocity Scattering Upper\n",
    "compiler_aspcap_test.starflagcut = True  # STARFLAG == 0\n",
    "compiler_aspcap_test.aspcapflagcut = True  # ASPCAPFALG == 0\n",
    "compiler_aspcap_test.ironlow = -10000.0  # [Fe/H] Lower\n",
    "compiler_aspcap_test.continuum = False  # use aspcap normalization\n",
    "compiler_aspcap_test.SNR_low = 100  # SNR Lower\n",
    "compiler_aspcap_test.SNR_high = 200  # SNR Upper\n",
    "\n",
    "compiler_aspcap_test.filename = \"aspcap_norm_test\"\n",
    "\n",
    "# To compile a .h5 datasets, use .compile() method\n",
    "compiler_aspcap_test.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a NN with ASPCAP normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 30067, Number of Validation Data: 3340\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 23s - loss: -1.9272e-01 - output_loss: -1.9277e-01 - variance_output_loss: -1.9277e-01 - output_mean_absolute_error: 0.4063 - output_mean_error: -6.2537e-02 - val_loss: -6.1062e-01 - val_output_loss: -6.1066e-01 - val_variance_output_loss: -6.1066e-01 - val_output_mean_absolute_error: 0.2627 - val_output_mean_error: -2.5713e-02\n",
      "Epoch 2/60\n",
      " - 18s - loss: -7.3945e-01 - output_loss: -7.3950e-01 - variance_output_loss: -7.3950e-01 - output_mean_absolute_error: 0.2312 - output_mean_error: -3.2024e-02 - val_loss: -8.3607e-01 - val_output_loss: -8.3612e-01 - val_variance_output_loss: -8.3612e-01 - val_output_mean_absolute_error: 0.2057 - val_output_mean_error: -2.1599e-02\n",
      "Epoch 3/60\n",
      " - 18s - loss: -8.9833e-01 - output_loss: -8.9838e-01 - variance_output_loss: -8.9838e-01 - output_mean_absolute_error: 0.1964 - output_mean_error: -1.9382e-02 - val_loss: -9.4541e-01 - val_output_loss: -9.4547e-01 - val_variance_output_loss: -9.4547e-01 - val_output_mean_absolute_error: 0.1841 - val_output_mean_error: -9.0486e-03\n",
      "Epoch 4/60\n",
      " - 18s - loss: -9.8940e-01 - output_loss: -9.8945e-01 - variance_output_loss: -9.8945e-01 - output_mean_absolute_error: 0.1805 - output_mean_error: -1.3799e-02 - val_loss: -9.9602e-01 - val_output_loss: -9.9608e-01 - val_variance_output_loss: -9.9608e-01 - val_output_mean_absolute_error: 0.1775 - val_output_mean_error: -4.6581e-02\n",
      "Epoch 5/60\n",
      " - 18s - loss: -1.0403e+00 - output_loss: -1.0404e+00 - variance_output_loss: -1.0404e+00 - output_mean_absolute_error: 0.1738 - output_mean_error: -1.2515e-02 - val_loss: -1.0671e+00 - val_output_loss: -1.0671e+00 - val_variance_output_loss: -1.0671e+00 - val_output_mean_absolute_error: 0.1667 - val_output_mean_error: -1.4224e-02\n",
      "Epoch 6/60\n",
      " - 18s - loss: -1.0874e+00 - output_loss: -1.0874e+00 - variance_output_loss: -1.0874e+00 - output_mean_absolute_error: 0.1670 - output_mean_error: -1.0821e-02 - val_loss: -1.0995e+00 - val_output_loss: -1.0995e+00 - val_variance_output_loss: -1.0995e+00 - val_output_mean_absolute_error: 0.1638 - val_output_mean_error: -2.7132e-02\n",
      "Epoch 7/60\n",
      " - 18s - loss: -1.1308e+00 - output_loss: -1.1309e+00 - variance_output_loss: -1.1309e+00 - output_mean_absolute_error: 0.1621 - output_mean_error: -9.8916e-03 - val_loss: -1.1092e+00 - val_output_loss: -1.1092e+00 - val_variance_output_loss: -1.1092e+00 - val_output_mean_absolute_error: 0.1631 - val_output_mean_error: -2.3538e-02\n",
      "Epoch 8/60\n",
      " - 18s - loss: -1.1592e+00 - output_loss: -1.1592e+00 - variance_output_loss: -1.1592e+00 - output_mean_absolute_error: 0.1590 - output_mean_error: -9.6124e-03 - val_loss: -1.1545e+00 - val_output_loss: -1.1545e+00 - val_variance_output_loss: -1.1545e+00 - val_output_mean_absolute_error: 0.1563 - val_output_mean_error: 6.9226e-04\n",
      "Epoch 9/60\n",
      " - 18s - loss: -1.1872e+00 - output_loss: -1.1872e+00 - variance_output_loss: -1.1872e+00 - output_mean_absolute_error: 0.1558 - output_mean_error: -9.2598e-03 - val_loss: -1.1638e+00 - val_output_loss: -1.1639e+00 - val_variance_output_loss: -1.1639e+00 - val_output_mean_absolute_error: 0.1560 - val_output_mean_error: 0.0192\n",
      "Epoch 10/60\n",
      " - 18s - loss: -1.2156e+00 - output_loss: -1.2156e+00 - variance_output_loss: -1.2156e+00 - output_mean_absolute_error: 0.1532 - output_mean_error: -8.9942e-03 - val_loss: -1.1834e+00 - val_output_loss: -1.1835e+00 - val_variance_output_loss: -1.1835e+00 - val_output_mean_absolute_error: 0.1545 - val_output_mean_error: 0.0035\n",
      "Epoch 11/60\n",
      " - 18s - loss: -1.2293e+00 - output_loss: -1.2294e+00 - variance_output_loss: -1.2294e+00 - output_mean_absolute_error: 0.1514 - output_mean_error: -8.2671e-03 - val_loss: -1.2194e+00 - val_output_loss: -1.2195e+00 - val_variance_output_loss: -1.2195e+00 - val_output_mean_absolute_error: 0.1487 - val_output_mean_error: -2.5703e-02\n",
      "Epoch 12/60\n",
      " - 18s - loss: -1.2450e+00 - output_loss: -1.2451e+00 - variance_output_loss: -1.2451e+00 - output_mean_absolute_error: 0.1503 - output_mean_error: -8.9164e-03 - val_loss: -1.2113e+00 - val_output_loss: -1.2113e+00 - val_variance_output_loss: -1.2113e+00 - val_output_mean_absolute_error: 0.1502 - val_output_mean_error: -1.2680e-03\n",
      "Epoch 13/60\n",
      " - 18s - loss: -1.2707e+00 - output_loss: -1.2708e+00 - variance_output_loss: -1.2708e+00 - output_mean_absolute_error: 0.1472 - output_mean_error: -8.2239e-03 - val_loss: -1.2455e+00 - val_output_loss: -1.2456e+00 - val_variance_output_loss: -1.2456e+00 - val_output_mean_absolute_error: 0.1477 - val_output_mean_error: -7.8407e-03\n",
      "Epoch 14/60\n",
      " - 18s - loss: -1.2779e+00 - output_loss: -1.2780e+00 - variance_output_loss: -1.2780e+00 - output_mean_absolute_error: 0.1457 - output_mean_error: -8.0131e-03 - val_loss: -1.2200e+00 - val_output_loss: -1.2201e+00 - val_variance_output_loss: -1.2201e+00 - val_output_mean_absolute_error: 0.1502 - val_output_mean_error: 0.0197\n",
      "Epoch 15/60\n",
      " - 18s - loss: -1.2977e+00 - output_loss: -1.2978e+00 - variance_output_loss: -1.2978e+00 - output_mean_absolute_error: 0.1440 - output_mean_error: -7.5613e-03 - val_loss: -1.2620e+00 - val_output_loss: -1.2621e+00 - val_variance_output_loss: -1.2621e+00 - val_output_mean_absolute_error: 0.1455 - val_output_mean_error: -9.4002e-03\n",
      "Epoch 16/60\n",
      " - 18s - loss: -1.3074e+00 - output_loss: -1.3075e+00 - variance_output_loss: -1.3075e+00 - output_mean_absolute_error: 0.1432 - output_mean_error: -8.4005e-03 - val_loss: -1.2545e+00 - val_output_loss: -1.2546e+00 - val_variance_output_loss: -1.2546e+00 - val_output_mean_absolute_error: 0.1465 - val_output_mean_error: -1.0430e-02\n",
      "Epoch 17/60\n",
      " - 18s - loss: -1.3200e+00 - output_loss: -1.3201e+00 - variance_output_loss: -1.3201e+00 - output_mean_absolute_error: 0.1419 - output_mean_error: -8.0042e-03 - val_loss: -1.2912e+00 - val_output_loss: -1.2913e+00 - val_variance_output_loss: -1.2913e+00 - val_output_mean_absolute_error: 0.1414 - val_output_mean_error: 0.0030\n",
      "Epoch 18/60\n",
      " - 18s - loss: -1.3263e+00 - output_loss: -1.3264e+00 - variance_output_loss: -1.3264e+00 - output_mean_absolute_error: 0.1413 - output_mean_error: -7.7585e-03 - val_loss: -1.2812e+00 - val_output_loss: -1.2813e+00 - val_variance_output_loss: -1.2813e+00 - val_output_mean_absolute_error: 0.1428 - val_output_mean_error: -2.9985e-02\n",
      "Epoch 19/60\n",
      " - 18s - loss: -1.3360e+00 - output_loss: -1.3361e+00 - variance_output_loss: -1.3361e+00 - output_mean_absolute_error: 0.1403 - output_mean_error: -7.9812e-03 - val_loss: -1.2741e+00 - val_output_loss: -1.2741e+00 - val_variance_output_loss: -1.2741e+00 - val_output_mean_absolute_error: 0.1439 - val_output_mean_error: 0.0053\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 20/60\n",
      " - 18s - loss: -1.3584e+00 - output_loss: -1.3585e+00 - variance_output_loss: -1.3585e+00 - output_mean_absolute_error: 0.1378 - output_mean_error: -7.5263e-03 - val_loss: -1.2880e+00 - val_output_loss: -1.2881e+00 - val_variance_output_loss: -1.2881e+00 - val_output_mean_absolute_error: 0.1422 - val_output_mean_error: -9.2744e-03\n",
      "Epoch 21/60\n",
      " - 18s - loss: -1.3697e+00 - output_loss: -1.3697e+00 - variance_output_loss: -1.3697e+00 - output_mean_absolute_error: 0.1369 - output_mean_error: -7.8827e-03 - val_loss: -1.3135e+00 - val_output_loss: -1.3136e+00 - val_variance_output_loss: -1.3136e+00 - val_output_mean_absolute_error: 0.1390 - val_output_mean_error: -6.5708e-03\n",
      "Epoch 22/60\n",
      " - 18s - loss: -1.3702e+00 - output_loss: -1.3703e+00 - variance_output_loss: -1.3703e+00 - output_mean_absolute_error: 0.1366 - output_mean_error: -7.1540e-03 - val_loss: -1.3196e+00 - val_output_loss: -1.3197e+00 - val_variance_output_loss: -1.3197e+00 - val_output_mean_absolute_error: 0.1388 - val_output_mean_error: -7.4629e-03\n",
      "Epoch 23/60\n",
      " - 18s - loss: -1.3751e+00 - output_loss: -1.3752e+00 - variance_output_loss: -1.3752e+00 - output_mean_absolute_error: 0.1362 - output_mean_error: -7.7452e-03 - val_loss: -1.3101e+00 - val_output_loss: -1.3102e+00 - val_variance_output_loss: -1.3102e+00 - val_output_mean_absolute_error: 0.1394 - val_output_mean_error: -9.1081e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      " - 18s - loss: -1.3827e+00 - output_loss: -1.3828e+00 - variance_output_loss: -1.3828e+00 - output_mean_absolute_error: 0.1354 - output_mean_error: -7.4095e-03 - val_loss: -1.3133e+00 - val_output_loss: -1.3134e+00 - val_variance_output_loss: -1.3134e+00 - val_output_mean_absolute_error: 0.1399 - val_output_mean_error: -8.0326e-03\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 25/60\n",
      " - 18s - loss: -1.3857e+00 - output_loss: -1.3858e+00 - variance_output_loss: -1.3858e+00 - output_mean_absolute_error: 0.1349 - output_mean_error: -7.6961e-03 - val_loss: -1.3262e+00 - val_output_loss: -1.3263e+00 - val_variance_output_loss: -1.3263e+00 - val_output_mean_absolute_error: 0.1364 - val_output_mean_error: -1.1555e-02\n",
      "Epoch 26/60\n",
      " - 18s - loss: -1.3951e+00 - output_loss: -1.3952e+00 - variance_output_loss: -1.3952e+00 - output_mean_absolute_error: 0.1341 - output_mean_error: -7.6912e-03 - val_loss: -1.3409e+00 - val_output_loss: -1.3410e+00 - val_variance_output_loss: -1.3410e+00 - val_output_mean_absolute_error: 0.1367 - val_output_mean_error: -1.1523e-02\n",
      "Epoch 27/60\n",
      " - 18s - loss: -1.3945e+00 - output_loss: -1.3946e+00 - variance_output_loss: -1.3946e+00 - output_mean_absolute_error: 0.1342 - output_mean_error: -7.6543e-03 - val_loss: -1.3328e+00 - val_output_loss: -1.3329e+00 - val_variance_output_loss: -1.3329e+00 - val_output_mean_absolute_error: 0.1367 - val_output_mean_error: -9.1507e-03\n",
      "Epoch 28/60\n",
      " - 18s - loss: -1.3960e+00 - output_loss: -1.3961e+00 - variance_output_loss: -1.3961e+00 - output_mean_absolute_error: 0.1338 - output_mean_error: -7.6309e-03 - val_loss: -1.3167e+00 - val_output_loss: -1.3168e+00 - val_variance_output_loss: -1.3168e+00 - val_output_mean_absolute_error: 0.1377 - val_output_mean_error: -1.7947e-02\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 29/60\n",
      " - 18s - loss: -1.4003e+00 - output_loss: -1.4003e+00 - variance_output_loss: -1.4003e+00 - output_mean_absolute_error: 0.1339 - output_mean_error: -7.7959e-03 - val_loss: -1.3370e+00 - val_output_loss: -1.3371e+00 - val_variance_output_loss: -1.3371e+00 - val_output_mean_absolute_error: 0.1359 - val_output_mean_error: -4.6744e-03\n",
      "Epoch 30/60\n",
      " - 18s - loss: -1.4083e+00 - output_loss: -1.4084e+00 - variance_output_loss: -1.4084e+00 - output_mean_absolute_error: 0.1327 - output_mean_error: -7.1960e-03 - val_loss: -1.3288e+00 - val_output_loss: -1.3289e+00 - val_variance_output_loss: -1.3289e+00 - val_output_mean_absolute_error: 0.1384 - val_output_mean_error: -6.4018e-03\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 31/60\n",
      " - 18s - loss: -1.4077e+00 - output_loss: -1.4077e+00 - variance_output_loss: -1.4077e+00 - output_mean_absolute_error: 0.1326 - output_mean_error: -7.7092e-03 - val_loss: -1.3414e+00 - val_output_loss: -1.3415e+00 - val_variance_output_loss: -1.3415e+00 - val_output_mean_absolute_error: 0.1351 - val_output_mean_error: -6.9641e-03\n",
      "Epoch 32/60\n",
      " - 18s - loss: -1.4074e+00 - output_loss: -1.4075e+00 - variance_output_loss: -1.4075e+00 - output_mean_absolute_error: 0.1326 - output_mean_error: -7.7549e-03 - val_loss: -1.3349e+00 - val_output_loss: -1.3350e+00 - val_variance_output_loss: -1.3350e+00 - val_output_mean_absolute_error: 0.1373 - val_output_mean_error: -1.3275e-02\n",
      "Epoch 33/60\n",
      " - 18s - loss: -1.4080e+00 - output_loss: -1.4081e+00 - variance_output_loss: -1.4081e+00 - output_mean_absolute_error: 0.1326 - output_mean_error: -7.8849e-03 - val_loss: -1.3262e+00 - val_output_loss: -1.3263e+00 - val_variance_output_loss: -1.3263e+00 - val_output_mean_absolute_error: 0.1373 - val_output_mean_error: -4.3412e-03\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 34/60\n",
      " - 18s - loss: -1.4137e+00 - output_loss: -1.4137e+00 - variance_output_loss: -1.4137e+00 - output_mean_absolute_error: 0.1321 - output_mean_error: -7.2493e-03 - val_loss: -1.3582e+00 - val_output_loss: -1.3583e+00 - val_variance_output_loss: -1.3583e+00 - val_output_mean_absolute_error: 0.1342 - val_output_mean_error: -1.1209e-02\n",
      "Epoch 35/60\n",
      " - 18s - loss: -1.4096e+00 - output_loss: -1.4097e+00 - variance_output_loss: -1.4097e+00 - output_mean_absolute_error: 0.1321 - output_mean_error: -7.2728e-03 - val_loss: -1.3420e+00 - val_output_loss: -1.3421e+00 - val_variance_output_loss: -1.3421e+00 - val_output_mean_absolute_error: 0.1357 - val_output_mean_error: -9.6951e-03\n",
      "Epoch 36/60\n",
      " - 18s - loss: -1.4113e+00 - output_loss: -1.4114e+00 - variance_output_loss: -1.4114e+00 - output_mean_absolute_error: 0.1328 - output_mean_error: -7.9284e-03 - val_loss: -1.3418e+00 - val_output_loss: -1.3419e+00 - val_variance_output_loss: -1.3419e+00 - val_output_mean_absolute_error: 0.1368 - val_output_mean_error: -1.1767e-02\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 37/60\n",
      " - 18s - loss: -1.4132e+00 - output_loss: -1.4133e+00 - variance_output_loss: -1.4133e+00 - output_mean_absolute_error: 0.1323 - output_mean_error: -7.3362e-03 - val_loss: -1.3449e+00 - val_output_loss: -1.3450e+00 - val_variance_output_loss: -1.3450e+00 - val_output_mean_absolute_error: 0.1345 - val_output_mean_error: -1.0104e-02\n",
      "Epoch 38/60\n",
      " - 18s - loss: -1.4132e+00 - output_loss: -1.4133e+00 - variance_output_loss: -1.4133e+00 - output_mean_absolute_error: 0.1324 - output_mean_error: -7.9215e-03 - val_loss: -1.3458e+00 - val_output_loss: -1.3458e+00 - val_variance_output_loss: -1.3458e+00 - val_output_mean_absolute_error: 0.1361 - val_output_mean_error: -7.3246e-03\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 39/60\n",
      " - 18s - loss: -1.4118e+00 - output_loss: -1.4119e+00 - variance_output_loss: -1.4119e+00 - output_mean_absolute_error: 0.1325 - output_mean_error: -7.3841e-03 - val_loss: -1.3459e+00 - val_output_loss: -1.3460e+00 - val_variance_output_loss: -1.3460e+00 - val_output_mean_absolute_error: 0.1347 - val_output_mean_error: -8.9413e-03\n",
      "Epoch 40/60\n",
      " - 18s - loss: -1.4102e+00 - output_loss: -1.4103e+00 - variance_output_loss: -1.4103e+00 - output_mean_absolute_error: 0.1328 - output_mean_error: -7.9154e-03 - val_loss: -1.3246e+00 - val_output_loss: -1.3247e+00 - val_variance_output_loss: -1.3247e+00 - val_output_mean_absolute_error: 0.1387 - val_output_mean_error: -1.1233e-02\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 41/60\n",
      " - 18s - loss: -1.4135e+00 - output_loss: -1.4136e+00 - variance_output_loss: -1.4136e+00 - output_mean_absolute_error: 0.1324 - output_mean_error: -7.6039e-03 - val_loss: -1.3421e+00 - val_output_loss: -1.3422e+00 - val_variance_output_loss: -1.3422e+00 - val_output_mean_absolute_error: 0.1356 - val_output_mean_error: -1.0542e-02\n",
      "Epoch 42/60\n",
      " - 18s - loss: -1.4173e+00 - output_loss: -1.4174e+00 - variance_output_loss: -1.4174e+00 - output_mean_absolute_error: 0.1315 - output_mean_error: -7.5700e-03 - val_loss: -1.3345e+00 - val_output_loss: -1.3346e+00 - val_variance_output_loss: -1.3346e+00 - val_output_mean_absolute_error: 0.1365 - val_output_mean_error: -1.1158e-02\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 43/60\n",
      " - 18s - loss: -1.4110e+00 - output_loss: -1.4111e+00 - variance_output_loss: -1.4111e+00 - output_mean_absolute_error: 0.1325 - output_mean_error: -7.8155e-03 - val_loss: -1.3462e+00 - val_output_loss: -1.3463e+00 - val_variance_output_loss: -1.3463e+00 - val_output_mean_absolute_error: 0.1354 - val_output_mean_error: -1.0303e-02\n",
      "Epoch 44/60\n",
      " - 18s - loss: -1.4081e+00 - output_loss: -1.4081e+00 - variance_output_loss: -1.4081e+00 - output_mean_absolute_error: 0.1328 - output_mean_error: -7.4642e-03 - val_loss: -1.3475e+00 - val_output_loss: -1.3475e+00 - val_variance_output_loss: -1.3475e+00 - val_output_mean_absolute_error: 0.1347 - val_output_mean_error: -9.1648e-03\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 45/60\n",
      " - 18s - loss: -1.4149e+00 - output_loss: -1.4150e+00 - variance_output_loss: -1.4150e+00 - output_mean_absolute_error: 0.1318 - output_mean_error: -7.2628e-03 - val_loss: -1.3461e+00 - val_output_loss: -1.3462e+00 - val_variance_output_loss: -1.3462e+00 - val_output_mean_absolute_error: 0.1367 - val_output_mean_error: -1.1903e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/60\n",
      " - 18s - loss: -1.4117e+00 - output_loss: -1.4117e+00 - variance_output_loss: -1.4117e+00 - output_mean_absolute_error: 0.1323 - output_mean_error: -7.8522e-03 - val_loss: -1.3368e+00 - val_output_loss: -1.3368e+00 - val_variance_output_loss: -1.3368e+00 - val_output_mean_absolute_error: 0.1367 - val_output_mean_error: -8.6707e-03\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 47/60\n",
      " - 18s - loss: -1.4133e+00 - output_loss: -1.4134e+00 - variance_output_loss: -1.4134e+00 - output_mean_absolute_error: 0.1319 - output_mean_error: -7.2950e-03 - val_loss: -1.3491e+00 - val_output_loss: -1.3492e+00 - val_variance_output_loss: -1.3492e+00 - val_output_mean_absolute_error: 0.1356 - val_output_mean_error: -9.8190e-03\n",
      "Epoch 48/60\n",
      " - 18s - loss: -1.4163e+00 - output_loss: -1.4164e+00 - variance_output_loss: -1.4164e+00 - output_mean_absolute_error: 0.1320 - output_mean_error: -7.4755e-03 - val_loss: -1.3423e+00 - val_output_loss: -1.3424e+00 - val_variance_output_loss: -1.3424e+00 - val_output_mean_absolute_error: 0.1353 - val_output_mean_error: -8.8604e-03\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 49/60\n",
      " - 18s - loss: -1.4135e+00 - output_loss: -1.4136e+00 - variance_output_loss: -1.4136e+00 - output_mean_absolute_error: 0.1320 - output_mean_error: -7.5849e-03 - val_loss: -1.3488e+00 - val_output_loss: -1.3489e+00 - val_variance_output_loss: -1.3489e+00 - val_output_mean_absolute_error: 0.1355 - val_output_mean_error: -7.4614e-03\n",
      "Epoch 50/60\n",
      " - 18s - loss: -1.4115e+00 - output_loss: -1.4116e+00 - variance_output_loss: -1.4116e+00 - output_mean_absolute_error: 0.1323 - output_mean_error: -7.3419e-03 - val_loss: -1.3455e+00 - val_output_loss: -1.3456e+00 - val_variance_output_loss: -1.3456e+00 - val_output_mean_absolute_error: 0.1357 - val_output_mean_error: -1.0693e-02\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 51/60\n",
      " - 18s - loss: -1.4103e+00 - output_loss: -1.4104e+00 - variance_output_loss: -1.4104e+00 - output_mean_absolute_error: 0.1325 - output_mean_error: -7.6592e-03 - val_loss: -1.3280e+00 - val_output_loss: -1.3281e+00 - val_variance_output_loss: -1.3281e+00 - val_output_mean_absolute_error: 0.1370 - val_output_mean_error: -1.0975e-02\n",
      "Epoch 52/60\n",
      " - 18s - loss: -1.4129e+00 - output_loss: -1.4130e+00 - variance_output_loss: -1.4130e+00 - output_mean_absolute_error: 0.1320 - output_mean_error: -8.4815e-03 - val_loss: -1.3424e+00 - val_output_loss: -1.3425e+00 - val_variance_output_loss: -1.3425e+00 - val_output_mean_absolute_error: 0.1345 - val_output_mean_error: -1.0239e-02\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 53/60\n",
      " - 18s - loss: -1.4092e+00 - output_loss: -1.4093e+00 - variance_output_loss: -1.4093e+00 - output_mean_absolute_error: 0.1327 - output_mean_error: -7.4804e-03 - val_loss: -1.3399e+00 - val_output_loss: -1.3400e+00 - val_variance_output_loss: -1.3400e+00 - val_output_mean_absolute_error: 0.1347 - val_output_mean_error: -9.6644e-03\n",
      "Epoch 54/60\n",
      " - 18s - loss: -1.4138e+00 - output_loss: -1.4139e+00 - variance_output_loss: -1.4139e+00 - output_mean_absolute_error: 0.1321 - output_mean_error: -7.7659e-03 - val_loss: -1.3253e+00 - val_output_loss: -1.3254e+00 - val_variance_output_loss: -1.3254e+00 - val_output_mean_absolute_error: 0.1362 - val_output_mean_error: -8.1041e-03\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 55/60\n",
      " - 18s - loss: -1.4148e+00 - output_loss: -1.4149e+00 - variance_output_loss: -1.4149e+00 - output_mean_absolute_error: 0.1318 - output_mean_error: -7.6277e-03 - val_loss: -1.3410e+00 - val_output_loss: -1.3411e+00 - val_variance_output_loss: -1.3411e+00 - val_output_mean_absolute_error: 0.1372 - val_output_mean_error: -1.2498e-02\n",
      "Epoch 56/60\n",
      " - 18s - loss: -1.4084e+00 - output_loss: -1.4085e+00 - variance_output_loss: -1.4085e+00 - output_mean_absolute_error: 0.1329 - output_mean_error: -8.3555e-03 - val_loss: -1.3366e+00 - val_output_loss: -1.3367e+00 - val_variance_output_loss: -1.3367e+00 - val_output_mean_absolute_error: 0.1366 - val_output_mean_error: -7.6462e-03\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "Epoch 57/60\n",
      " - 18s - loss: -1.4128e+00 - output_loss: -1.4129e+00 - variance_output_loss: -1.4129e+00 - output_mean_absolute_error: 0.1325 - output_mean_error: -8.5677e-03 - val_loss: -1.3528e+00 - val_output_loss: -1.3529e+00 - val_variance_output_loss: -1.3529e+00 - val_output_mean_absolute_error: 0.1357 - val_output_mean_error: -9.9709e-03\n",
      "Epoch 58/60\n",
      " - 18s - loss: -1.4130e+00 - output_loss: -1.4131e+00 - variance_output_loss: -1.4131e+00 - output_mean_absolute_error: 0.1321 - output_mean_error: -6.9566e-03 - val_loss: -1.3281e+00 - val_output_loss: -1.3282e+00 - val_variance_output_loss: -1.3282e+00 - val_output_mean_absolute_error: 0.1374 - val_output_mean_error: -9.6029e-03\n",
      "Epoch 59/60\n",
      " - 18s - loss: -1.4122e+00 - output_loss: -1.4123e+00 - variance_output_loss: -1.4123e+00 - output_mean_absolute_error: 0.1324 - output_mean_error: -7.7584e-03 - val_loss: -1.3328e+00 - val_output_loss: -1.3329e+00 - val_variance_output_loss: -1.3329e+00 - val_output_mean_absolute_error: 0.1371 - val_output_mean_error: -9.3528e-03\n",
      "Epoch 60/60\n",
      " - 18s - loss: -1.4137e+00 - output_loss: -1.4138e+00 - variance_output_loss: -1.4138e+00 - output_mean_absolute_error: 0.1321 - output_mean_error: -7.7550e-03 - val_loss: -1.3416e+00 - val_output_loss: -1.3417e+00 - val_variance_output_loss: -1.3417e+00 - val_output_mean_absolute_error: 0.1347 - val_output_mean_error: -7.4386e-03\n",
      "Completed Training, 1071.06s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\aspcapStar_BCNNCensored/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from utils_h5 import H5Loader\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader(\"aspcap_norm_train\")  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = [\n",
    "    \"teff\",\n",
    "    \"logg\",\n",
    "    \"C\",\n",
    "    \"C1\",\n",
    "    \"N\",\n",
    "    \"O\",\n",
    "    \"Na\",\n",
    "    \"Mg\",\n",
    "    \"Al\",\n",
    "    \"Si\",\n",
    "    \"P\",\n",
    "    \"S\",\n",
    "    \"K\",\n",
    "    \"Ca\",\n",
    "    \"Ti\",\n",
    "    \"Ti2\",\n",
    "    \"V\",\n",
    "    \"Cr\",\n",
    "    \"Mn\",\n",
    "    \"Fe\",\n",
    "    \"Co\",\n",
    "    \"Ni\",\n",
    "]\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = \"aspcapStar_BCNNCensored\"\n",
    "\n",
    "bcnn.train(x, y, labels_err=y_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the NN with ASPCAP normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 109.53s elapsed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Bias</th>\n",
       "      <th>Scatter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teff</td>\n",
       "      <td>-22.139</td>\n",
       "      <td>30.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logg</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>O</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Na</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mg</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Al</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Si</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>S</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>K</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ca</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ti</td>\n",
       "      <td>-0.024</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ti2</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>V</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cr</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mn</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fe</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Co</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ni</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name     Bias Scatter\n",
       "0   teff  -22.139  30.553\n",
       "1   logg    0.010   0.050\n",
       "2      C   -0.003   0.051\n",
       "3     C1    0.010   0.056\n",
       "4      N    0.008   0.064\n",
       "5      O   -0.017   0.047\n",
       "6     Na   -0.013   0.132\n",
       "7     Mg   -0.000   0.025\n",
       "8     Al   -0.040   0.070\n",
       "9     Si   -0.002   0.029\n",
       "10     P   -0.018   0.110\n",
       "11     S    0.011   0.060\n",
       "12     K   -0.010   0.046\n",
       "13    Ca   -0.014   0.030\n",
       "14    Ti   -0.024   0.050\n",
       "15   Ti2    0.039   0.105\n",
       "16     V   -0.007   0.099\n",
       "17    Cr    0.000   0.048\n",
       "18    Mn   -0.016   0.038\n",
       "19    Fe   -0.003   0.018\n",
       "20    Co   -0.021   0.140\n",
       "21    Ni    0.003   0.030"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.stats import mad_std as mad\n",
    "\n",
    "from utils_h5 import H5Loader\n",
    "from astroNN.models import ApogeeBCNNCensored, load_folder\n",
    "\n",
    "loader = H5Loader(\"aspcap_norm_test\")  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = [\n",
    "    \"teff\",\n",
    "    \"logg\",\n",
    "    \"C\",\n",
    "    \"C1\",\n",
    "    \"N\",\n",
    "    \"O\",\n",
    "    \"Na\",\n",
    "    \"Mg\",\n",
    "    \"Al\",\n",
    "    \"Si\",\n",
    "    \"P\",\n",
    "    \"S\",\n",
    "    \"K\",\n",
    "    \"Ca\",\n",
    "    \"Ti\",\n",
    "    \"Ti2\",\n",
    "    \"V\",\n",
    "    \"Cr\",\n",
    "    \"Mn\",\n",
    "    \"Fe\",\n",
    "    \"Co\",\n",
    "    \"Ni\",\n",
    "]\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = load_folder(\"aspcapStar_BCNNCensored\")\n",
    "\n",
    "pred, pred_error = bcnn.test(x, y)\n",
    "\n",
    "residue = pred - y\n",
    "\n",
    "bias = np.ma.median(np.ma.array(residue, mask=[y == -9999.0]), axis=0)\n",
    "scatter = mad(np.ma.array(residue, mask=[y == -9999.0]), axis=0)\n",
    "\n",
    "d = {\n",
    "    \"Name\": bcnn.targetname,\n",
    "    \"Bias\": [f\"{bias_single:.{3}f}\" for bias_single in bias],\n",
    "    \"Scatter\": [f\"{scatter_single:.{3}f}\" for scatter_single in scatter],\n",
    "}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}