{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 15033, Number of Validation Data: 1670\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 15s - loss: 0.1852 - output_loss: 0.1852 - variance_output_loss: 0.1852 - output_mean_absolute_error: 0.5726 - output_mean_error: -4.7036e-02 - val_loss: -1.3395e-01 - val_output_loss: -1.3399e-01 - val_variance_output_loss: -1.3399e-01 - val_output_mean_absolute_error: 0.4540 - val_output_mean_error: -7.8906e-02\n",
      "Epoch 2/60\n",
      " - 9s - loss: -3.5270e-01 - output_loss: -3.5274e-01 - variance_output_loss: -3.5274e-01 - output_mean_absolute_error: 0.3750 - output_mean_error: -5.5414e-02 - val_loss: -4.7807e-01 - val_output_loss: -4.7812e-01 - val_variance_output_loss: -4.7812e-01 - val_output_mean_absolute_error: 0.3417 - val_output_mean_error: -9.0919e-02\n",
      "Epoch 3/60\n",
      " - 9s - loss: -6.1332e-01 - output_loss: -6.1337e-01 - variance_output_loss: -6.1337e-01 - output_mean_absolute_error: 0.2909 - output_mean_error: -3.3768e-02 - val_loss: -6.8704e-01 - val_output_loss: -6.8709e-01 - val_variance_output_loss: -6.8709e-01 - val_output_mean_absolute_error: 0.2717 - val_output_mean_error: -4.5009e-02\n",
      "Epoch 4/60\n",
      " - 9s - loss: -7.7622e-01 - output_loss: -7.7627e-01 - variance_output_loss: -7.7627e-01 - output_mean_absolute_error: 0.2400 - output_mean_error: -2.0939e-02 - val_loss: -8.2092e-01 - val_output_loss: -8.2097e-01 - val_variance_output_loss: -8.2097e-01 - val_output_mean_absolute_error: 0.2305 - val_output_mean_error: -5.0615e-02\n",
      "Epoch 5/60\n",
      " - 9s - loss: -8.7958e-01 - output_loss: -8.7963e-01 - variance_output_loss: -8.7963e-01 - output_mean_absolute_error: 0.2127 - output_mean_error: -1.2551e-02 - val_loss: -9.0689e-01 - val_output_loss: -9.0694e-01 - val_variance_output_loss: -9.0694e-01 - val_output_mean_absolute_error: 0.2096 - val_output_mean_error: -5.2356e-02\n",
      "Epoch 6/60\n",
      " - 9s - loss: -9.5767e-01 - output_loss: -9.5772e-01 - variance_output_loss: -9.5772e-01 - output_mean_absolute_error: 0.1992 - output_mean_error: -1.1098e-02 - val_loss: -9.5950e-01 - val_output_loss: -9.5955e-01 - val_variance_output_loss: -9.5955e-01 - val_output_mean_absolute_error: 0.2020 - val_output_mean_error: -3.6878e-02\n",
      "Epoch 7/60\n",
      " - 10s - loss: -1.0215e+00 - output_loss: -1.0216e+00 - variance_output_loss: -1.0216e+00 - output_mean_absolute_error: 0.1869 - output_mean_error: -9.0247e-03 - val_loss: -9.8939e-01 - val_output_loss: -9.8944e-01 - val_variance_output_loss: -9.8944e-01 - val_output_mean_absolute_error: 0.1982 - val_output_mean_error: -4.6845e-02\n",
      "Epoch 8/60\n",
      " - 9s - loss: -1.0619e+00 - output_loss: -1.0619e+00 - variance_output_loss: -1.0619e+00 - output_mean_absolute_error: 0.1807 - output_mean_error: -8.6494e-03 - val_loss: -1.0414e+00 - val_output_loss: -1.0414e+00 - val_variance_output_loss: -1.0414e+00 - val_output_mean_absolute_error: 0.1855 - val_output_mean_error: -2.4043e-02\n",
      "Epoch 9/60\n",
      " - 9s - loss: -1.0902e+00 - output_loss: -1.0902e+00 - variance_output_loss: -1.0902e+00 - output_mean_absolute_error: 0.1773 - output_mean_error: -8.3523e-03 - val_loss: -1.0650e+00 - val_output_loss: -1.0650e+00 - val_variance_output_loss: -1.0650e+00 - val_output_mean_absolute_error: 0.1832 - val_output_mean_error: -3.6371e-02\n",
      "Epoch 10/60\n",
      " - 9s - loss: -1.1231e+00 - output_loss: -1.1232e+00 - variance_output_loss: -1.1232e+00 - output_mean_absolute_error: 0.1723 - output_mean_error: -7.3849e-03 - val_loss: -1.0961e+00 - val_output_loss: -1.0961e+00 - val_variance_output_loss: -1.0961e+00 - val_output_mean_absolute_error: 0.1798 - val_output_mean_error: -1.5147e-02\n",
      "Epoch 11/60\n",
      " - 9s - loss: -1.1423e+00 - output_loss: -1.1424e+00 - variance_output_loss: -1.1424e+00 - output_mean_absolute_error: 0.1688 - output_mean_error: -6.3570e-03 - val_loss: -1.1370e+00 - val_output_loss: -1.1370e+00 - val_variance_output_loss: -1.1370e+00 - val_output_mean_absolute_error: 0.1712 - val_output_mean_error: -5.8037e-03\n",
      "Epoch 12/60\n",
      " - 9s - loss: -1.1653e+00 - output_loss: -1.1654e+00 - variance_output_loss: -1.1654e+00 - output_mean_absolute_error: 0.1671 - output_mean_error: -6.5955e-03 - val_loss: -1.1320e+00 - val_output_loss: -1.1320e+00 - val_variance_output_loss: -1.1320e+00 - val_output_mean_absolute_error: 0.1734 - val_output_mean_error: -2.1347e-02\n",
      "Epoch 13/60\n",
      " - 9s - loss: -1.1752e+00 - output_loss: -1.1752e+00 - variance_output_loss: -1.1752e+00 - output_mean_absolute_error: 0.1657 - output_mean_error: -6.7131e-03 - val_loss: -1.1176e+00 - val_output_loss: -1.1177e+00 - val_variance_output_loss: -1.1177e+00 - val_output_mean_absolute_error: 0.1736 - val_output_mean_error: 0.0259\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/60\n",
      " - 9s - loss: -1.2038e+00 - output_loss: -1.2039e+00 - variance_output_loss: -1.2039e+00 - output_mean_absolute_error: 0.1612 - output_mean_error: -6.6215e-03 - val_loss: -1.1443e+00 - val_output_loss: -1.1443e+00 - val_variance_output_loss: -1.1443e+00 - val_output_mean_absolute_error: 0.1712 - val_output_mean_error: 0.0058\n",
      "Epoch 15/60\n",
      " - 9s - loss: -1.2167e+00 - output_loss: -1.2168e+00 - variance_output_loss: -1.2168e+00 - output_mean_absolute_error: 0.1603 - output_mean_error: -7.5026e-03 - val_loss: -1.1935e+00 - val_output_loss: -1.1935e+00 - val_variance_output_loss: -1.1935e+00 - val_output_mean_absolute_error: 0.1654 - val_output_mean_error: -3.4457e-04\n",
      "Epoch 16/60\n",
      " - 9s - loss: -1.2196e+00 - output_loss: -1.2197e+00 - variance_output_loss: -1.2197e+00 - output_mean_absolute_error: 0.1601 - output_mean_error: -7.0140e-03 - val_loss: -1.1839e+00 - val_output_loss: -1.1840e+00 - val_variance_output_loss: -1.1840e+00 - val_output_mean_absolute_error: 0.1695 - val_output_mean_error: 0.0056\n",
      "Epoch 17/60\n",
      " - 9s - loss: -1.2292e+00 - output_loss: -1.2292e+00 - variance_output_loss: -1.2292e+00 - output_mean_absolute_error: 0.1587 - output_mean_error: -6.7969e-03 - val_loss: -1.1783e+00 - val_output_loss: -1.1784e+00 - val_variance_output_loss: -1.1784e+00 - val_output_mean_absolute_error: 0.1663 - val_output_mean_error: 0.0017\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/60\n",
      " - 9s - loss: -1.2371e+00 - output_loss: -1.2371e+00 - variance_output_loss: -1.2371e+00 - output_mean_absolute_error: 0.1577 - output_mean_error: -6.3005e-03 - val_loss: -1.2107e+00 - val_output_loss: -1.2107e+00 - val_variance_output_loss: -1.2107e+00 - val_output_mean_absolute_error: 0.1627 - val_output_mean_error: -1.9238e-02\n",
      "Epoch 19/60\n",
      " - 9s - loss: -1.2426e+00 - output_loss: -1.2427e+00 - variance_output_loss: -1.2427e+00 - output_mean_absolute_error: 0.1569 - output_mean_error: -6.9473e-03 - val_loss: -1.1848e+00 - val_output_loss: -1.1849e+00 - val_variance_output_loss: -1.1849e+00 - val_output_mean_absolute_error: 0.1659 - val_output_mean_error: 0.0131\n",
      "Epoch 20/60\n",
      " - 9s - loss: -1.2491e+00 - output_loss: -1.2492e+00 - variance_output_loss: -1.2492e+00 - output_mean_absolute_error: 0.1561 - output_mean_error: -6.2422e-03 - val_loss: -1.2008e+00 - val_output_loss: -1.2009e+00 - val_variance_output_loss: -1.2009e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -4.5020e-03\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 21/60\n",
      " - 9s - loss: -1.2541e+00 - output_loss: -1.2541e+00 - variance_output_loss: -1.2541e+00 - output_mean_absolute_error: 0.1552 - output_mean_error: -7.0140e-03 - val_loss: -1.2038e+00 - val_output_loss: -1.2039e+00 - val_variance_output_loss: -1.2039e+00 - val_output_mean_absolute_error: 0.1650 - val_output_mean_error: -1.5228e-02\n",
      "Epoch 22/60\n",
      " - 9s - loss: -1.2554e+00 - output_loss: -1.2555e+00 - variance_output_loss: -1.2555e+00 - output_mean_absolute_error: 0.1556 - output_mean_error: -7.1320e-03 - val_loss: -1.2088e+00 - val_output_loss: -1.2088e+00 - val_variance_output_loss: -1.2088e+00 - val_output_mean_absolute_error: 0.1628 - val_output_mean_error: -2.1817e-02\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/60\n",
      " - 9s - loss: -1.2575e+00 - output_loss: -1.2575e+00 - variance_output_loss: -1.2575e+00 - output_mean_absolute_error: 0.1550 - output_mean_error: -6.5305e-03 - val_loss: -1.2095e+00 - val_output_loss: -1.2095e+00 - val_variance_output_loss: -1.2095e+00 - val_output_mean_absolute_error: 0.1619 - val_output_mean_error: -1.8145e-02\n",
      "Epoch 24/60\n",
      " - 9s - loss: -1.2622e+00 - output_loss: -1.2623e+00 - variance_output_loss: -1.2623e+00 - output_mean_absolute_error: 0.1542 - output_mean_error: -6.7186e-03 - val_loss: -1.2232e+00 - val_output_loss: -1.2233e+00 - val_variance_output_loss: -1.2233e+00 - val_output_mean_absolute_error: 0.1619 - val_output_mean_error: -1.2225e-03\n",
      "Epoch 25/60\n",
      " - 9s - loss: -1.2600e+00 - output_loss: -1.2601e+00 - variance_output_loss: -1.2601e+00 - output_mean_absolute_error: 0.1551 - output_mean_error: -6.8650e-03 - val_loss: -1.2101e+00 - val_output_loss: -1.2102e+00 - val_variance_output_loss: -1.2102e+00 - val_output_mean_absolute_error: 0.1656 - val_output_mean_error: -8.6061e-03\n",
      "Epoch 26/60\n",
      " - 9s - loss: -1.2611e+00 - output_loss: -1.2612e+00 - variance_output_loss: -1.2612e+00 - output_mean_absolute_error: 0.1548 - output_mean_error: -6.8400e-03 - val_loss: -1.2101e+00 - val_output_loss: -1.2102e+00 - val_variance_output_loss: -1.2102e+00 - val_output_mean_absolute_error: 0.1634 - val_output_mean_error: -2.0341e-02\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 27/60\n",
      " - 9s - loss: -1.2636e+00 - output_loss: -1.2637e+00 - variance_output_loss: -1.2637e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -6.9054e-03 - val_loss: -1.2201e+00 - val_output_loss: -1.2201e+00 - val_variance_output_loss: -1.2201e+00 - val_output_mean_absolute_error: 0.1622 - val_output_mean_error: -5.5943e-03\n",
      "Epoch 28/60\n",
      " - 9s - loss: -1.2673e+00 - output_loss: -1.2673e+00 - variance_output_loss: -1.2673e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -7.4681e-03 - val_loss: -1.2090e+00 - val_output_loss: -1.2091e+00 - val_variance_output_loss: -1.2091e+00 - val_output_mean_absolute_error: 0.1643 - val_output_mean_error: -8.3784e-03\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 29/60\n",
      " - 9s - loss: -1.2669e+00 - output_loss: -1.2670e+00 - variance_output_loss: -1.2670e+00 - output_mean_absolute_error: 0.1543 - output_mean_error: -6.6670e-03 - val_loss: -1.2064e+00 - val_output_loss: -1.2065e+00 - val_variance_output_loss: -1.2065e+00 - val_output_mean_absolute_error: 0.1593 - val_output_mean_error: -6.4049e-03\n",
      "Epoch 30/60\n",
      " - 9s - loss: -1.2659e+00 - output_loss: -1.2659e+00 - variance_output_loss: -1.2659e+00 - output_mean_absolute_error: 0.1542 - output_mean_error: -6.7849e-03 - val_loss: -1.2222e+00 - val_output_loss: -1.2222e+00 - val_variance_output_loss: -1.2222e+00 - val_output_mean_absolute_error: 0.1604 - val_output_mean_error: -9.7327e-03\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 31/60\n",
      " - 9s - loss: -1.2710e+00 - output_loss: -1.2710e+00 - variance_output_loss: -1.2710e+00 - output_mean_absolute_error: 0.1534 - output_mean_error: -6.5499e-03 - val_loss: -1.2165e+00 - val_output_loss: -1.2165e+00 - val_variance_output_loss: -1.2165e+00 - val_output_mean_absolute_error: 0.1633 - val_output_mean_error: -8.4457e-03\n",
      "Epoch 32/60\n",
      " - 9s - loss: -1.2719e+00 - output_loss: -1.2719e+00 - variance_output_loss: -1.2719e+00 - output_mean_absolute_error: 0.1532 - output_mean_error: -7.4190e-03 - val_loss: -1.2041e+00 - val_output_loss: -1.2042e+00 - val_variance_output_loss: -1.2042e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -8.3924e-03\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 33/60\n",
      " - 9s - loss: -1.2620e+00 - output_loss: -1.2621e+00 - variance_output_loss: -1.2621e+00 - output_mean_absolute_error: 0.1547 - output_mean_error: -6.2962e-03 - val_loss: -1.2186e+00 - val_output_loss: -1.2187e+00 - val_variance_output_loss: -1.2187e+00 - val_output_mean_absolute_error: 0.1596 - val_output_mean_error: -3.1411e-03\n",
      "Epoch 34/60\n",
      " - 9s - loss: -1.2724e+00 - output_loss: -1.2725e+00 - variance_output_loss: -1.2725e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -6.3959e-03 - val_loss: -1.2471e+00 - val_output_loss: -1.2472e+00 - val_variance_output_loss: -1.2472e+00 - val_output_mean_absolute_error: 0.1600 - val_output_mean_error: -7.6004e-03\n",
      "Epoch 35/60\n",
      " - 9s - loss: -1.2679e+00 - output_loss: -1.2679e+00 - variance_output_loss: -1.2679e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -7.1840e-03 - val_loss: -1.2291e+00 - val_output_loss: -1.2292e+00 - val_variance_output_loss: -1.2292e+00 - val_output_mean_absolute_error: 0.1637 - val_output_mean_error: -1.2144e-02\n",
      "Epoch 36/60\n",
      " - 9s - loss: -1.2687e+00 - output_loss: -1.2688e+00 - variance_output_loss: -1.2688e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -6.2612e-03 - val_loss: -1.1906e+00 - val_output_loss: -1.1907e+00 - val_variance_output_loss: -1.1907e+00 - val_output_mean_absolute_error: 0.1627 - val_output_mean_error: -7.8267e-03\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 37/60\n",
      " - 9s - loss: -1.2695e+00 - output_loss: -1.2696e+00 - variance_output_loss: -1.2696e+00 - output_mean_absolute_error: 0.1538 - output_mean_error: -6.7028e-03 - val_loss: -1.2173e+00 - val_output_loss: -1.2173e+00 - val_variance_output_loss: -1.2173e+00 - val_output_mean_absolute_error: 0.1615 - val_output_mean_error: -1.1769e-02\n",
      "Epoch 38/60\n",
      " - 9s - loss: -1.2636e+00 - output_loss: -1.2636e+00 - variance_output_loss: -1.2636e+00 - output_mean_absolute_error: 0.1548 - output_mean_error: -7.6880e-03 - val_loss: -1.2226e+00 - val_output_loss: -1.2226e+00 - val_variance_output_loss: -1.2226e+00 - val_output_mean_absolute_error: 0.1617 - val_output_mean_error: -7.7972e-03\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 39/60\n",
      " - 9s - loss: -1.2679e+00 - output_loss: -1.2680e+00 - variance_output_loss: -1.2680e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -5.9196e-03 - val_loss: -1.1879e+00 - val_output_loss: -1.1880e+00 - val_variance_output_loss: -1.1880e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -1.0310e-02\n",
      "Epoch 40/60\n",
      " - 9s - loss: -1.2662e+00 - output_loss: -1.2663e+00 - variance_output_loss: -1.2663e+00 - output_mean_absolute_error: 0.1542 - output_mean_error: -6.6073e-03 - val_loss: -1.2324e+00 - val_output_loss: -1.2324e+00 - val_variance_output_loss: -1.2324e+00 - val_output_mean_absolute_error: 0.1601 - val_output_mean_error: -7.2646e-03\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 41/60\n",
      " - 9s - loss: -1.2697e+00 - output_loss: -1.2698e+00 - variance_output_loss: -1.2698e+00 - output_mean_absolute_error: 0.1535 - output_mean_error: -7.1622e-03 - val_loss: -1.2322e+00 - val_output_loss: -1.2323e+00 - val_variance_output_loss: -1.2323e+00 - val_output_mean_absolute_error: 0.1612 - val_output_mean_error: -1.3201e-02\n",
      "Epoch 42/60\n",
      " - 9s - loss: -1.2653e+00 - output_loss: -1.2653e+00 - variance_output_loss: -1.2653e+00 - output_mean_absolute_error: 0.1544 - output_mean_error: -7.9702e-03 - val_loss: -1.2151e+00 - val_output_loss: -1.2152e+00 - val_variance_output_loss: -1.2152e+00 - val_output_mean_absolute_error: 0.1608 - val_output_mean_error: -1.0185e-02\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 43/60\n",
      " - 9s - loss: -1.2685e+00 - output_loss: -1.2685e+00 - variance_output_loss: -1.2685e+00 - output_mean_absolute_error: 0.1535 - output_mean_error: -6.7677e-03 - val_loss: -1.2171e+00 - val_output_loss: -1.2172e+00 - val_variance_output_loss: -1.2172e+00 - val_output_mean_absolute_error: 0.1620 - val_output_mean_error: -9.0127e-03\n",
      "Epoch 44/60\n",
      " - 9s - loss: -1.2643e+00 - output_loss: -1.2644e+00 - variance_output_loss: -1.2644e+00 - output_mean_absolute_error: 0.1554 - output_mean_error: -7.4679e-03 - val_loss: -1.2177e+00 - val_output_loss: -1.2178e+00 - val_variance_output_loss: -1.2178e+00 - val_output_mean_absolute_error: 0.1612 - val_output_mean_error: -9.1430e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 45/60\n",
      " - 9s - loss: -1.2687e+00 - output_loss: -1.2688e+00 - variance_output_loss: -1.2688e+00 - output_mean_absolute_error: 0.1537 - output_mean_error: -6.9174e-03 - val_loss: -1.2275e+00 - val_output_loss: -1.2276e+00 - val_variance_output_loss: -1.2276e+00 - val_output_mean_absolute_error: 0.1610 - val_output_mean_error: -5.4341e-03\n",
      "Epoch 46/60\n",
      " - 9s - loss: -1.2684e+00 - output_loss: -1.2684e+00 - variance_output_loss: -1.2684e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -7.1442e-03 - val_loss: -1.2125e+00 - val_output_loss: -1.2125e+00 - val_variance_output_loss: -1.2125e+00 - val_output_mean_absolute_error: 0.1640 - val_output_mean_error: -1.5527e-02\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 47/60\n",
      " - 9s - loss: -1.2699e+00 - output_loss: -1.2700e+00 - variance_output_loss: -1.2700e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -6.6905e-03 - val_loss: -1.2080e+00 - val_output_loss: -1.2080e+00 - val_variance_output_loss: -1.2080e+00 - val_output_mean_absolute_error: 0.1628 - val_output_mean_error: -9.3021e-03\n",
      "Epoch 48/60\n",
      " - 9s - loss: -1.2647e+00 - output_loss: -1.2648e+00 - variance_output_loss: -1.2648e+00 - output_mean_absolute_error: 0.1540 - output_mean_error: -6.1355e-03 - val_loss: -1.2378e+00 - val_output_loss: -1.2379e+00 - val_variance_output_loss: -1.2379e+00 - val_output_mean_absolute_error: 0.1597 - val_output_mean_error: -8.4778e-03\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 49/60\n",
      " - 9s - loss: -1.2649e+00 - output_loss: -1.2649e+00 - variance_output_loss: -1.2649e+00 - output_mean_absolute_error: 0.1537 - output_mean_error: -5.9456e-03 - val_loss: -1.2141e+00 - val_output_loss: -1.2142e+00 - val_variance_output_loss: -1.2142e+00 - val_output_mean_absolute_error: 0.1630 - val_output_mean_error: -9.6078e-03\n",
      "Epoch 50/60\n",
      " - 9s - loss: -1.2692e+00 - output_loss: -1.2693e+00 - variance_output_loss: -1.2693e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -7.7391e-03 - val_loss: -1.2213e+00 - val_output_loss: -1.2214e+00 - val_variance_output_loss: -1.2214e+00 - val_output_mean_absolute_error: 0.1623 - val_output_mean_error: -8.3724e-03\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "Epoch 51/60\n",
      " - 9s - loss: -1.2686e+00 - output_loss: -1.2687e+00 - variance_output_loss: -1.2687e+00 - output_mean_absolute_error: 0.1540 - output_mean_error: -7.1530e-03 - val_loss: -1.2152e+00 - val_output_loss: -1.2152e+00 - val_variance_output_loss: -1.2152e+00 - val_output_mean_absolute_error: 0.1624 - val_output_mean_error: -7.3985e-03\n",
      "Epoch 52/60\n",
      " - 9s - loss: -1.2675e+00 - output_loss: -1.2676e+00 - variance_output_loss: -1.2676e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -7.9907e-03 - val_loss: -1.2133e+00 - val_output_loss: -1.2133e+00 - val_variance_output_loss: -1.2133e+00 - val_output_mean_absolute_error: 0.1623 - val_output_mean_error: -8.8896e-03\n",
      "Epoch 53/60\n",
      " - 9s - loss: -1.2680e+00 - output_loss: -1.2680e+00 - variance_output_loss: -1.2680e+00 - output_mean_absolute_error: 0.1538 - output_mean_error: -6.4551e-03 - val_loss: -1.2169e+00 - val_output_loss: -1.2170e+00 - val_variance_output_loss: -1.2170e+00 - val_output_mean_absolute_error: 0.1636 - val_output_mean_error: -8.1578e-03\n",
      "Epoch 54/60\n",
      " - 9s - loss: -1.2637e+00 - output_loss: -1.2638e+00 - variance_output_loss: -1.2638e+00 - output_mean_absolute_error: 0.1544 - output_mean_error: -7.3259e-03 - val_loss: -1.2186e+00 - val_output_loss: -1.2187e+00 - val_variance_output_loss: -1.2187e+00 - val_output_mean_absolute_error: 0.1619 - val_output_mean_error: -6.2379e-03\n",
      "Epoch 55/60\n",
      " - 9s - loss: -1.2678e+00 - output_loss: -1.2679e+00 - variance_output_loss: -1.2679e+00 - output_mean_absolute_error: 0.1540 - output_mean_error: -6.5779e-03 - val_loss: -1.2170e+00 - val_output_loss: -1.2171e+00 - val_variance_output_loss: -1.2171e+00 - val_output_mean_absolute_error: 0.1615 - val_output_mean_error: -6.6991e-03\n",
      "Epoch 56/60\n",
      " - 9s - loss: -1.2676e+00 - output_loss: -1.2677e+00 - variance_output_loss: -1.2677e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -5.8322e-03 - val_loss: -1.1925e+00 - val_output_loss: -1.1926e+00 - val_variance_output_loss: -1.1926e+00 - val_output_mean_absolute_error: 0.1620 - val_output_mean_error: -9.0764e-03\n",
      "Epoch 57/60\n",
      " - 9s - loss: -1.2674e+00 - output_loss: -1.2674e+00 - variance_output_loss: -1.2674e+00 - output_mean_absolute_error: 0.1545 - output_mean_error: -7.0725e-03 - val_loss: -1.2233e+00 - val_output_loss: -1.2233e+00 - val_variance_output_loss: -1.2233e+00 - val_output_mean_absolute_error: 0.1603 - val_output_mean_error: -5.4786e-03\n",
      "Epoch 58/60\n",
      " - 9s - loss: -1.2701e+00 - output_loss: -1.2702e+00 - variance_output_loss: -1.2702e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -8.4738e-03 - val_loss: -1.2392e+00 - val_output_loss: -1.2392e+00 - val_variance_output_loss: -1.2392e+00 - val_output_mean_absolute_error: 0.1624 - val_output_mean_error: -7.4900e-03\n",
      "Epoch 59/60\n",
      " - 9s - loss: -1.2673e+00 - output_loss: -1.2674e+00 - variance_output_loss: -1.2674e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -7.7231e-03 - val_loss: -1.1925e+00 - val_output_loss: -1.1925e+00 - val_variance_output_loss: -1.1925e+00 - val_output_mean_absolute_error: 0.1628 - val_output_mean_error: -5.6812e-03\n",
      "Epoch 60/60\n",
      " - 9s - loss: -1.2679e+00 - output_loss: -1.2680e+00 - variance_output_loss: -1.2680e+00 - output_mean_absolute_error: 0.1543 - output_mean_error: -7.2616e-03 - val_loss: -1.2188e+00 - val_output_loss: -1.2189e+00 - val_variance_output_loss: -1.2189e+00 - val_output_mean_absolute_error: 0.1593 - val_output_mean_error: -6.9268e-03\n",
      "Completed Training, 546.60s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_50/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_50'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/2), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 7516, Number of Validation Data: 835\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 10s - loss: 0.3336 - output_loss: 0.3336 - variance_output_loss: 0.3336 - output_mean_absolute_error: 0.6251 - output_mean_error: -2.1928e-02 - val_loss: 0.1246 - val_output_loss: 0.1246 - val_variance_output_loss: 0.1246 - val_output_mean_absolute_error: 0.4977 - val_output_mean_error: -7.2640e-02\n",
      "Epoch 2/60\n",
      " - 5s - loss: -9.7967e-02 - output_loss: -9.8012e-02 - variance_output_loss: -9.8012e-02 - output_mean_absolute_error: 0.4100 - output_mean_error: -6.2073e-02 - val_loss: -2.3634e-01 - val_output_loss: -2.3638e-01 - val_variance_output_loss: -2.3638e-01 - val_output_mean_absolute_error: 0.3814 - val_output_mean_error: -9.2241e-02\n",
      "Epoch 3/60\n",
      " - 5s - loss: -3.7193e-01 - output_loss: -3.7198e-01 - variance_output_loss: -3.7198e-01 - output_mean_absolute_error: 0.3416 - output_mean_error: -4.9012e-02 - val_loss: -4.5664e-01 - val_output_loss: -4.5668e-01 - val_variance_output_loss: -4.5668e-01 - val_output_mean_absolute_error: 0.3231 - val_output_mean_error: -2.8954e-02\n",
      "Epoch 4/60\n",
      " - 5s - loss: -5.2673e-01 - output_loss: -5.2677e-01 - variance_output_loss: -5.2677e-01 - output_mean_absolute_error: 0.2991 - output_mean_error: -3.6364e-02 - val_loss: -5.8556e-01 - val_output_loss: -5.8561e-01 - val_variance_output_loss: -5.8561e-01 - val_output_mean_absolute_error: 0.2835 - val_output_mean_error: -1.4081e-02\n",
      "Epoch 5/60\n",
      " - 5s - loss: -6.4571e-01 - output_loss: -6.4575e-01 - variance_output_loss: -6.4575e-01 - output_mean_absolute_error: 0.2642 - output_mean_error: -2.1464e-02 - val_loss: -6.6848e-01 - val_output_loss: -6.6853e-01 - val_variance_output_loss: -6.6853e-01 - val_output_mean_absolute_error: 0.2603 - val_output_mean_error: 0.0060\n",
      "Epoch 6/60\n",
      " - 4s - loss: -7.2576e-01 - output_loss: -7.2581e-01 - variance_output_loss: -7.2581e-01 - output_mean_absolute_error: 0.2434 - output_mean_error: -1.6988e-02 - val_loss: -7.6558e-01 - val_output_loss: -7.6563e-01 - val_variance_output_loss: -7.6563e-01 - val_output_mean_absolute_error: 0.2352 - val_output_mean_error: 0.0317\n",
      "Epoch 7/60\n",
      " - 4s - loss: -7.8460e-01 - output_loss: -7.8465e-01 - variance_output_loss: -7.8465e-01 - output_mean_absolute_error: 0.2273 - output_mean_error: -1.2541e-02 - val_loss: -7.5825e-01 - val_output_loss: -7.5829e-01 - val_variance_output_loss: -7.5829e-01 - val_output_mean_absolute_error: 0.2333 - val_output_mean_error: 0.0576\n",
      "Epoch 8/60\n",
      " - 4s - loss: -8.3533e-01 - output_loss: -8.3538e-01 - variance_output_loss: -8.3538e-01 - output_mean_absolute_error: 0.2161 - output_mean_error: -9.3723e-03 - val_loss: -8.0536e-01 - val_output_loss: -8.0541e-01 - val_variance_output_loss: -8.0541e-01 - val_output_mean_absolute_error: 0.2221 - val_output_mean_error: -3.4307e-02\n",
      "Epoch 9/60\n",
      " - 4s - loss: -8.8558e-01 - output_loss: -8.8563e-01 - variance_output_loss: -8.8563e-01 - output_mean_absolute_error: 0.2060 - output_mean_error: -7.7806e-03 - val_loss: -8.7030e-01 - val_output_loss: -8.7035e-01 - val_variance_output_loss: -8.7035e-01 - val_output_mean_absolute_error: 0.2134 - val_output_mean_error: 0.0179\n",
      "Epoch 10/60\n",
      " - 5s - loss: -9.1562e-01 - output_loss: -9.1567e-01 - variance_output_loss: -9.1567e-01 - output_mean_absolute_error: 0.1999 - output_mean_error: -7.4214e-03 - val_loss: -9.1523e-01 - val_output_loss: -9.1528e-01 - val_variance_output_loss: -9.1528e-01 - val_output_mean_absolute_error: 0.2003 - val_output_mean_error: -3.0754e-02\n",
      "Epoch 11/60\n",
      " - 5s - loss: -9.4724e-01 - output_loss: -9.4729e-01 - variance_output_loss: -9.4729e-01 - output_mean_absolute_error: 0.1940 - output_mean_error: -6.9983e-03 - val_loss: -8.9769e-01 - val_output_loss: -8.9774e-01 - val_variance_output_loss: -8.9774e-01 - val_output_mean_absolute_error: 0.2028 - val_output_mean_error: 0.0305\n",
      "Epoch 12/60\n",
      " - 5s - loss: -9.6582e-01 - output_loss: -9.6587e-01 - variance_output_loss: -9.6587e-01 - output_mean_absolute_error: 0.1902 - output_mean_error: -5.0393e-03 - val_loss: -9.5805e-01 - val_output_loss: -9.5810e-01 - val_variance_output_loss: -9.5810e-01 - val_output_mean_absolute_error: 0.1915 - val_output_mean_error: -2.9315e-02\n",
      "Epoch 13/60\n",
      " - 5s - loss: -9.9835e-01 - output_loss: -9.9840e-01 - variance_output_loss: -9.9840e-01 - output_mean_absolute_error: 0.1863 - output_mean_error: -3.7388e-03 - val_loss: -9.2779e-01 - val_output_loss: -9.2784e-01 - val_variance_output_loss: -9.2784e-01 - val_output_mean_absolute_error: 0.2021 - val_output_mean_error: 0.0161\n",
      "Epoch 14/60\n",
      " - 5s - loss: -1.0179e+00 - output_loss: -1.0180e+00 - variance_output_loss: -1.0180e+00 - output_mean_absolute_error: 0.1839 - output_mean_error: -5.0946e-03 - val_loss: -1.0303e+00 - val_output_loss: -1.0303e+00 - val_variance_output_loss: -1.0303e+00 - val_output_mean_absolute_error: 0.1827 - val_output_mean_error: -9.3289e-03\n",
      "Epoch 15/60\n",
      " - 5s - loss: -1.0325e+00 - output_loss: -1.0326e+00 - variance_output_loss: -1.0326e+00 - output_mean_absolute_error: 0.1816 - output_mean_error: -5.5605e-03 - val_loss: -1.0344e+00 - val_output_loss: -1.0344e+00 - val_variance_output_loss: -1.0344e+00 - val_output_mean_absolute_error: 0.1834 - val_output_mean_error: -5.6702e-03\n",
      "Epoch 16/60\n",
      " - 4s - loss: -1.0481e+00 - output_loss: -1.0481e+00 - variance_output_loss: -1.0481e+00 - output_mean_absolute_error: 0.1799 - output_mean_error: -6.5995e-03 - val_loss: -1.0320e+00 - val_output_loss: -1.0321e+00 - val_variance_output_loss: -1.0321e+00 - val_output_mean_absolute_error: 0.1846 - val_output_mean_error: -7.3345e-03\n",
      "Epoch 17/60\n",
      " - 4s - loss: -1.0666e+00 - output_loss: -1.0667e+00 - variance_output_loss: -1.0667e+00 - output_mean_absolute_error: 0.1775 - output_mean_error: -5.3084e-03 - val_loss: -1.0563e+00 - val_output_loss: -1.0563e+00 - val_variance_output_loss: -1.0563e+00 - val_output_mean_absolute_error: 0.1816 - val_output_mean_error: 0.0087\n",
      "Epoch 18/60\n",
      " - 4s - loss: -1.0860e+00 - output_loss: -1.0861e+00 - variance_output_loss: -1.0861e+00 - output_mean_absolute_error: 0.1742 - output_mean_error: -5.0769e-03 - val_loss: -1.0321e+00 - val_output_loss: -1.0322e+00 - val_variance_output_loss: -1.0322e+00 - val_output_mean_absolute_error: 0.1825 - val_output_mean_error: -3.5106e-02\n",
      "Epoch 19/60\n",
      " - 5s - loss: -1.1040e+00 - output_loss: -1.1041e+00 - variance_output_loss: -1.1041e+00 - output_mean_absolute_error: 0.1725 - output_mean_error: -6.1717e-03 - val_loss: -1.0549e+00 - val_output_loss: -1.0550e+00 - val_variance_output_loss: -1.0550e+00 - val_output_mean_absolute_error: 0.1786 - val_output_mean_error: -1.9965e-03\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 20/60\n",
      " - 4s - loss: -1.1265e+00 - output_loss: -1.1266e+00 - variance_output_loss: -1.1266e+00 - output_mean_absolute_error: 0.1701 - output_mean_error: -5.8935e-03 - val_loss: -1.0965e+00 - val_output_loss: -1.0965e+00 - val_variance_output_loss: -1.0965e+00 - val_output_mean_absolute_error: 0.1758 - val_output_mean_error: -2.6856e-02\n",
      "Epoch 21/60\n",
      " - 5s - loss: -1.1429e+00 - output_loss: -1.1429e+00 - variance_output_loss: -1.1429e+00 - output_mean_absolute_error: 0.1682 - output_mean_error: -5.8552e-03 - val_loss: -1.0863e+00 - val_output_loss: -1.0863e+00 - val_variance_output_loss: -1.0863e+00 - val_output_mean_absolute_error: 0.1751 - val_output_mean_error: 0.0170\n",
      "Epoch 22/60\n",
      " - 5s - loss: -1.1349e+00 - output_loss: -1.1349e+00 - variance_output_loss: -1.1349e+00 - output_mean_absolute_error: 0.1680 - output_mean_error: -4.7267e-03 - val_loss: -1.1013e+00 - val_output_loss: -1.1014e+00 - val_variance_output_loss: -1.1014e+00 - val_output_mean_absolute_error: 0.1737 - val_output_mean_error: -1.1743e-02\n",
      "Epoch 23/60\n",
      " - 4s - loss: -1.1463e+00 - output_loss: -1.1464e+00 - variance_output_loss: -1.1464e+00 - output_mean_absolute_error: 0.1686 - output_mean_error: -6.4485e-03 - val_loss: -1.1047e+00 - val_output_loss: -1.1047e+00 - val_variance_output_loss: -1.1047e+00 - val_output_mean_absolute_error: 0.1747 - val_output_mean_error: 2.6419e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      " - 4s - loss: -1.1534e+00 - output_loss: -1.1534e+00 - variance_output_loss: -1.1534e+00 - output_mean_absolute_error: 0.1657 - output_mean_error: -5.7820e-03 - val_loss: -1.1079e+00 - val_output_loss: -1.1080e+00 - val_variance_output_loss: -1.1080e+00 - val_output_mean_absolute_error: 0.1729 - val_output_mean_error: 0.0056\n",
      "Epoch 25/60\n",
      " - 4s - loss: -1.1642e+00 - output_loss: -1.1643e+00 - variance_output_loss: -1.1643e+00 - output_mean_absolute_error: 0.1649 - output_mean_error: -5.8232e-03 - val_loss: -1.1229e+00 - val_output_loss: -1.1230e+00 - val_variance_output_loss: -1.1230e+00 - val_output_mean_absolute_error: 0.1713 - val_output_mean_error: -2.1227e-02\n",
      "Epoch 26/60\n",
      " - 5s - loss: -1.1669e+00 - output_loss: -1.1669e+00 - variance_output_loss: -1.1669e+00 - output_mean_absolute_error: 0.1645 - output_mean_error: -5.3876e-03 - val_loss: -1.1397e+00 - val_output_loss: -1.1397e+00 - val_variance_output_loss: -1.1397e+00 - val_output_mean_absolute_error: 0.1702 - val_output_mean_error: -1.9760e-02\n",
      "Epoch 27/60\n",
      " - 5s - loss: -1.1800e+00 - output_loss: -1.1801e+00 - variance_output_loss: -1.1801e+00 - output_mean_absolute_error: 0.1630 - output_mean_error: -6.1604e-03 - val_loss: -1.1371e+00 - val_output_loss: -1.1371e+00 - val_variance_output_loss: -1.1371e+00 - val_output_mean_absolute_error: 0.1712 - val_output_mean_error: -2.8694e-02\n",
      "Epoch 28/60\n",
      " - 4s - loss: -1.1608e+00 - output_loss: -1.1609e+00 - variance_output_loss: -1.1609e+00 - output_mean_absolute_error: 0.1661 - output_mean_error: -6.4487e-03 - val_loss: -1.1269e+00 - val_output_loss: -1.1270e+00 - val_variance_output_loss: -1.1270e+00 - val_output_mean_absolute_error: 0.1721 - val_output_mean_error: -1.7990e-03\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 29/60\n",
      " - 4s - loss: -1.1823e+00 - output_loss: -1.1824e+00 - variance_output_loss: -1.1824e+00 - output_mean_absolute_error: 0.1628 - output_mean_error: -4.2886e-03 - val_loss: -1.1600e+00 - val_output_loss: -1.1600e+00 - val_variance_output_loss: -1.1600e+00 - val_output_mean_absolute_error: 0.1653 - val_output_mean_error: 0.0157\n",
      "Epoch 30/60\n",
      " - 5s - loss: -1.1933e+00 - output_loss: -1.1934e+00 - variance_output_loss: -1.1934e+00 - output_mean_absolute_error: 0.1616 - output_mean_error: -6.5533e-03 - val_loss: -1.1648e+00 - val_output_loss: -1.1648e+00 - val_variance_output_loss: -1.1648e+00 - val_output_mean_absolute_error: 0.1634 - val_output_mean_error: -2.3764e-03\n",
      "Epoch 31/60\n",
      " - 5s - loss: -1.1934e+00 - output_loss: -1.1934e+00 - variance_output_loss: -1.1934e+00 - output_mean_absolute_error: 0.1613 - output_mean_error: -6.3115e-03 - val_loss: -1.1677e+00 - val_output_loss: -1.1678e+00 - val_variance_output_loss: -1.1678e+00 - val_output_mean_absolute_error: 0.1660 - val_output_mean_error: -1.0782e-02\n",
      "Epoch 32/60\n",
      " - 4s - loss: -1.1946e+00 - output_loss: -1.1947e+00 - variance_output_loss: -1.1947e+00 - output_mean_absolute_error: 0.1615 - output_mean_error: -5.3200e-03 - val_loss: -1.1328e+00 - val_output_loss: -1.1329e+00 - val_variance_output_loss: -1.1329e+00 - val_output_mean_absolute_error: 0.1689 - val_output_mean_error: -2.2390e-02\n",
      "Epoch 33/60\n",
      " - 5s - loss: -1.1965e+00 - output_loss: -1.1966e+00 - variance_output_loss: -1.1966e+00 - output_mean_absolute_error: 0.1614 - output_mean_error: -6.1644e-03 - val_loss: -1.1736e+00 - val_output_loss: -1.1736e+00 - val_variance_output_loss: -1.1736e+00 - val_output_mean_absolute_error: 0.1657 - val_output_mean_error: 0.0127\n",
      "Epoch 34/60\n",
      " - 5s - loss: -1.2085e+00 - output_loss: -1.2086e+00 - variance_output_loss: -1.2086e+00 - output_mean_absolute_error: 0.1601 - output_mean_error: -6.0654e-03 - val_loss: -1.1650e+00 - val_output_loss: -1.1650e+00 - val_variance_output_loss: -1.1650e+00 - val_output_mean_absolute_error: 0.1668 - val_output_mean_error: 0.0071\n",
      "Epoch 35/60\n",
      " - 5s - loss: -1.2081e+00 - output_loss: -1.2081e+00 - variance_output_loss: -1.2081e+00 - output_mean_absolute_error: 0.1604 - output_mean_error: -6.5283e-03 - val_loss: -1.1139e+00 - val_output_loss: -1.1139e+00 - val_variance_output_loss: -1.1139e+00 - val_output_mean_absolute_error: 0.1740 - val_output_mean_error: 0.0034\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 36/60\n",
      " - 5s - loss: -1.2120e+00 - output_loss: -1.2121e+00 - variance_output_loss: -1.2121e+00 - output_mean_absolute_error: 0.1596 - output_mean_error: -4.6962e-03 - val_loss: -1.1626e+00 - val_output_loss: -1.1627e+00 - val_variance_output_loss: -1.1627e+00 - val_output_mean_absolute_error: 0.1675 - val_output_mean_error: -3.7290e-03\n",
      "Epoch 37/60\n",
      " - 5s - loss: -1.2123e+00 - output_loss: -1.2123e+00 - variance_output_loss: -1.2123e+00 - output_mean_absolute_error: 0.1602 - output_mean_error: -5.2038e-03 - val_loss: -1.1303e+00 - val_output_loss: -1.1303e+00 - val_variance_output_loss: -1.1303e+00 - val_output_mean_absolute_error: 0.1737 - val_output_mean_error: -1.6635e-02\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 38/60\n",
      " - 4s - loss: -1.2108e+00 - output_loss: -1.2108e+00 - variance_output_loss: -1.2108e+00 - output_mean_absolute_error: 0.1596 - output_mean_error: -6.0381e-03 - val_loss: -1.1531e+00 - val_output_loss: -1.1532e+00 - val_variance_output_loss: -1.1532e+00 - val_output_mean_absolute_error: 0.1700 - val_output_mean_error: -1.4939e-02\n",
      "Epoch 39/60\n",
      " - 4s - loss: -1.2292e+00 - output_loss: -1.2293e+00 - variance_output_loss: -1.2293e+00 - output_mean_absolute_error: 0.1570 - output_mean_error: -7.2654e-03 - val_loss: -1.1507e+00 - val_output_loss: -1.1507e+00 - val_variance_output_loss: -1.1507e+00 - val_output_mean_absolute_error: 0.1664 - val_output_mean_error: -3.2568e-03\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 40/60\n",
      " - 4s - loss: -1.2175e+00 - output_loss: -1.2176e+00 - variance_output_loss: -1.2176e+00 - output_mean_absolute_error: 0.1598 - output_mean_error: -6.2211e-03 - val_loss: -1.1650e+00 - val_output_loss: -1.1650e+00 - val_variance_output_loss: -1.1650e+00 - val_output_mean_absolute_error: 0.1677 - val_output_mean_error: -6.0767e-03\n",
      "Epoch 41/60\n",
      " - 4s - loss: -1.2277e+00 - output_loss: -1.2278e+00 - variance_output_loss: -1.2278e+00 - output_mean_absolute_error: 0.1559 - output_mean_error: -4.6766e-03 - val_loss: -1.1356e+00 - val_output_loss: -1.1357e+00 - val_variance_output_loss: -1.1357e+00 - val_output_mean_absolute_error: 0.1671 - val_output_mean_error: -9.7732e-04\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 42/60\n",
      " - 4s - loss: -1.2126e+00 - output_loss: -1.2127e+00 - variance_output_loss: -1.2127e+00 - output_mean_absolute_error: 0.1600 - output_mean_error: -7.0283e-03 - val_loss: -1.1645e+00 - val_output_loss: -1.1645e+00 - val_variance_output_loss: -1.1645e+00 - val_output_mean_absolute_error: 0.1691 - val_output_mean_error: -5.0310e-03\n",
      "Epoch 43/60\n",
      " - 5s - loss: -1.2231e+00 - output_loss: -1.2232e+00 - variance_output_loss: -1.2232e+00 - output_mean_absolute_error: 0.1576 - output_mean_error: -5.1369e-03 - val_loss: -1.1697e+00 - val_output_loss: -1.1698e+00 - val_variance_output_loss: -1.1698e+00 - val_output_mean_absolute_error: 0.1662 - val_output_mean_error: -8.4658e-03\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 44/60\n",
      " - 4s - loss: -1.2250e+00 - output_loss: -1.2250e+00 - variance_output_loss: -1.2250e+00 - output_mean_absolute_error: 0.1577 - output_mean_error: -5.8167e-03 - val_loss: -1.1729e+00 - val_output_loss: -1.1729e+00 - val_variance_output_loss: -1.1729e+00 - val_output_mean_absolute_error: 0.1645 - val_output_mean_error: -6.2165e-03\n",
      "Epoch 45/60\n",
      " - 4s - loss: -1.2224e+00 - output_loss: -1.2225e+00 - variance_output_loss: -1.2225e+00 - output_mean_absolute_error: 0.1578 - output_mean_error: -6.5054e-03 - val_loss: -1.1425e+00 - val_output_loss: -1.1425e+00 - val_variance_output_loss: -1.1425e+00 - val_output_mean_absolute_error: 0.1699 - val_output_mean_error: -1.4964e-02\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 46/60\n",
      " - 4s - loss: -1.2176e+00 - output_loss: -1.2177e+00 - variance_output_loss: -1.2177e+00 - output_mean_absolute_error: 0.1580 - output_mean_error: -5.2517e-03 - val_loss: -1.1955e+00 - val_output_loss: -1.1955e+00 - val_variance_output_loss: -1.1955e+00 - val_output_mean_absolute_error: 0.1638 - val_output_mean_error: -9.5697e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      " - 4s - loss: -1.2233e+00 - output_loss: -1.2234e+00 - variance_output_loss: -1.2234e+00 - output_mean_absolute_error: 0.1577 - output_mean_error: -5.8325e-03 - val_loss: -1.1536e+00 - val_output_loss: -1.1536e+00 - val_variance_output_loss: -1.1536e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -5.9521e-03\n",
      "Epoch 48/60\n",
      " - 4s - loss: -1.2177e+00 - output_loss: -1.2177e+00 - variance_output_loss: -1.2177e+00 - output_mean_absolute_error: 0.1595 - output_mean_error: -7.0635e-03 - val_loss: -1.1671e+00 - val_output_loss: -1.1671e+00 - val_variance_output_loss: -1.1671e+00 - val_output_mean_absolute_error: 0.1665 - val_output_mean_error: -8.5970e-03\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 49/60\n",
      " - 4s - loss: -1.2250e+00 - output_loss: -1.2250e+00 - variance_output_loss: -1.2250e+00 - output_mean_absolute_error: 0.1573 - output_mean_error: -5.0689e-03 - val_loss: -1.1638e+00 - val_output_loss: -1.1639e+00 - val_variance_output_loss: -1.1639e+00 - val_output_mean_absolute_error: 0.1667 - val_output_mean_error: -6.1507e-03\n",
      "Epoch 50/60\n",
      " - 4s - loss: -1.2248e+00 - output_loss: -1.2248e+00 - variance_output_loss: -1.2248e+00 - output_mean_absolute_error: 0.1578 - output_mean_error: -6.9660e-03 - val_loss: -1.1856e+00 - val_output_loss: -1.1856e+00 - val_variance_output_loss: -1.1856e+00 - val_output_mean_absolute_error: 0.1615 - val_output_mean_error: -1.5237e-03\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 51/60\n",
      " - 5s - loss: -1.2251e+00 - output_loss: -1.2252e+00 - variance_output_loss: -1.2252e+00 - output_mean_absolute_error: 0.1575 - output_mean_error: -6.2238e-03 - val_loss: -1.1791e+00 - val_output_loss: -1.1792e+00 - val_variance_output_loss: -1.1792e+00 - val_output_mean_absolute_error: 0.1675 - val_output_mean_error: -7.2171e-03\n",
      "Epoch 52/60\n",
      " - 5s - loss: -1.2259e+00 - output_loss: -1.2260e+00 - variance_output_loss: -1.2260e+00 - output_mean_absolute_error: 0.1583 - output_mean_error: -6.5885e-03 - val_loss: -1.1882e+00 - val_output_loss: -1.1882e+00 - val_variance_output_loss: -1.1882e+00 - val_output_mean_absolute_error: 0.1633 - val_output_mean_error: -7.8710e-03\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 53/60\n",
      " - 4s - loss: -1.2221e+00 - output_loss: -1.2222e+00 - variance_output_loss: -1.2222e+00 - output_mean_absolute_error: 0.1578 - output_mean_error: -5.5872e-03 - val_loss: -1.1820e+00 - val_output_loss: -1.1820e+00 - val_variance_output_loss: -1.1820e+00 - val_output_mean_absolute_error: 0.1668 - val_output_mean_error: -1.0032e-02\n",
      "Epoch 54/60\n",
      " - 4s - loss: -1.2192e+00 - output_loss: -1.2192e+00 - variance_output_loss: -1.2192e+00 - output_mean_absolute_error: 0.1581 - output_mean_error: -3.0214e-03 - val_loss: -1.1788e+00 - val_output_loss: -1.1789e+00 - val_variance_output_loss: -1.1789e+00 - val_output_mean_absolute_error: 0.1639 - val_output_mean_error: -6.2348e-03\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 55/60\n",
      " - 4s - loss: -1.2185e+00 - output_loss: -1.2186e+00 - variance_output_loss: -1.2186e+00 - output_mean_absolute_error: 0.1592 - output_mean_error: -4.8130e-03 - val_loss: -1.1816e+00 - val_output_loss: -1.1816e+00 - val_variance_output_loss: -1.1816e+00 - val_output_mean_absolute_error: 0.1651 - val_output_mean_error: -8.3036e-03\n",
      "Epoch 56/60\n",
      " - 5s - loss: -1.2289e+00 - output_loss: -1.2289e+00 - variance_output_loss: -1.2289e+00 - output_mean_absolute_error: 0.1580 - output_mean_error: -5.4008e-03 - val_loss: -1.1639e+00 - val_output_loss: -1.1639e+00 - val_variance_output_loss: -1.1639e+00 - val_output_mean_absolute_error: 0.1664 - val_output_mean_error: -5.0749e-03\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 57/60\n",
      " - 4s - loss: -1.2253e+00 - output_loss: -1.2253e+00 - variance_output_loss: -1.2253e+00 - output_mean_absolute_error: 0.1575 - output_mean_error: -6.6607e-03 - val_loss: -1.1796e+00 - val_output_loss: -1.1797e+00 - val_variance_output_loss: -1.1797e+00 - val_output_mean_absolute_error: 0.1639 - val_output_mean_error: -9.4413e-03\n",
      "Epoch 58/60\n",
      " - 4s - loss: -1.2210e+00 - output_loss: -1.2211e+00 - variance_output_loss: -1.2211e+00 - output_mean_absolute_error: 0.1583 - output_mean_error: -6.5592e-03 - val_loss: -1.1708e+00 - val_output_loss: -1.1709e+00 - val_variance_output_loss: -1.1709e+00 - val_output_mean_absolute_error: 0.1641 - val_output_mean_error: -1.8710e-03\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 59/60\n",
      " - 4s - loss: -1.2148e+00 - output_loss: -1.2149e+00 - variance_output_loss: -1.2149e+00 - output_mean_absolute_error: 0.1595 - output_mean_error: -7.1776e-03 - val_loss: -1.1794e+00 - val_output_loss: -1.1795e+00 - val_variance_output_loss: -1.1795e+00 - val_output_mean_absolute_error: 0.1625 - val_output_mean_error: -9.0460e-03\n",
      "Epoch 60/60\n",
      " - 4s - loss: -1.2196e+00 - output_loss: -1.2196e+00 - variance_output_loss: -1.2196e+00 - output_mean_absolute_error: 0.1586 - output_mean_error: -5.3842e-03 - val_loss: -1.1772e+00 - val_output_loss: -1.1773e+00 - val_variance_output_loss: -1.1773e+00 - val_output_mean_absolute_error: 0.1670 - val_output_mean_error: -7.4797e-03\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Completed Training, 279.65s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_25/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_25'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/4), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 3758, Number of Validation Data: 417\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 8s - loss: 0.3842 - output_loss: 0.3842 - variance_output_loss: 0.3842 - output_mean_absolute_error: 0.6283 - output_mean_error: -2.4548e-02 - val_loss: 0.3116 - val_output_loss: 0.3115 - val_variance_output_loss: 0.3115 - val_output_mean_absolute_error: 0.5525 - val_output_mean_error: -6.4697e-02\n",
      "Epoch 2/60\n",
      " - 2s - loss: 0.1690 - output_loss: 0.1689 - variance_output_loss: 0.1689 - output_mean_absolute_error: 0.5009 - output_mean_error: -4.5530e-02 - val_loss: 0.0521 - val_output_loss: 0.0520 - val_variance_output_loss: 0.0520 - val_output_mean_absolute_error: 0.4406 - val_output_mean_error: -7.7326e-03\n",
      "Epoch 3/60\n",
      " - 2s - loss: -4.9196e-02 - output_loss: -4.9241e-02 - variance_output_loss: -4.9241e-02 - output_mean_absolute_error: 0.4141 - output_mean_error: -3.4218e-02 - val_loss: -1.5913e-01 - val_output_loss: -1.5918e-01 - val_variance_output_loss: -1.5918e-01 - val_output_mean_absolute_error: 0.3780 - val_output_mean_error: -3.7097e-02\n",
      "Epoch 4/60\n",
      " - 2s - loss: -2.2725e-01 - output_loss: -2.2729e-01 - variance_output_loss: -2.2729e-01 - output_mean_absolute_error: 0.3743 - output_mean_error: -2.7714e-02 - val_loss: -2.8475e-01 - val_output_loss: -2.8480e-01 - val_variance_output_loss: -2.8480e-01 - val_output_mean_absolute_error: 0.3548 - val_output_mean_error: -3.7382e-02\n",
      "Epoch 5/60\n",
      " - 2s - loss: -3.6693e-01 - output_loss: -3.6698e-01 - variance_output_loss: -3.6698e-01 - output_mean_absolute_error: 0.3375 - output_mean_error: -2.0541e-02 - val_loss: -3.8855e-01 - val_output_loss: -3.8859e-01 - val_variance_output_loss: -3.8859e-01 - val_output_mean_absolute_error: 0.3323 - val_output_mean_error: -5.6551e-02\n",
      "Epoch 6/60\n",
      " - 2s - loss: -4.6549e-01 - output_loss: -4.6554e-01 - variance_output_loss: -4.6554e-01 - output_mean_absolute_error: 0.3118 - output_mean_error: -1.8691e-02 - val_loss: -5.0727e-01 - val_output_loss: -5.0732e-01 - val_variance_output_loss: -5.0732e-01 - val_output_mean_absolute_error: 0.2967 - val_output_mean_error: -8.0704e-03\n",
      "Epoch 7/60\n",
      " - 2s - loss: -5.2841e-01 - output_loss: -5.2846e-01 - variance_output_loss: -5.2846e-01 - output_mean_absolute_error: 0.2935 - output_mean_error: -1.7775e-02 - val_loss: -5.2047e-01 - val_output_loss: -5.2052e-01 - val_variance_output_loss: -5.2052e-01 - val_output_mean_absolute_error: 0.3035 - val_output_mean_error: -5.3648e-02\n",
      "Epoch 8/60\n",
      " - 2s - loss: -5.9966e-01 - output_loss: -5.9971e-01 - variance_output_loss: -5.9971e-01 - output_mean_absolute_error: 0.2730 - output_mean_error: -1.2692e-02 - val_loss: -5.8831e-01 - val_output_loss: -5.8836e-01 - val_variance_output_loss: -5.8836e-01 - val_output_mean_absolute_error: 0.2798 - val_output_mean_error: -5.9223e-02\n",
      "Epoch 9/60\n",
      " - 2s - loss: -6.4985e-01 - output_loss: -6.4990e-01 - variance_output_loss: -6.4990e-01 - output_mean_absolute_error: 0.2618 - output_mean_error: -1.5420e-02 - val_loss: -6.7147e-01 - val_output_loss: -6.7152e-01 - val_variance_output_loss: -6.7152e-01 - val_output_mean_absolute_error: 0.2563 - val_output_mean_error: -3.5672e-02\n",
      "Epoch 10/60\n",
      " - 2s - loss: -6.9783e-01 - output_loss: -6.9788e-01 - variance_output_loss: -6.9788e-01 - output_mean_absolute_error: 0.2490 - output_mean_error: -9.9447e-03 - val_loss: -6.8279e-01 - val_output_loss: -6.8284e-01 - val_variance_output_loss: -6.8284e-01 - val_output_mean_absolute_error: 0.2502 - val_output_mean_error: -4.2199e-02\n",
      "Epoch 11/60\n",
      " - 2s - loss: -7.2516e-01 - output_loss: -7.2521e-01 - variance_output_loss: -7.2521e-01 - output_mean_absolute_error: 0.2430 - output_mean_error: -1.4133e-02 - val_loss: -7.4018e-01 - val_output_loss: -7.4023e-01 - val_variance_output_loss: -7.4023e-01 - val_output_mean_absolute_error: 0.2380 - val_output_mean_error: -4.5638e-02\n",
      "Epoch 12/60\n",
      " - 2s - loss: -7.7436e-01 - output_loss: -7.7441e-01 - variance_output_loss: -7.7441e-01 - output_mean_absolute_error: 0.2322 - output_mean_error: -1.2843e-02 - val_loss: -7.4875e-01 - val_output_loss: -7.4880e-01 - val_variance_output_loss: -7.4880e-01 - val_output_mean_absolute_error: 0.2295 - val_output_mean_error: 0.0062\n",
      "Epoch 13/60\n",
      " - 2s - loss: -7.9746e-01 - output_loss: -7.9751e-01 - variance_output_loss: -7.9751e-01 - output_mean_absolute_error: 0.2274 - output_mean_error: -1.3328e-02 - val_loss: -7.1858e-01 - val_output_loss: -7.1863e-01 - val_variance_output_loss: -7.1863e-01 - val_output_mean_absolute_error: 0.2428 - val_output_mean_error: -6.2389e-02\n",
      "Epoch 14/60\n",
      " - 2s - loss: -8.1677e-01 - output_loss: -8.1682e-01 - variance_output_loss: -8.1682e-01 - output_mean_absolute_error: 0.2233 - output_mean_error: -1.0832e-02 - val_loss: -7.5459e-01 - val_output_loss: -7.5464e-01 - val_variance_output_loss: -7.5464e-01 - val_output_mean_absolute_error: 0.2384 - val_output_mean_error: -7.6253e-02\n",
      "Epoch 15/60\n",
      " - 2s - loss: -8.4725e-01 - output_loss: -8.4730e-01 - variance_output_loss: -8.4730e-01 - output_mean_absolute_error: 0.2169 - output_mean_error: -1.2935e-02 - val_loss: -8.1183e-01 - val_output_loss: -8.1188e-01 - val_variance_output_loss: -8.1188e-01 - val_output_mean_absolute_error: 0.2167 - val_output_mean_error: 0.0237\n",
      "Epoch 16/60\n",
      " - 2s - loss: -8.9089e-01 - output_loss: -8.9094e-01 - variance_output_loss: -8.9094e-01 - output_mean_absolute_error: 0.2085 - output_mean_error: -9.2699e-03 - val_loss: -8.4265e-01 - val_output_loss: -8.4270e-01 - val_variance_output_loss: -8.4270e-01 - val_output_mean_absolute_error: 0.2223 - val_output_mean_error: -1.8327e-02\n",
      "Epoch 17/60\n",
      " - 2s - loss: -9.0736e-01 - output_loss: -9.0741e-01 - variance_output_loss: -9.0741e-01 - output_mean_absolute_error: 0.2055 - output_mean_error: -9.4055e-03 - val_loss: -8.8886e-01 - val_output_loss: -8.8891e-01 - val_variance_output_loss: -8.8891e-01 - val_output_mean_absolute_error: 0.2058 - val_output_mean_error: -2.5665e-02\n",
      "Epoch 18/60\n",
      " - 2s - loss: -9.2775e-01 - output_loss: -9.2780e-01 - variance_output_loss: -9.2780e-01 - output_mean_absolute_error: 0.2024 - output_mean_error: -1.0618e-02 - val_loss: -8.9436e-01 - val_output_loss: -8.9441e-01 - val_variance_output_loss: -8.9441e-01 - val_output_mean_absolute_error: 0.2073 - val_output_mean_error: -1.1726e-02\n",
      "Epoch 19/60\n",
      " - 2s - loss: -9.4683e-01 - output_loss: -9.4688e-01 - variance_output_loss: -9.4688e-01 - output_mean_absolute_error: 0.1993 - output_mean_error: -1.0950e-02 - val_loss: -9.0546e-01 - val_output_loss: -9.0551e-01 - val_variance_output_loss: -9.0551e-01 - val_output_mean_absolute_error: 0.2036 - val_output_mean_error: -1.3554e-02\n",
      "Epoch 20/60\n",
      " - 2s - loss: -9.5733e-01 - output_loss: -9.5738e-01 - variance_output_loss: -9.5738e-01 - output_mean_absolute_error: 0.1972 - output_mean_error: -8.8248e-03 - val_loss: -8.9856e-01 - val_output_loss: -8.9862e-01 - val_variance_output_loss: -8.9862e-01 - val_output_mean_absolute_error: 0.2079 - val_output_mean_error: -8.6442e-02\n",
      "Epoch 21/60\n",
      " - 2s - loss: -9.8637e-01 - output_loss: -9.8642e-01 - variance_output_loss: -9.8642e-01 - output_mean_absolute_error: 0.1912 - output_mean_error: -8.5780e-03 - val_loss: -9.2565e-01 - val_output_loss: -9.2570e-01 - val_variance_output_loss: -9.2570e-01 - val_output_mean_absolute_error: 0.2007 - val_output_mean_error: -4.5157e-02\n",
      "Epoch 22/60\n",
      " - 2s - loss: -1.0054e+00 - output_loss: -1.0054e+00 - variance_output_loss: -1.0054e+00 - output_mean_absolute_error: 0.1899 - output_mean_error: -1.1678e-02 - val_loss: -9.7620e-01 - val_output_loss: -9.7625e-01 - val_variance_output_loss: -9.7625e-01 - val_output_mean_absolute_error: 0.2003 - val_output_mean_error: -1.7063e-02\n",
      "Epoch 23/60\n",
      " - 2s - loss: -1.0180e+00 - output_loss: -1.0180e+00 - variance_output_loss: -1.0180e+00 - output_mean_absolute_error: 0.1880 - output_mean_error: -8.2609e-03 - val_loss: -9.0951e-01 - val_output_loss: -9.0956e-01 - val_variance_output_loss: -9.0956e-01 - val_output_mean_absolute_error: 0.2061 - val_output_mean_error: -4.4496e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      " - 2s - loss: -1.0293e+00 - output_loss: -1.0293e+00 - variance_output_loss: -1.0293e+00 - output_mean_absolute_error: 0.1845 - output_mean_error: -6.8864e-03 - val_loss: -9.1224e-01 - val_output_loss: -9.1229e-01 - val_variance_output_loss: -9.1229e-01 - val_output_mean_absolute_error: 0.1973 - val_output_mean_error: -4.2558e-02\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 25/60\n",
      " - 2s - loss: -1.0479e+00 - output_loss: -1.0479e+00 - variance_output_loss: -1.0479e+00 - output_mean_absolute_error: 0.1841 - output_mean_error: -1.1628e-02 - val_loss: -1.0201e+00 - val_output_loss: -1.0201e+00 - val_variance_output_loss: -1.0201e+00 - val_output_mean_absolute_error: 0.1876 - val_output_mean_error: 0.0031\n",
      "Epoch 26/60\n",
      " - 2s - loss: -1.0663e+00 - output_loss: -1.0663e+00 - variance_output_loss: -1.0663e+00 - output_mean_absolute_error: 0.1803 - output_mean_error: -9.6866e-03 - val_loss: -1.0150e+00 - val_output_loss: -1.0151e+00 - val_variance_output_loss: -1.0151e+00 - val_output_mean_absolute_error: 0.1937 - val_output_mean_error: -9.0252e-03\n",
      "Epoch 27/60\n",
      " - 2s - loss: -1.0735e+00 - output_loss: -1.0736e+00 - variance_output_loss: -1.0736e+00 - output_mean_absolute_error: 0.1795 - output_mean_error: -8.5681e-03 - val_loss: -1.0395e+00 - val_output_loss: -1.0396e+00 - val_variance_output_loss: -1.0396e+00 - val_output_mean_absolute_error: 0.1789 - val_output_mean_error: -1.9537e-02\n",
      "Epoch 28/60\n",
      " - 2s - loss: -1.0816e+00 - output_loss: -1.0817e+00 - variance_output_loss: -1.0817e+00 - output_mean_absolute_error: 0.1766 - output_mean_error: -9.4063e-03 - val_loss: -1.0192e+00 - val_output_loss: -1.0192e+00 - val_variance_output_loss: -1.0192e+00 - val_output_mean_absolute_error: 0.1844 - val_output_mean_error: -1.0422e-02\n",
      "Epoch 29/60\n",
      " - 2s - loss: -1.0821e+00 - output_loss: -1.0822e+00 - variance_output_loss: -1.0822e+00 - output_mean_absolute_error: 0.1789 - output_mean_error: -1.0113e-02 - val_loss: -1.0745e+00 - val_output_loss: -1.0746e+00 - val_variance_output_loss: -1.0746e+00 - val_output_mean_absolute_error: 0.1759 - val_output_mean_error: 8.6055e-04\n",
      "Epoch 30/60\n",
      " - 2s - loss: -1.0892e+00 - output_loss: -1.0892e+00 - variance_output_loss: -1.0892e+00 - output_mean_absolute_error: 0.1779 - output_mean_error: -7.4594e-03 - val_loss: -1.0554e+00 - val_output_loss: -1.0554e+00 - val_variance_output_loss: -1.0554e+00 - val_output_mean_absolute_error: 0.1854 - val_output_mean_error: -2.1346e-02\n",
      "Epoch 31/60\n",
      " - 2s - loss: -1.1073e+00 - output_loss: -1.1074e+00 - variance_output_loss: -1.1074e+00 - output_mean_absolute_error: 0.1735 - output_mean_error: -1.0816e-02 - val_loss: -1.0568e+00 - val_output_loss: -1.0569e+00 - val_variance_output_loss: -1.0569e+00 - val_output_mean_absolute_error: 0.1815 - val_output_mean_error: -2.6119e-02\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 32/60\n",
      " - 2s - loss: -1.1052e+00 - output_loss: -1.1053e+00 - variance_output_loss: -1.1053e+00 - output_mean_absolute_error: 0.1743 - output_mean_error: -8.4881e-03 - val_loss: -1.0961e+00 - val_output_loss: -1.0961e+00 - val_variance_output_loss: -1.0961e+00 - val_output_mean_absolute_error: 0.1719 - val_output_mean_error: -8.2183e-03\n",
      "Epoch 33/60\n",
      " - 2s - loss: -1.1049e+00 - output_loss: -1.1049e+00 - variance_output_loss: -1.1049e+00 - output_mean_absolute_error: 0.1749 - output_mean_error: -9.8245e-03 - val_loss: -1.1066e+00 - val_output_loss: -1.1067e+00 - val_variance_output_loss: -1.1067e+00 - val_output_mean_absolute_error: 0.1738 - val_output_mean_error: -9.7245e-03\n",
      "Epoch 34/60\n",
      " - 2s - loss: -1.1154e+00 - output_loss: -1.1154e+00 - variance_output_loss: -1.1154e+00 - output_mean_absolute_error: 0.1749 - output_mean_error: -1.0359e-02 - val_loss: -1.0385e+00 - val_output_loss: -1.0385e+00 - val_variance_output_loss: -1.0385e+00 - val_output_mean_absolute_error: 0.1853 - val_output_mean_error: -2.2988e-02\n",
      "Epoch 35/60\n",
      " - 2s - loss: -1.1242e+00 - output_loss: -1.1243e+00 - variance_output_loss: -1.1243e+00 - output_mean_absolute_error: 0.1727 - output_mean_error: -8.3304e-03 - val_loss: -1.0935e+00 - val_output_loss: -1.0935e+00 - val_variance_output_loss: -1.0935e+00 - val_output_mean_absolute_error: 0.1775 - val_output_mean_error: -2.5112e-02\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 36/60\n",
      " - 2s - loss: -1.1343e+00 - output_loss: -1.1343e+00 - variance_output_loss: -1.1343e+00 - output_mean_absolute_error: 0.1723 - output_mean_error: -1.1414e-02 - val_loss: -1.0773e+00 - val_output_loss: -1.0773e+00 - val_variance_output_loss: -1.0773e+00 - val_output_mean_absolute_error: 0.1776 - val_output_mean_error: -2.1830e-02\n",
      "Epoch 37/60\n",
      " - 2s - loss: -1.1203e+00 - output_loss: -1.1203e+00 - variance_output_loss: -1.1203e+00 - output_mean_absolute_error: 0.1742 - output_mean_error: -7.8693e-03 - val_loss: -1.0320e+00 - val_output_loss: -1.0321e+00 - val_variance_output_loss: -1.0321e+00 - val_output_mean_absolute_error: 0.1834 - val_output_mean_error: -2.6410e-02\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 38/60\n",
      " - 2s - loss: -1.1360e+00 - output_loss: -1.1360e+00 - variance_output_loss: -1.1360e+00 - output_mean_absolute_error: 0.1720 - output_mean_error: -1.3181e-02 - val_loss: -1.0942e+00 - val_output_loss: -1.0942e+00 - val_variance_output_loss: -1.0942e+00 - val_output_mean_absolute_error: 0.1697 - val_output_mean_error: -1.2205e-02\n",
      "Epoch 39/60\n",
      " - 3s - loss: -1.1416e+00 - output_loss: -1.1416e+00 - variance_output_loss: -1.1416e+00 - output_mean_absolute_error: 0.1680 - output_mean_error: -6.1838e-03 - val_loss: -1.0701e+00 - val_output_loss: -1.0702e+00 - val_variance_output_loss: -1.0702e+00 - val_output_mean_absolute_error: 0.1829 - val_output_mean_error: -2.4805e-02\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 40/60\n",
      " - 2s - loss: -1.1331e+00 - output_loss: -1.1331e+00 - variance_output_loss: -1.1331e+00 - output_mean_absolute_error: 0.1709 - output_mean_error: -9.8291e-03 - val_loss: -1.0866e+00 - val_output_loss: -1.0867e+00 - val_variance_output_loss: -1.0867e+00 - val_output_mean_absolute_error: 0.1772 - val_output_mean_error: -2.1289e-02\n",
      "Epoch 41/60\n",
      " - 2s - loss: -1.1424e+00 - output_loss: -1.1424e+00 - variance_output_loss: -1.1424e+00 - output_mean_absolute_error: 0.1699 - output_mean_error: -1.0603e-02 - val_loss: -1.0608e+00 - val_output_loss: -1.0608e+00 - val_variance_output_loss: -1.0608e+00 - val_output_mean_absolute_error: 0.1856 - val_output_mean_error: -2.0839e-02\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 42/60\n",
      " - 2s - loss: -1.1448e+00 - output_loss: -1.1449e+00 - variance_output_loss: -1.1449e+00 - output_mean_absolute_error: 0.1710 - output_mean_error: -9.7425e-03 - val_loss: -1.0632e+00 - val_output_loss: -1.0632e+00 - val_variance_output_loss: -1.0632e+00 - val_output_mean_absolute_error: 0.1849 - val_output_mean_error: -2.0485e-02\n",
      "Epoch 43/60\n",
      " - 2s - loss: -1.1334e+00 - output_loss: -1.1335e+00 - variance_output_loss: -1.1335e+00 - output_mean_absolute_error: 0.1705 - output_mean_error: -8.4269e-03 - val_loss: -1.0760e+00 - val_output_loss: -1.0760e+00 - val_variance_output_loss: -1.0760e+00 - val_output_mean_absolute_error: 0.1777 - val_output_mean_error: -1.7582e-02\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 44/60\n",
      " - 2s - loss: -1.1307e+00 - output_loss: -1.1308e+00 - variance_output_loss: -1.1308e+00 - output_mean_absolute_error: 0.1726 - output_mean_error: -9.7759e-03 - val_loss: -1.0555e+00 - val_output_loss: -1.0556e+00 - val_variance_output_loss: -1.0556e+00 - val_output_mean_absolute_error: 0.1834 - val_output_mean_error: -2.3400e-02\n",
      "Epoch 45/60\n",
      " - 2s - loss: -1.1386e+00 - output_loss: -1.1387e+00 - variance_output_loss: -1.1387e+00 - output_mean_absolute_error: 0.1705 - output_mean_error: -8.4499e-03 - val_loss: -1.0722e+00 - val_output_loss: -1.0723e+00 - val_variance_output_loss: -1.0723e+00 - val_output_mean_absolute_error: 0.1856 - val_output_mean_error: -2.1502e-02\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 46/60\n",
      " - 2s - loss: -1.1406e+00 - output_loss: -1.1407e+00 - variance_output_loss: -1.1407e+00 - output_mean_absolute_error: 0.1699 - output_mean_error: -9.1234e-03 - val_loss: -1.0959e+00 - val_output_loss: -1.0959e+00 - val_variance_output_loss: -1.0959e+00 - val_output_mean_absolute_error: 0.1757 - val_output_mean_error: -2.3133e-02\n",
      "Epoch 47/60\n",
      " - 2s - loss: -1.1416e+00 - output_loss: -1.1416e+00 - variance_output_loss: -1.1416e+00 - output_mean_absolute_error: 0.1706 - output_mean_error: -1.2100e-02 - val_loss: -1.0475e+00 - val_output_loss: -1.0476e+00 - val_variance_output_loss: -1.0476e+00 - val_output_mean_absolute_error: 0.1944 - val_output_mean_error: -3.4219e-02\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 48/60\n",
      " - 2s - loss: -1.1421e+00 - output_loss: -1.1421e+00 - variance_output_loss: -1.1421e+00 - output_mean_absolute_error: 0.1702 - output_mean_error: -1.0724e-02 - val_loss: -1.1291e+00 - val_output_loss: -1.1292e+00 - val_variance_output_loss: -1.1292e+00 - val_output_mean_absolute_error: 0.1671 - val_output_mean_error: -1.6242e-02\n",
      "Epoch 49/60\n",
      " - 2s - loss: -1.1394e+00 - output_loss: -1.1395e+00 - variance_output_loss: -1.1395e+00 - output_mean_absolute_error: 0.1700 - output_mean_error: -9.7056e-03 - val_loss: -1.0756e+00 - val_output_loss: -1.0757e+00 - val_variance_output_loss: -1.0757e+00 - val_output_mean_absolute_error: 0.1781 - val_output_mean_error: -1.3530e-02\n",
      "Epoch 50/60\n",
      " - 2s - loss: -1.1377e+00 - output_loss: -1.1378e+00 - variance_output_loss: -1.1378e+00 - output_mean_absolute_error: 0.1707 - output_mean_error: -1.0127e-02 - val_loss: -1.0862e+00 - val_output_loss: -1.0863e+00 - val_variance_output_loss: -1.0863e+00 - val_output_mean_absolute_error: 0.1813 - val_output_mean_error: -2.8924e-02\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 51/60\n",
      " - 2s - loss: -1.1386e+00 - output_loss: -1.1387e+00 - variance_output_loss: -1.1387e+00 - output_mean_absolute_error: 0.1701 - output_mean_error: -1.1188e-02 - val_loss: -1.1080e+00 - val_output_loss: -1.1080e+00 - val_variance_output_loss: -1.1080e+00 - val_output_mean_absolute_error: 0.1775 - val_output_mean_error: -1.9039e-02\n",
      "Epoch 52/60\n",
      " - 2s - loss: -1.1410e+00 - output_loss: -1.1411e+00 - variance_output_loss: -1.1411e+00 - output_mean_absolute_error: 0.1709 - output_mean_error: -8.6073e-03 - val_loss: -1.1344e+00 - val_output_loss: -1.1345e+00 - val_variance_output_loss: -1.1345e+00 - val_output_mean_absolute_error: 0.1626 - val_output_mean_error: -1.3311e-02\n",
      "Epoch 53/60\n",
      " - 2s - loss: -1.1429e+00 - output_loss: -1.1430e+00 - variance_output_loss: -1.1430e+00 - output_mean_absolute_error: 0.1703 - output_mean_error: -8.6400e-03 - val_loss: -1.0768e+00 - val_output_loss: -1.0768e+00 - val_variance_output_loss: -1.0768e+00 - val_output_mean_absolute_error: 0.1848 - val_output_mean_error: -2.0573e-02\n",
      "Epoch 54/60\n",
      " - 2s - loss: -1.1356e+00 - output_loss: -1.1356e+00 - variance_output_loss: -1.1356e+00 - output_mean_absolute_error: 0.1718 - output_mean_error: -7.7087e-03 - val_loss: -1.0812e+00 - val_output_loss: -1.0813e+00 - val_variance_output_loss: -1.0813e+00 - val_output_mean_absolute_error: 0.1823 - val_output_mean_error: -2.6663e-02\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 55/60\n",
      " - 2s - loss: -1.1396e+00 - output_loss: -1.1397e+00 - variance_output_loss: -1.1397e+00 - output_mean_absolute_error: 0.1714 - output_mean_error: -1.1278e-02 - val_loss: -1.0982e+00 - val_output_loss: -1.0982e+00 - val_variance_output_loss: -1.0982e+00 - val_output_mean_absolute_error: 0.1751 - val_output_mean_error: -1.7232e-02\n",
      "Epoch 56/60\n",
      " - 2s - loss: -1.1417e+00 - output_loss: -1.1417e+00 - variance_output_loss: -1.1417e+00 - output_mean_absolute_error: 0.1687 - output_mean_error: -6.9109e-03 - val_loss: -1.0589e+00 - val_output_loss: -1.0590e+00 - val_variance_output_loss: -1.0590e+00 - val_output_mean_absolute_error: 0.1796 - val_output_mean_error: -2.4753e-02\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 57/60\n",
      " - 2s - loss: -1.1460e+00 - output_loss: -1.1460e+00 - variance_output_loss: -1.1460e+00 - output_mean_absolute_error: 0.1698 - output_mean_error: -9.2753e-03 - val_loss: -1.0561e+00 - val_output_loss: -1.0561e+00 - val_variance_output_loss: -1.0561e+00 - val_output_mean_absolute_error: 0.1748 - val_output_mean_error: -1.7296e-02\n",
      "Epoch 58/60\n",
      " - 2s - loss: -1.1471e+00 - output_loss: -1.1472e+00 - variance_output_loss: -1.1472e+00 - output_mean_absolute_error: 0.1686 - output_mean_error: -8.6204e-03 - val_loss: -1.0804e+00 - val_output_loss: -1.0804e+00 - val_variance_output_loss: -1.0804e+00 - val_output_mean_absolute_error: 0.1802 - val_output_mean_error: -3.2713e-02\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 59/60\n",
      " - 2s - loss: -1.1316e+00 - output_loss: -1.1316e+00 - variance_output_loss: -1.1316e+00 - output_mean_absolute_error: 0.1730 - output_mean_error: -9.5940e-03 - val_loss: -1.1079e+00 - val_output_loss: -1.1080e+00 - val_variance_output_loss: -1.1080e+00 - val_output_mean_absolute_error: 0.1706 - val_output_mean_error: -1.1242e-02\n",
      "Epoch 60/60\n",
      " - 2s - loss: -1.1411e+00 - output_loss: -1.1412e+00 - variance_output_loss: -1.1412e+00 - output_mean_absolute_error: 0.1700 - output_mean_error: -1.0534e-02 - val_loss: -1.0914e+00 - val_output_loss: -1.0914e+00 - val_variance_output_loss: -1.0914e+00 - val_output_mean_absolute_error: 0.1681 - val_output_mean_error: -1.2959e-02\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Completed Training, 145.63s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_12_5/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_12_5'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/8), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 1879, Number of Validation Data: 208\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 7s - loss: 0.4630 - output_loss: 0.4630 - variance_output_loss: 0.4630 - output_mean_absolute_error: 0.6878 - output_mean_error: -1.6965e-02 - val_loss: 0.4029 - val_output_loss: 0.4028 - val_variance_output_loss: 0.4028 - val_output_mean_absolute_error: 0.6419 - val_output_mean_error: 0.0384\n",
      "Epoch 2/60\n",
      " - 1s - loss: 0.3730 - output_loss: 0.3730 - variance_output_loss: 0.3730 - output_mean_absolute_error: 0.6413 - output_mean_error: 0.0092 - val_loss: 0.3034 - val_output_loss: 0.3033 - val_variance_output_loss: 0.3033 - val_output_mean_absolute_error: 0.6012 - val_output_mean_error: 0.0455\n",
      "Epoch 3/60\n",
      " - 1s - loss: 0.3309 - output_loss: 0.3309 - variance_output_loss: 0.3309 - output_mean_absolute_error: 0.6127 - output_mean_error: -3.6293e-02 - val_loss: 0.3209 - val_output_loss: 0.3209 - val_variance_output_loss: 0.3209 - val_output_mean_absolute_error: 0.5756 - val_output_mean_error: -9.1030e-02\n",
      "Epoch 4/60\n",
      " - 1s - loss: 0.2151 - output_loss: 0.2151 - variance_output_loss: 0.2151 - output_mean_absolute_error: 0.5389 - output_mean_error: -8.2430e-02 - val_loss: 0.0585 - val_output_loss: 0.0584 - val_variance_output_loss: 0.0584 - val_output_mean_absolute_error: 0.4666 - val_output_mean_error: -4.0060e-02\n",
      "Epoch 5/60\n",
      " - 1s - loss: 0.0853 - output_loss: 0.0853 - variance_output_loss: 0.0853 - output_mean_absolute_error: 0.4846 - output_mean_error: -7.3145e-02 - val_loss: 0.0692 - val_output_loss: 0.0691 - val_variance_output_loss: 0.0691 - val_output_mean_absolute_error: 0.4714 - val_output_mean_error: -1.4367e-01\n",
      "Epoch 6/60\n",
      " - 1s - loss: -4.5025e-02 - output_loss: -4.5071e-02 - variance_output_loss: -4.5071e-02 - output_mean_absolute_error: 0.4328 - output_mean_error: -8.2231e-02 - val_loss: -4.9256e-02 - val_output_loss: -4.9301e-02 - val_variance_output_loss: -4.9301e-02 - val_output_mean_absolute_error: 0.4292 - val_output_mean_error: -9.6950e-02\n",
      "Epoch 7/60\n",
      " - 1s - loss: -1.2890e-01 - output_loss: -1.2895e-01 - variance_output_loss: -1.2895e-01 - output_mean_absolute_error: 0.4042 - output_mean_error: -8.3693e-02 - val_loss: -1.4110e-01 - val_output_loss: -1.4115e-01 - val_variance_output_loss: -1.4115e-01 - val_output_mean_absolute_error: 0.3979 - val_output_mean_error: -8.8111e-02\n",
      "Epoch 8/60\n",
      " - 1s - loss: -2.2688e-01 - output_loss: -2.2693e-01 - variance_output_loss: -2.2693e-01 - output_mean_absolute_error: 0.3689 - output_mean_error: -6.0569e-02 - val_loss: -2.6349e-01 - val_output_loss: -2.6353e-01 - val_variance_output_loss: -2.6353e-01 - val_output_mean_absolute_error: 0.3524 - val_output_mean_error: -3.8541e-02\n",
      "Epoch 9/60\n",
      " - 1s - loss: -3.0322e-01 - output_loss: -3.0326e-01 - variance_output_loss: -3.0326e-01 - output_mean_absolute_error: 0.3498 - output_mean_error: -5.7888e-02 - val_loss: -3.1359e-01 - val_output_loss: -3.1363e-01 - val_variance_output_loss: -3.1363e-01 - val_output_mean_absolute_error: 0.3345 - val_output_mean_error: -4.0748e-02\n",
      "Epoch 10/60\n",
      " - 1s - loss: -3.5619e-01 - output_loss: -3.5624e-01 - variance_output_loss: -3.5624e-01 - output_mean_absolute_error: 0.3326 - output_mean_error: -4.3836e-02 - val_loss: -3.3867e-01 - val_output_loss: -3.3872e-01 - val_variance_output_loss: -3.3872e-01 - val_output_mean_absolute_error: 0.3351 - val_output_mean_error: -6.8089e-02\n",
      "Epoch 11/60\n",
      " - 1s - loss: -4.1278e-01 - output_loss: -4.1283e-01 - variance_output_loss: -4.1283e-01 - output_mean_absolute_error: 0.3224 - output_mean_error: -5.1028e-02 - val_loss: -4.0815e-01 - val_output_loss: -4.0819e-01 - val_variance_output_loss: -4.0819e-01 - val_output_mean_absolute_error: 0.3133 - val_output_mean_error: -3.4107e-02\n",
      "Epoch 12/60\n",
      " - 1s - loss: -4.6738e-01 - output_loss: -4.6742e-01 - variance_output_loss: -4.6742e-01 - output_mean_absolute_error: 0.3023 - output_mean_error: -3.6269e-02 - val_loss: -4.6034e-01 - val_output_loss: -4.6039e-01 - val_variance_output_loss: -4.6039e-01 - val_output_mean_absolute_error: 0.3045 - val_output_mean_error: -9.4840e-03\n",
      "Epoch 13/60\n",
      " - 1s - loss: -4.9838e-01 - output_loss: -4.9843e-01 - variance_output_loss: -4.9843e-01 - output_mean_absolute_error: 0.2997 - output_mean_error: -4.2958e-02 - val_loss: -4.4332e-01 - val_output_loss: -4.4337e-01 - val_variance_output_loss: -4.4337e-01 - val_output_mean_absolute_error: 0.3238 - val_output_mean_error: -3.7109e-02\n",
      "Epoch 14/60\n",
      " - 1s - loss: -5.5177e-01 - output_loss: -5.5182e-01 - variance_output_loss: -5.5182e-01 - output_mean_absolute_error: 0.2846 - output_mean_error: -3.6495e-02 - val_loss: -5.0153e-01 - val_output_loss: -5.0157e-01 - val_variance_output_loss: -5.0157e-01 - val_output_mean_absolute_error: 0.3016 - val_output_mean_error: -6.3861e-02\n",
      "Epoch 15/60\n",
      " - 1s - loss: -5.6646e-01 - output_loss: -5.6651e-01 - variance_output_loss: -5.6651e-01 - output_mean_absolute_error: 0.2844 - output_mean_error: -4.1555e-02 - val_loss: -5.2089e-01 - val_output_loss: -5.2094e-01 - val_variance_output_loss: -5.2094e-01 - val_output_mean_absolute_error: 0.2922 - val_output_mean_error: 0.0057\n",
      "Epoch 16/60\n",
      " - 1s - loss: -5.9729e-01 - output_loss: -5.9734e-01 - variance_output_loss: -5.9734e-01 - output_mean_absolute_error: 0.2738 - output_mean_error: -3.1151e-02 - val_loss: -5.8708e-01 - val_output_loss: -5.8713e-01 - val_variance_output_loss: -5.8713e-01 - val_output_mean_absolute_error: 0.2836 - val_output_mean_error: -6.7759e-02\n",
      "Epoch 17/60\n",
      " - 1s - loss: -6.2803e-01 - output_loss: -6.2807e-01 - variance_output_loss: -6.2807e-01 - output_mean_absolute_error: 0.2691 - output_mean_error: -3.6872e-02 - val_loss: -5.9784e-01 - val_output_loss: -5.9789e-01 - val_variance_output_loss: -5.9789e-01 - val_output_mean_absolute_error: 0.2712 - val_output_mean_error: -1.8966e-02\n",
      "Epoch 18/60\n",
      " - 1s - loss: -6.6489e-01 - output_loss: -6.6493e-01 - variance_output_loss: -6.6493e-01 - output_mean_absolute_error: 0.2581 - output_mean_error: -3.4598e-02 - val_loss: -6.0518e-01 - val_output_loss: -6.0523e-01 - val_variance_output_loss: -6.0523e-01 - val_output_mean_absolute_error: 0.2725 - val_output_mean_error: -5.3479e-02\n",
      "Epoch 19/60\n",
      " - 1s - loss: -6.9343e-01 - output_loss: -6.9347e-01 - variance_output_loss: -6.9347e-01 - output_mean_absolute_error: 0.2547 - output_mean_error: -3.4226e-02 - val_loss: -6.6675e-01 - val_output_loss: -6.6680e-01 - val_variance_output_loss: -6.6680e-01 - val_output_mean_absolute_error: 0.2527 - val_output_mean_error: -4.1324e-02\n",
      "Epoch 20/60\n",
      " - 1s - loss: -7.2535e-01 - output_loss: -7.2540e-01 - variance_output_loss: -7.2540e-01 - output_mean_absolute_error: 0.2428 - output_mean_error: -2.8086e-02 - val_loss: -7.0672e-01 - val_output_loss: -7.0677e-01 - val_variance_output_loss: -7.0677e-01 - val_output_mean_absolute_error: 0.2493 - val_output_mean_error: -9.6192e-03\n",
      "Epoch 21/60\n",
      " - 1s - loss: -7.1645e-01 - output_loss: -7.1650e-01 - variance_output_loss: -7.1650e-01 - output_mean_absolute_error: 0.2477 - output_mean_error: -3.1484e-02 - val_loss: -7.2228e-01 - val_output_loss: -7.2233e-01 - val_variance_output_loss: -7.2233e-01 - val_output_mean_absolute_error: 0.2471 - val_output_mean_error: -6.0309e-02\n",
      "Epoch 22/60\n",
      " - 1s - loss: -7.4614e-01 - output_loss: -7.4619e-01 - variance_output_loss: -7.4619e-01 - output_mean_absolute_error: 0.2377 - output_mean_error: -2.7407e-02 - val_loss: -7.0088e-01 - val_output_loss: -7.0093e-01 - val_variance_output_loss: -7.0093e-01 - val_output_mean_absolute_error: 0.2446 - val_output_mean_error: 0.0049\n",
      "Epoch 23/60\n",
      " - 1s - loss: -7.7467e-01 - output_loss: -7.7472e-01 - variance_output_loss: -7.7472e-01 - output_mean_absolute_error: 0.2352 - output_mean_error: -3.0578e-02 - val_loss: -7.2213e-01 - val_output_loss: -7.2218e-01 - val_variance_output_loss: -7.2218e-01 - val_output_mean_absolute_error: 0.2524 - val_output_mean_error: -4.4718e-02\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 24/60\n",
      " - 1s - loss: -8.0586e-01 - output_loss: -8.0591e-01 - variance_output_loss: -8.0591e-01 - output_mean_absolute_error: 0.2264 - output_mean_error: -2.5595e-02 - val_loss: -7.9753e-01 - val_output_loss: -7.9758e-01 - val_variance_output_loss: -7.9758e-01 - val_output_mean_absolute_error: 0.2227 - val_output_mean_error: -2.6394e-02\n",
      "Epoch 25/60\n",
      " - 1s - loss: -8.0176e-01 - output_loss: -8.0181e-01 - variance_output_loss: -8.0181e-01 - output_mean_absolute_error: 0.2302 - output_mean_error: -3.3232e-02 - val_loss: -7.7099e-01 - val_output_loss: -7.7104e-01 - val_variance_output_loss: -7.7104e-01 - val_output_mean_absolute_error: 0.2351 - val_output_mean_error: -1.9732e-02\n",
      "Epoch 26/60\n",
      " - 1s - loss: -8.1148e-01 - output_loss: -8.1153e-01 - variance_output_loss: -8.1153e-01 - output_mean_absolute_error: 0.2267 - output_mean_error: -2.5745e-02 - val_loss: -7.6193e-01 - val_output_loss: -7.6198e-01 - val_variance_output_loss: -7.6198e-01 - val_output_mean_absolute_error: 0.2386 - val_output_mean_error: -3.6202e-02\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 27/60\n",
      " - 1s - loss: -8.3753e-01 - output_loss: -8.3758e-01 - variance_output_loss: -8.3758e-01 - output_mean_absolute_error: 0.2218 - output_mean_error: -2.6462e-02 - val_loss: -7.6361e-01 - val_output_loss: -7.6367e-01 - val_variance_output_loss: -7.6367e-01 - val_output_mean_absolute_error: 0.2336 - val_output_mean_error: -5.5672e-02\n",
      "Epoch 28/60\n",
      " - 1s - loss: -8.2559e-01 - output_loss: -8.2565e-01 - variance_output_loss: -8.2565e-01 - output_mean_absolute_error: 0.2232 - output_mean_error: -2.6512e-02 - val_loss: -7.8509e-01 - val_output_loss: -7.8514e-01 - val_variance_output_loss: -7.8514e-01 - val_output_mean_absolute_error: 0.2306 - val_output_mean_error: -3.3274e-02\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 29/60\n",
      " - 1s - loss: -8.3776e-01 - output_loss: -8.3781e-01 - variance_output_loss: -8.3781e-01 - output_mean_absolute_error: 0.2222 - output_mean_error: -2.8711e-02 - val_loss: -7.6206e-01 - val_output_loss: -7.6211e-01 - val_variance_output_loss: -7.6211e-01 - val_output_mean_absolute_error: 0.2364 - val_output_mean_error: -3.0377e-02\n",
      "Epoch 30/60\n",
      " - 1s - loss: -8.5056e-01 - output_loss: -8.5061e-01 - variance_output_loss: -8.5061e-01 - output_mean_absolute_error: 0.2196 - output_mean_error: -2.7410e-02 - val_loss: -7.9205e-01 - val_output_loss: -7.9210e-01 - val_variance_output_loss: -7.9210e-01 - val_output_mean_absolute_error: 0.2253 - val_output_mean_error: -4.6637e-02\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 31/60\n",
      " - 1s - loss: -8.4316e-01 - output_loss: -8.4321e-01 - variance_output_loss: -8.4321e-01 - output_mean_absolute_error: 0.2203 - output_mean_error: -2.8391e-02 - val_loss: -7.3924e-01 - val_output_loss: -7.3929e-01 - val_variance_output_loss: -7.3929e-01 - val_output_mean_absolute_error: 0.2422 - val_output_mean_error: -2.5078e-02\n",
      "Epoch 32/60\n",
      " - 1s - loss: -8.5373e-01 - output_loss: -8.5378e-01 - variance_output_loss: -8.5378e-01 - output_mean_absolute_error: 0.2186 - output_mean_error: -2.7113e-02 - val_loss: -7.9824e-01 - val_output_loss: -7.9829e-01 - val_variance_output_loss: -7.9829e-01 - val_output_mean_absolute_error: 0.2318 - val_output_mean_error: -3.2333e-02\n",
      "Epoch 33/60\n",
      " - 1s - loss: -8.4921e-01 - output_loss: -8.4926e-01 - variance_output_loss: -8.4926e-01 - output_mean_absolute_error: 0.2221 - output_mean_error: -2.7227e-02 - val_loss: -7.4529e-01 - val_output_loss: -7.4534e-01 - val_variance_output_loss: -7.4534e-01 - val_output_mean_absolute_error: 0.2314 - val_output_mean_error: -8.3097e-03\n",
      "Epoch 34/60\n",
      " - 1s - loss: -8.5486e-01 - output_loss: -8.5491e-01 - variance_output_loss: -8.5491e-01 - output_mean_absolute_error: 0.2175 - output_mean_error: -2.6315e-02 - val_loss: -7.6045e-01 - val_output_loss: -7.6050e-01 - val_variance_output_loss: -7.6050e-01 - val_output_mean_absolute_error: 0.2395 - val_output_mean_error: -5.2022e-02\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 35/60\n",
      " - 1s - loss: -8.4980e-01 - output_loss: -8.4985e-01 - variance_output_loss: -8.4985e-01 - output_mean_absolute_error: 0.2191 - output_mean_error: -2.6480e-02 - val_loss: -8.0367e-01 - val_output_loss: -8.0372e-01 - val_variance_output_loss: -8.0372e-01 - val_output_mean_absolute_error: 0.2304 - val_output_mean_error: 0.0013\n",
      "Epoch 36/60\n",
      " - 1s - loss: -8.5827e-01 - output_loss: -8.5832e-01 - variance_output_loss: -8.5832e-01 - output_mean_absolute_error: 0.2175 - output_mean_error: -2.6187e-02 - val_loss: -8.0854e-01 - val_output_loss: -8.0859e-01 - val_variance_output_loss: -8.0859e-01 - val_output_mean_absolute_error: 0.2262 - val_output_mean_error: -4.6407e-02\n",
      "Epoch 37/60\n",
      " - 1s - loss: -8.4509e-01 - output_loss: -8.4514e-01 - variance_output_loss: -8.4514e-01 - output_mean_absolute_error: 0.2209 - output_mean_error: -2.9792e-02 - val_loss: -8.0884e-01 - val_output_loss: -8.0889e-01 - val_variance_output_loss: -8.0889e-01 - val_output_mean_absolute_error: 0.2224 - val_output_mean_error: -1.0824e-02\n",
      "Epoch 38/60\n",
      " - 1s - loss: -8.5948e-01 - output_loss: -8.5953e-01 - variance_output_loss: -8.5953e-01 - output_mean_absolute_error: 0.2159 - output_mean_error: -2.4522e-02 - val_loss: -8.4230e-01 - val_output_loss: -8.4235e-01 - val_variance_output_loss: -8.4235e-01 - val_output_mean_absolute_error: 0.2200 - val_output_mean_error: -2.7907e-02\n",
      "Epoch 39/60\n",
      " - 1s - loss: -8.5081e-01 - output_loss: -8.5086e-01 - variance_output_loss: -8.5086e-01 - output_mean_absolute_error: 0.2200 - output_mean_error: -2.6984e-02 - val_loss: -7.8203e-01 - val_output_loss: -7.8208e-01 - val_variance_output_loss: -7.8208e-01 - val_output_mean_absolute_error: 0.2346 - val_output_mean_error: -3.0000e-02\n",
      "Epoch 40/60\n",
      " - 1s - loss: -8.6053e-01 - output_loss: -8.6058e-01 - variance_output_loss: -8.6058e-01 - output_mean_absolute_error: 0.2188 - output_mean_error: -2.8619e-02 - val_loss: -8.1763e-01 - val_output_loss: -8.1768e-01 - val_variance_output_loss: -8.1768e-01 - val_output_mean_absolute_error: 0.2273 - val_output_mean_error: -3.4445e-02\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 41/60\n",
      " - 1s - loss: -8.7455e-01 - output_loss: -8.7460e-01 - variance_output_loss: -8.7460e-01 - output_mean_absolute_error: 0.2147 - output_mean_error: -2.2479e-02 - val_loss: -7.8404e-01 - val_output_loss: -7.8409e-01 - val_variance_output_loss: -7.8409e-01 - val_output_mean_absolute_error: 0.2282 - val_output_mean_error: -3.3316e-02\n",
      "Epoch 42/60\n",
      " - 1s - loss: -8.6116e-01 - output_loss: -8.6121e-01 - variance_output_loss: -8.6121e-01 - output_mean_absolute_error: 0.2181 - output_mean_error: -2.7682e-02 - val_loss: -8.0213e-01 - val_output_loss: -8.0218e-01 - val_variance_output_loss: -8.0218e-01 - val_output_mean_absolute_error: 0.2303 - val_output_mean_error: -3.3412e-02\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 43/60\n",
      " - 1s - loss: -8.5276e-01 - output_loss: -8.5281e-01 - variance_output_loss: -8.5281e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.7068e-02 - val_loss: -8.1750e-01 - val_output_loss: -8.1755e-01 - val_variance_output_loss: -8.1755e-01 - val_output_mean_absolute_error: 0.2254 - val_output_mean_error: -3.0011e-02\n",
      "Epoch 44/60\n",
      " - 1s - loss: -8.5653e-01 - output_loss: -8.5658e-01 - variance_output_loss: -8.5658e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.8189e-02 - val_loss: -7.9744e-01 - val_output_loss: -7.9749e-01 - val_variance_output_loss: -7.9749e-01 - val_output_mean_absolute_error: 0.2356 - val_output_mean_error: -3.2064e-02\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 45/60\n",
      " - 1s - loss: -8.6308e-01 - output_loss: -8.6313e-01 - variance_output_loss: -8.6313e-01 - output_mean_absolute_error: 0.2163 - output_mean_error: -2.2857e-02 - val_loss: -8.0846e-01 - val_output_loss: -8.0851e-01 - val_variance_output_loss: -8.0851e-01 - val_output_mean_absolute_error: 0.2250 - val_output_mean_error: -2.9214e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/60\n",
      " - 1s - loss: -8.5248e-01 - output_loss: -8.5253e-01 - variance_output_loss: -8.5253e-01 - output_mean_absolute_error: 0.2189 - output_mean_error: -2.8606e-02 - val_loss: -7.8174e-01 - val_output_loss: -7.8179e-01 - val_variance_output_loss: -7.8179e-01 - val_output_mean_absolute_error: 0.2349 - val_output_mean_error: -2.2638e-02\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 47/60\n",
      " - 1s - loss: -8.5219e-01 - output_loss: -8.5224e-01 - variance_output_loss: -8.5224e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.4259e-02 - val_loss: -8.4288e-01 - val_output_loss: -8.4293e-01 - val_variance_output_loss: -8.4293e-01 - val_output_mean_absolute_error: 0.2190 - val_output_mean_error: -2.6133e-02\n",
      "Epoch 48/60\n",
      " - 1s - loss: -8.6340e-01 - output_loss: -8.6346e-01 - variance_output_loss: -8.6346e-01 - output_mean_absolute_error: 0.2176 - output_mean_error: -3.0914e-02 - val_loss: -7.9581e-01 - val_output_loss: -7.9586e-01 - val_variance_output_loss: -7.9586e-01 - val_output_mean_absolute_error: 0.2273 - val_output_mean_error: -1.1548e-02\n",
      "Epoch 49/60\n",
      " - 1s - loss: -8.4937e-01 - output_loss: -8.4943e-01 - variance_output_loss: -8.4943e-01 - output_mean_absolute_error: 0.2205 - output_mean_error: -3.0583e-02 - val_loss: -7.9666e-01 - val_output_loss: -7.9671e-01 - val_variance_output_loss: -7.9671e-01 - val_output_mean_absolute_error: 0.2322 - val_output_mean_error: -3.8083e-02\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 50/60\n",
      " - 1s - loss: -8.6280e-01 - output_loss: -8.6285e-01 - variance_output_loss: -8.6285e-01 - output_mean_absolute_error: 0.2165 - output_mean_error: -2.4932e-02 - val_loss: -7.8482e-01 - val_output_loss: -7.8488e-01 - val_variance_output_loss: -7.8488e-01 - val_output_mean_absolute_error: 0.2352 - val_output_mean_error: -2.4251e-02\n",
      "Epoch 51/60\n",
      " - 1s - loss: -8.6471e-01 - output_loss: -8.6476e-01 - variance_output_loss: -8.6476e-01 - output_mean_absolute_error: 0.2166 - output_mean_error: -2.6203e-02 - val_loss: -7.8671e-01 - val_output_loss: -7.8676e-01 - val_variance_output_loss: -7.8676e-01 - val_output_mean_absolute_error: 0.2257 - val_output_mean_error: -2.2793e-02\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 52/60\n",
      " - 1s - loss: -8.6474e-01 - output_loss: -8.6479e-01 - variance_output_loss: -8.6479e-01 - output_mean_absolute_error: 0.2173 - output_mean_error: -2.9252e-02 - val_loss: -7.5581e-01 - val_output_loss: -7.5586e-01 - val_variance_output_loss: -7.5586e-01 - val_output_mean_absolute_error: 0.2368 - val_output_mean_error: -3.0232e-02\n",
      "Epoch 53/60\n",
      " - 1s - loss: -8.6116e-01 - output_loss: -8.6121e-01 - variance_output_loss: -8.6121e-01 - output_mean_absolute_error: 0.2169 - output_mean_error: -2.4582e-02 - val_loss: -8.2189e-01 - val_output_loss: -8.2194e-01 - val_variance_output_loss: -8.2194e-01 - val_output_mean_absolute_error: 0.2193 - val_output_mean_error: -2.0764e-02\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 54/60\n",
      " - 1s - loss: -8.6539e-01 - output_loss: -8.6544e-01 - variance_output_loss: -8.6544e-01 - output_mean_absolute_error: 0.2174 - output_mean_error: -2.9423e-02 - val_loss: -8.2636e-01 - val_output_loss: -8.2641e-01 - val_variance_output_loss: -8.2641e-01 - val_output_mean_absolute_error: 0.2195 - val_output_mean_error: -2.7064e-02\n",
      "Epoch 55/60\n",
      " - 1s - loss: -8.4854e-01 - output_loss: -8.4859e-01 - variance_output_loss: -8.4859e-01 - output_mean_absolute_error: 0.2185 - output_mean_error: -2.4577e-02 - val_loss: -8.0316e-01 - val_output_loss: -8.0321e-01 - val_variance_output_loss: -8.0321e-01 - val_output_mean_absolute_error: 0.2347 - val_output_mean_error: -2.4151e-02\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 56/60\n",
      " - 1s - loss: -8.4959e-01 - output_loss: -8.4964e-01 - variance_output_loss: -8.4964e-01 - output_mean_absolute_error: 0.2189 - output_mean_error: -2.8588e-02 - val_loss: -8.1500e-01 - val_output_loss: -8.1505e-01 - val_variance_output_loss: -8.1505e-01 - val_output_mean_absolute_error: 0.2267 - val_output_mean_error: -3.3707e-02\n",
      "Epoch 57/60\n",
      " - 1s - loss: -8.7571e-01 - output_loss: -8.7576e-01 - variance_output_loss: -8.7576e-01 - output_mean_absolute_error: 0.2126 - output_mean_error: -2.3711e-02 - val_loss: -7.7255e-01 - val_output_loss: -7.7260e-01 - val_variance_output_loss: -7.7260e-01 - val_output_mean_absolute_error: 0.2360 - val_output_mean_error: -2.8271e-02\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 58/60\n",
      " - 1s - loss: -8.5666e-01 - output_loss: -8.5671e-01 - variance_output_loss: -8.5671e-01 - output_mean_absolute_error: 0.2197 - output_mean_error: -2.4424e-02 - val_loss: -7.8550e-01 - val_output_loss: -7.8555e-01 - val_variance_output_loss: -7.8555e-01 - val_output_mean_absolute_error: 0.2327 - val_output_mean_error: -2.9433e-02\n",
      "Epoch 59/60\n",
      " - 1s - loss: -8.5500e-01 - output_loss: -8.5505e-01 - variance_output_loss: -8.5505e-01 - output_mean_absolute_error: 0.2182 - output_mean_error: -2.6217e-02 - val_loss: -8.1519e-01 - val_output_loss: -8.1524e-01 - val_variance_output_loss: -8.1524e-01 - val_output_mean_absolute_error: 0.2181 - val_output_mean_error: -3.0092e-02\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 60/60\n",
      " - 1s - loss: -8.5664e-01 - output_loss: -8.5669e-01 - variance_output_loss: -8.5669e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.9202e-02 - val_loss: -8.5742e-01 - val_output_loss: -8.5747e-01 - val_variance_output_loss: -8.5747e-01 - val_output_mean_absolute_error: 0.2175 - val_output_mean_error: -1.8125e-02\n",
      "Completed Training, 79.97s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_model_fixed_6_25/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_6_25'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/16), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 939, Number of Validation Data: 104\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 6s - loss: 0.4819 - output_loss: 0.4818 - variance_output_loss: 0.4818 - output_mean_absolute_error: 0.7017 - output_mean_error: -1.3248e-02 - val_loss: 0.3123 - val_output_loss: 0.3123 - val_variance_output_loss: 0.3123 - val_output_mean_absolute_error: 0.5688 - val_output_mean_error: 0.1058\n",
      "Epoch 2/60\n",
      " - 1s - loss: 0.4943 - output_loss: 0.4943 - variance_output_loss: 0.4943 - output_mean_absolute_error: 0.7097 - output_mean_error: -3.2834e-02 - val_loss: 0.3214 - val_output_loss: 0.3214 - val_variance_output_loss: 0.3214 - val_output_mean_absolute_error: 0.5853 - val_output_mean_error: 0.1485\n",
      "Epoch 3/60\n",
      " - 1s - loss: 0.4216 - output_loss: 0.4216 - variance_output_loss: 0.4216 - output_mean_absolute_error: 0.6613 - output_mean_error: 2.8559e-04 - val_loss: 0.2772 - val_output_loss: 0.2772 - val_variance_output_loss: 0.2772 - val_output_mean_absolute_error: 0.5943 - val_output_mean_error: 0.0958\n",
      "Epoch 4/60\n",
      " - 1s - loss: 0.4263 - output_loss: 0.4262 - variance_output_loss: 0.4262 - output_mean_absolute_error: 0.6677 - output_mean_error: -1.3007e-02 - val_loss: 0.3557 - val_output_loss: 0.3557 - val_variance_output_loss: 0.3557 - val_output_mean_absolute_error: 0.6158 - val_output_mean_error: 0.1037\n",
      "Epoch 5/60\n",
      " - 1s - loss: 0.4606 - output_loss: 0.4605 - variance_output_loss: 0.4605 - output_mean_absolute_error: 0.6763 - output_mean_error: -2.5260e-02 - val_loss: 0.2662 - val_output_loss: 0.2662 - val_variance_output_loss: 0.2662 - val_output_mean_absolute_error: 0.5593 - val_output_mean_error: 0.0353\n",
      "Epoch 6/60\n",
      " - 1s - loss: 0.3704 - output_loss: 0.3704 - variance_output_loss: 0.3704 - output_mean_absolute_error: 0.6203 - output_mean_error: -2.9312e-04 - val_loss: 0.2248 - val_output_loss: 0.2248 - val_variance_output_loss: 0.2248 - val_output_mean_absolute_error: 0.5530 - val_output_mean_error: 0.0982\n",
      "Epoch 7/60\n",
      " - 1s - loss: 0.3301 - output_loss: 0.3301 - variance_output_loss: 0.3301 - output_mean_absolute_error: 0.5980 - output_mean_error: -4.0815e-02 - val_loss: 0.1797 - val_output_loss: 0.1796 - val_variance_output_loss: 0.1796 - val_output_mean_absolute_error: 0.5331 - val_output_mean_error: 0.0693\n",
      "Epoch 8/60\n",
      " - 1s - loss: 0.2657 - output_loss: 0.2656 - variance_output_loss: 0.2656 - output_mean_absolute_error: 0.5735 - output_mean_error: -1.9646e-02 - val_loss: 0.1433 - val_output_loss: 0.1433 - val_variance_output_loss: 0.1433 - val_output_mean_absolute_error: 0.5159 - val_output_mean_error: 0.0285\n",
      "Epoch 9/60\n",
      " - 1s - loss: 0.2135 - output_loss: 0.2134 - variance_output_loss: 0.2134 - output_mean_absolute_error: 0.5436 - output_mean_error: -6.3124e-02 - val_loss: 0.0816 - val_output_loss: 0.0816 - val_variance_output_loss: 0.0816 - val_output_mean_absolute_error: 0.4859 - val_output_mean_error: 0.0258\n",
      "Epoch 10/60\n",
      " - 1s - loss: 0.1302 - output_loss: 0.1301 - variance_output_loss: 0.1301 - output_mean_absolute_error: 0.5178 - output_mean_error: -3.8115e-02 - val_loss: 0.0280 - val_output_loss: 0.0279 - val_variance_output_loss: 0.0279 - val_output_mean_absolute_error: 0.4641 - val_output_mean_error: 0.0908\n",
      "Epoch 11/60\n",
      " - 1s - loss: 0.1017 - output_loss: 0.1016 - variance_output_loss: 0.1016 - output_mean_absolute_error: 0.5104 - output_mean_error: -4.8163e-02 - val_loss: -1.0692e-02 - val_output_loss: -1.0738e-02 - val_variance_output_loss: -1.0738e-02 - val_output_mean_absolute_error: 0.4391 - val_output_mean_error: -1.7737e-02\n",
      "Epoch 12/60\n",
      " - 1s - loss: 0.0199 - output_loss: 0.0199 - variance_output_loss: 0.0199 - output_mean_absolute_error: 0.4753 - output_mean_error: -5.9459e-02 - val_loss: -6.2743e-02 - val_output_loss: -6.2789e-02 - val_variance_output_loss: -6.2789e-02 - val_output_mean_absolute_error: 0.4369 - val_output_mean_error: -1.1720e-02\n",
      "Epoch 13/60\n",
      " - 1s - loss: -1.7830e-02 - output_loss: -1.7875e-02 - variance_output_loss: -1.7875e-02 - output_mean_absolute_error: 0.4658 - output_mean_error: -6.4620e-02 - val_loss: -1.3310e-01 - val_output_loss: -1.3315e-01 - val_variance_output_loss: -1.3315e-01 - val_output_mean_absolute_error: 0.4006 - val_output_mean_error: -1.0067e-03\n",
      "Epoch 14/60\n",
      " - 1s - loss: -6.9499e-02 - output_loss: -6.9545e-02 - variance_output_loss: -6.9545e-02 - output_mean_absolute_error: 0.4461 - output_mean_error: -6.1632e-02 - val_loss: -1.5680e-01 - val_output_loss: -1.5685e-01 - val_variance_output_loss: -1.5685e-01 - val_output_mean_absolute_error: 0.3978 - val_output_mean_error: 0.0206\n",
      "Epoch 15/60\n",
      " - 1s - loss: -9.5932e-02 - output_loss: -9.5978e-02 - variance_output_loss: -9.5978e-02 - output_mean_absolute_error: 0.4455 - output_mean_error: -9.0086e-02 - val_loss: -2.0262e-01 - val_output_loss: -2.0267e-01 - val_variance_output_loss: -2.0267e-01 - val_output_mean_absolute_error: 0.3622 - val_output_mean_error: 0.0118\n",
      "Epoch 16/60\n",
      " - 1s - loss: -1.6332e-01 - output_loss: -1.6337e-01 - variance_output_loss: -1.6337e-01 - output_mean_absolute_error: 0.4176 - output_mean_error: -6.0686e-02 - val_loss: -2.0568e-01 - val_output_loss: -2.0573e-01 - val_variance_output_loss: -2.0573e-01 - val_output_mean_absolute_error: 0.3893 - val_output_mean_error: -4.6918e-02\n",
      "Epoch 17/60\n",
      " - 1s - loss: -1.6616e-01 - output_loss: -1.6620e-01 - variance_output_loss: -1.6620e-01 - output_mean_absolute_error: 0.4225 - output_mean_error: -8.3032e-02 - val_loss: -2.2810e-01 - val_output_loss: -2.2815e-01 - val_variance_output_loss: -2.2815e-01 - val_output_mean_absolute_error: 0.3907 - val_output_mean_error: -4.5269e-02\n",
      "Epoch 18/60\n",
      " - 1s - loss: -2.2477e-01 - output_loss: -2.2482e-01 - variance_output_loss: -2.2482e-01 - output_mean_absolute_error: 0.4000 - output_mean_error: -6.5321e-02 - val_loss: -2.5105e-01 - val_output_loss: -2.5110e-01 - val_variance_output_loss: -2.5110e-01 - val_output_mean_absolute_error: 0.3590 - val_output_mean_error: -3.8811e-02\n",
      "Epoch 19/60\n",
      " - 1s - loss: -2.4958e-01 - output_loss: -2.4962e-01 - variance_output_loss: -2.4962e-01 - output_mean_absolute_error: 0.3924 - output_mean_error: -7.8512e-02 - val_loss: -3.1833e-01 - val_output_loss: -3.1838e-01 - val_variance_output_loss: -3.1838e-01 - val_output_mean_absolute_error: 0.3552 - val_output_mean_error: 0.0195\n",
      "Epoch 20/60\n",
      " - 1s - loss: -2.6593e-01 - output_loss: -2.6598e-01 - variance_output_loss: -2.6598e-01 - output_mean_absolute_error: 0.3857 - output_mean_error: -7.4378e-02 - val_loss: -3.0016e-01 - val_output_loss: -3.0021e-01 - val_variance_output_loss: -3.0021e-01 - val_output_mean_absolute_error: 0.3718 - val_output_mean_error: -5.9437e-02\n",
      "Epoch 21/60\n",
      " - 1s - loss: -2.9294e-01 - output_loss: -2.9298e-01 - variance_output_loss: -2.9298e-01 - output_mean_absolute_error: 0.3794 - output_mean_error: -6.9863e-02 - val_loss: -3.5708e-01 - val_output_loss: -3.5713e-01 - val_variance_output_loss: -3.5713e-01 - val_output_mean_absolute_error: 0.3410 - val_output_mean_error: -3.2643e-02\n",
      "Epoch 22/60\n",
      " - 1s - loss: -3.1864e-01 - output_loss: -3.1869e-01 - variance_output_loss: -3.1869e-01 - output_mean_absolute_error: 0.3710 - output_mean_error: -6.7801e-02 - val_loss: -3.8196e-01 - val_output_loss: -3.8200e-01 - val_variance_output_loss: -3.8200e-01 - val_output_mean_absolute_error: 0.3329 - val_output_mean_error: -1.0257e-02\n",
      "Epoch 23/60\n",
      " - 1s - loss: -3.5316e-01 - output_loss: -3.5321e-01 - variance_output_loss: -3.5321e-01 - output_mean_absolute_error: 0.3577 - output_mean_error: -5.5498e-02 - val_loss: -3.7921e-01 - val_output_loss: -3.7926e-01 - val_variance_output_loss: -3.7926e-01 - val_output_mean_absolute_error: 0.3483 - val_output_mean_error: -4.3060e-02\n",
      "Epoch 24/60\n",
      " - 1s - loss: -3.6394e-01 - output_loss: -3.6398e-01 - variance_output_loss: -3.6398e-01 - output_mean_absolute_error: 0.3587 - output_mean_error: -7.1982e-02 - val_loss: -4.5015e-01 - val_output_loss: -4.5020e-01 - val_variance_output_loss: -4.5020e-01 - val_output_mean_absolute_error: 0.3130 - val_output_mean_error: -6.9040e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      " - 1s - loss: -3.9155e-01 - output_loss: -3.9159e-01 - variance_output_loss: -3.9159e-01 - output_mean_absolute_error: 0.3500 - output_mean_error: -5.5693e-02 - val_loss: -3.6585e-01 - val_output_loss: -3.6589e-01 - val_variance_output_loss: -3.6589e-01 - val_output_mean_absolute_error: 0.3403 - val_output_mean_error: 0.0425\n",
      "Epoch 26/60\n",
      " - 1s - loss: -4.0286e-01 - output_loss: -4.0290e-01 - variance_output_loss: -4.0290e-01 - output_mean_absolute_error: 0.3461 - output_mean_error: -6.3673e-02 - val_loss: -3.7752e-01 - val_output_loss: -3.7757e-01 - val_variance_output_loss: -3.7757e-01 - val_output_mean_absolute_error: 0.3405 - val_output_mean_error: 0.0625\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 27/60\n",
      " - 1s - loss: -4.3230e-01 - output_loss: -4.3234e-01 - variance_output_loss: -4.3234e-01 - output_mean_absolute_error: 0.3341 - output_mean_error: -5.5570e-02 - val_loss: -4.2472e-01 - val_output_loss: -4.2476e-01 - val_variance_output_loss: -4.2476e-01 - val_output_mean_absolute_error: 0.3247 - val_output_mean_error: -2.5207e-02\n",
      "Epoch 28/60\n",
      " - 1s - loss: -4.3255e-01 - output_loss: -4.3260e-01 - variance_output_loss: -4.3260e-01 - output_mean_absolute_error: 0.3346 - output_mean_error: -5.3318e-02 - val_loss: -4.6593e-01 - val_output_loss: -4.6598e-01 - val_variance_output_loss: -4.6598e-01 - val_output_mean_absolute_error: 0.3049 - val_output_mean_error: 3.8070e-04\n",
      "Epoch 29/60\n",
      " - 1s - loss: -4.4733e-01 - output_loss: -4.4738e-01 - variance_output_loss: -4.4738e-01 - output_mean_absolute_error: 0.3338 - output_mean_error: -6.0701e-02 - val_loss: -4.8591e-01 - val_output_loss: -4.8595e-01 - val_variance_output_loss: -4.8595e-01 - val_output_mean_absolute_error: 0.3070 - val_output_mean_error: -8.8801e-03\n",
      "Epoch 30/60\n",
      " - 1s - loss: -4.6619e-01 - output_loss: -4.6624e-01 - variance_output_loss: -4.6624e-01 - output_mean_absolute_error: 0.3263 - output_mean_error: -6.3640e-02 - val_loss: -4.6178e-01 - val_output_loss: -4.6183e-01 - val_variance_output_loss: -4.6183e-01 - val_output_mean_absolute_error: 0.3140 - val_output_mean_error: 0.0047\n",
      "Epoch 31/60\n",
      " - 1s - loss: -4.7116e-01 - output_loss: -4.7120e-01 - variance_output_loss: -4.7120e-01 - output_mean_absolute_error: 0.3214 - output_mean_error: -3.8253e-02 - val_loss: -4.4829e-01 - val_output_loss: -4.4834e-01 - val_variance_output_loss: -4.4834e-01 - val_output_mean_absolute_error: 0.3299 - val_output_mean_error: -5.1166e-02\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 32/60\n",
      " - 1s - loss: -4.7837e-01 - output_loss: -4.7842e-01 - variance_output_loss: -4.7842e-01 - output_mean_absolute_error: 0.3233 - output_mean_error: -5.9977e-02 - val_loss: -5.4922e-01 - val_output_loss: -5.4927e-01 - val_variance_output_loss: -5.4927e-01 - val_output_mean_absolute_error: 0.2923 - val_output_mean_error: -1.4871e-02\n",
      "Epoch 33/60\n",
      " - 1s - loss: -4.7344e-01 - output_loss: -4.7348e-01 - variance_output_loss: -4.7348e-01 - output_mean_absolute_error: 0.3228 - output_mean_error: -4.8075e-02 - val_loss: -4.5497e-01 - val_output_loss: -4.5502e-01 - val_variance_output_loss: -4.5502e-01 - val_output_mean_absolute_error: 0.3094 - val_output_mean_error: -3.4269e-02\n",
      "Epoch 34/60\n",
      " - 1s - loss: -4.7747e-01 - output_loss: -4.7752e-01 - variance_output_loss: -4.7752e-01 - output_mean_absolute_error: 0.3239 - output_mean_error: -6.1079e-02 - val_loss: -4.9368e-01 - val_output_loss: -4.9373e-01 - val_variance_output_loss: -4.9373e-01 - val_output_mean_absolute_error: 0.2996 - val_output_mean_error: -2.3666e-02\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 35/60\n",
      " - 1s - loss: -5.0255e-01 - output_loss: -5.0260e-01 - variance_output_loss: -5.0260e-01 - output_mean_absolute_error: 0.3103 - output_mean_error: -3.5684e-02 - val_loss: -5.3201e-01 - val_output_loss: -5.3206e-01 - val_variance_output_loss: -5.3206e-01 - val_output_mean_absolute_error: 0.2864 - val_output_mean_error: -4.4030e-02\n",
      "Epoch 36/60\n",
      " - 1s - loss: -4.8141e-01 - output_loss: -4.8146e-01 - variance_output_loss: -4.8146e-01 - output_mean_absolute_error: 0.3252 - output_mean_error: -6.2617e-02 - val_loss: -4.7752e-01 - val_output_loss: -4.7757e-01 - val_variance_output_loss: -4.7757e-01 - val_output_mean_absolute_error: 0.2981 - val_output_mean_error: -1.4426e-02\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 37/60\n",
      " - 1s - loss: -4.9291e-01 - output_loss: -4.9296e-01 - variance_output_loss: -4.9296e-01 - output_mean_absolute_error: 0.3157 - output_mean_error: -5.0730e-02 - val_loss: -4.9534e-01 - val_output_loss: -4.9539e-01 - val_variance_output_loss: -4.9539e-01 - val_output_mean_absolute_error: 0.3034 - val_output_mean_error: 0.0026\n",
      "Epoch 38/60\n",
      " - 1s - loss: -5.0091e-01 - output_loss: -5.0096e-01 - variance_output_loss: -5.0096e-01 - output_mean_absolute_error: 0.3135 - output_mean_error: -4.3708e-02 - val_loss: -4.8732e-01 - val_output_loss: -4.8737e-01 - val_variance_output_loss: -4.8737e-01 - val_output_mean_absolute_error: 0.3181 - val_output_mean_error: -3.9015e-02\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 39/60\n",
      " - 1s - loss: -4.9591e-01 - output_loss: -4.9596e-01 - variance_output_loss: -4.9596e-01 - output_mean_absolute_error: 0.3158 - output_mean_error: -5.3267e-02 - val_loss: -4.6304e-01 - val_output_loss: -4.6309e-01 - val_variance_output_loss: -4.6309e-01 - val_output_mean_absolute_error: 0.3124 - val_output_mean_error: -1.7426e-02\n",
      "Epoch 40/60\n",
      " - 1s - loss: -4.9733e-01 - output_loss: -4.9738e-01 - variance_output_loss: -4.9738e-01 - output_mean_absolute_error: 0.3177 - output_mean_error: -5.4160e-02 - val_loss: -4.8406e-01 - val_output_loss: -4.8411e-01 - val_variance_output_loss: -4.8411e-01 - val_output_mean_absolute_error: 0.2986 - val_output_mean_error: -7.4843e-03\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 41/60\n",
      " - 1s - loss: -4.8962e-01 - output_loss: -4.8966e-01 - variance_output_loss: -4.8966e-01 - output_mean_absolute_error: 0.3158 - output_mean_error: -4.6726e-02 - val_loss: -5.3549e-01 - val_output_loss: -5.3554e-01 - val_variance_output_loss: -5.3554e-01 - val_output_mean_absolute_error: 0.2890 - val_output_mean_error: -3.8561e-03\n",
      "Epoch 42/60\n",
      " - 1s - loss: -5.1477e-01 - output_loss: -5.1481e-01 - variance_output_loss: -5.1481e-01 - output_mean_absolute_error: 0.3105 - output_mean_error: -5.4747e-02 - val_loss: -5.6296e-01 - val_output_loss: -5.6300e-01 - val_variance_output_loss: -5.6300e-01 - val_output_mean_absolute_error: 0.2868 - val_output_mean_error: -3.0884e-02\n",
      "Epoch 43/60\n",
      " - 1s - loss: -4.9731e-01 - output_loss: -4.9736e-01 - variance_output_loss: -4.9736e-01 - output_mean_absolute_error: 0.3183 - output_mean_error: -5.4092e-02 - val_loss: -4.5754e-01 - val_output_loss: -4.5758e-01 - val_variance_output_loss: -4.5758e-01 - val_output_mean_absolute_error: 0.3043 - val_output_mean_error: -1.3168e-02\n",
      "Epoch 44/60\n",
      " - 1s - loss: -5.0740e-01 - output_loss: -5.0745e-01 - variance_output_loss: -5.0745e-01 - output_mean_absolute_error: 0.3126 - output_mean_error: -4.6624e-02 - val_loss: -5.2231e-01 - val_output_loss: -5.2236e-01 - val_variance_output_loss: -5.2236e-01 - val_output_mean_absolute_error: 0.3122 - val_output_mean_error: -3.6513e-02\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 45/60\n",
      " - 1s - loss: -5.0443e-01 - output_loss: -5.0448e-01 - variance_output_loss: -5.0448e-01 - output_mean_absolute_error: 0.3157 - output_mean_error: -5.6487e-02 - val_loss: -5.0937e-01 - val_output_loss: -5.0942e-01 - val_variance_output_loss: -5.0942e-01 - val_output_mean_absolute_error: 0.2945 - val_output_mean_error: -7.8778e-03\n",
      "Epoch 46/60\n",
      " - 1s - loss: -4.9401e-01 - output_loss: -4.9405e-01 - variance_output_loss: -4.9405e-01 - output_mean_absolute_error: 0.3202 - output_mean_error: -6.1656e-02 - val_loss: -5.0086e-01 - val_output_loss: -5.0090e-01 - val_variance_output_loss: -5.0090e-01 - val_output_mean_absolute_error: 0.2982 - val_output_mean_error: 0.0047\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 47/60\n",
      " - 1s - loss: -4.9778e-01 - output_loss: -4.9783e-01 - variance_output_loss: -4.9783e-01 - output_mean_absolute_error: 0.3133 - output_mean_error: -4.7610e-02 - val_loss: -5.1586e-01 - val_output_loss: -5.1591e-01 - val_variance_output_loss: -5.1591e-01 - val_output_mean_absolute_error: 0.3034 - val_output_mean_error: -3.8256e-02\n",
      "Epoch 48/60\n",
      " - 1s - loss: -5.0118e-01 - output_loss: -5.0123e-01 - variance_output_loss: -5.0123e-01 - output_mean_absolute_error: 0.3108 - output_mean_error: -4.7081e-02 - val_loss: -4.9944e-01 - val_output_loss: -4.9949e-01 - val_variance_output_loss: -4.9949e-01 - val_output_mean_absolute_error: 0.3030 - val_output_mean_error: -2.4089e-02\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 49/60\n",
      " - 1s - loss: -4.8121e-01 - output_loss: -4.8126e-01 - variance_output_loss: -4.8126e-01 - output_mean_absolute_error: 0.3236 - output_mean_error: -5.4614e-02 - val_loss: -5.0913e-01 - val_output_loss: -5.0918e-01 - val_variance_output_loss: -5.0918e-01 - val_output_mean_absolute_error: 0.3025 - val_output_mean_error: -3.0631e-02\n",
      "Epoch 50/60\n",
      " - 1s - loss: -5.0957e-01 - output_loss: -5.0962e-01 - variance_output_loss: -5.0962e-01 - output_mean_absolute_error: 0.3113 - output_mean_error: -5.4415e-02 - val_loss: -5.2001e-01 - val_output_loss: -5.2006e-01 - val_variance_output_loss: -5.2006e-01 - val_output_mean_absolute_error: 0.3023 - val_output_mean_error: -2.8331e-02\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 51/60\n",
      " - 1s - loss: -4.9922e-01 - output_loss: -4.9927e-01 - variance_output_loss: -4.9927e-01 - output_mean_absolute_error: 0.3171 - output_mean_error: -5.8330e-02 - val_loss: -5.3667e-01 - val_output_loss: -5.3672e-01 - val_variance_output_loss: -5.3672e-01 - val_output_mean_absolute_error: 0.2887 - val_output_mean_error: -3.8947e-02\n",
      "Epoch 52/60\n",
      " - 1s - loss: -4.8920e-01 - output_loss: -4.8924e-01 - variance_output_loss: -4.8924e-01 - output_mean_absolute_error: 0.3175 - output_mean_error: -5.0056e-02 - val_loss: -5.1326e-01 - val_output_loss: -5.1331e-01 - val_variance_output_loss: -5.1331e-01 - val_output_mean_absolute_error: 0.3062 - val_output_mean_error: -2.3995e-02\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 53/60\n",
      " - 1s - loss: -5.0437e-01 - output_loss: -5.0442e-01 - variance_output_loss: -5.0442e-01 - output_mean_absolute_error: 0.3136 - output_mean_error: -5.7288e-02 - val_loss: -5.5612e-01 - val_output_loss: -5.5616e-01 - val_variance_output_loss: -5.5616e-01 - val_output_mean_absolute_error: 0.2842 - val_output_mean_error: -8.4786e-03\n",
      "Epoch 54/60\n",
      " - 1s - loss: -4.9956e-01 - output_loss: -4.9961e-01 - variance_output_loss: -4.9961e-01 - output_mean_absolute_error: 0.3166 - output_mean_error: -4.9170e-02 - val_loss: -5.3616e-01 - val_output_loss: -5.3621e-01 - val_variance_output_loss: -5.3621e-01 - val_output_mean_absolute_error: 0.2952 - val_output_mean_error: -2.8191e-02\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 55/60\n",
      " - 1s - loss: -4.9695e-01 - output_loss: -4.9700e-01 - variance_output_loss: -4.9700e-01 - output_mean_absolute_error: 0.3169 - output_mean_error: -5.5658e-02 - val_loss: -4.6742e-01 - val_output_loss: -4.6747e-01 - val_variance_output_loss: -4.6747e-01 - val_output_mean_absolute_error: 0.3099 - val_output_mean_error: -9.5522e-03\n",
      "Epoch 56/60\n",
      " - 1s - loss: -5.0825e-01 - output_loss: -5.0829e-01 - variance_output_loss: -5.0829e-01 - output_mean_absolute_error: 0.3092 - output_mean_error: -4.9394e-02 - val_loss: -5.2277e-01 - val_output_loss: -5.2282e-01 - val_variance_output_loss: -5.2282e-01 - val_output_mean_absolute_error: 0.2989 - val_output_mean_error: -3.2881e-02\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 57/60\n",
      " - 1s - loss: -4.9849e-01 - output_loss: -4.9853e-01 - variance_output_loss: -4.9853e-01 - output_mean_absolute_error: 0.3180 - output_mean_error: -5.5852e-02 - val_loss: -4.8574e-01 - val_output_loss: -4.8579e-01 - val_variance_output_loss: -4.8579e-01 - val_output_mean_absolute_error: 0.3074 - val_output_mean_error: -1.7344e-02\n",
      "Epoch 58/60\n",
      " - 1s - loss: -5.0945e-01 - output_loss: -5.0950e-01 - variance_output_loss: -5.0950e-01 - output_mean_absolute_error: 0.3115 - output_mean_error: -4.7934e-02 - val_loss: -4.9841e-01 - val_output_loss: -4.9846e-01 - val_variance_output_loss: -4.9846e-01 - val_output_mean_absolute_error: 0.3116 - val_output_mean_error: -2.9869e-02\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 59/60\n",
      " - 1s - loss: -4.9243e-01 - output_loss: -4.9248e-01 - variance_output_loss: -4.9248e-01 - output_mean_absolute_error: 0.3188 - output_mean_error: -5.5068e-02 - val_loss: -5.2097e-01 - val_output_loss: -5.2102e-01 - val_variance_output_loss: -5.2102e-01 - val_output_mean_absolute_error: 0.3036 - val_output_mean_error: -2.9526e-02\n",
      "Epoch 60/60\n",
      " - 1s - loss: -5.0795e-01 - output_loss: -5.0800e-01 - variance_output_loss: -5.0800e-01 - output_mean_absolute_error: 0.3122 - output_mean_error: -4.8119e-02 - val_loss: -4.8745e-01 - val_output_loss: -4.8750e-01 - val_variance_output_loss: -4.8750e-01 - val_output_mean_absolute_error: 0.3085 - val_output_mean_error: -2.2517e-02\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Completed Training, 44.04s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_3_125/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_3_125'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/32), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 109.43s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 108.15s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 108.61s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 110.26s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 109.92s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 110.23s elapsed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Data</th>\n",
       "      <th>Scatter</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30067</td>\n",
       "      <td>0.172124</td>\n",
       "      <td>-0.017152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15033</td>\n",
       "      <td>0.186913</td>\n",
       "      <td>-0.017570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7516</td>\n",
       "      <td>0.193223</td>\n",
       "      <td>-0.018622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3758</td>\n",
       "      <td>0.205817</td>\n",
       "      <td>-0.023268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1879</td>\n",
       "      <td>0.245651</td>\n",
       "      <td>-0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>939</td>\n",
       "      <td>0.309125</td>\n",
       "      <td>-0.007424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Data   Scatter      Bias\n",
       "0           30067  0.172124 -0.017152\n",
       "1           15033  0.186913 -0.017570\n",
       "2            7516  0.193223 -0.018622\n",
       "3            3758  0.205817 -0.023268\n",
       "4            1879  0.245651 -0.001448\n",
       "5             939  0.309125 -0.007424"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.stats import mad_std\n",
    "\n",
    "from astroNN.models import load_folder\n",
    "from astroNN.datasets import H5Loader\n",
    "\n",
    "loader = H5Loader('_highsnr_test')  # continuum normalized dataset\n",
    "loader.load_err = False\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y = loader.load()\n",
    "\n",
    "mae = []\n",
    "me = []\n",
    "\n",
    "net_100 = load_folder(\"astroNN_0617_run001\")  # this is the main model we used\n",
    "net_100_pred, err = net_100.test(x)\n",
    "residue = ((net_100_pred - y) / net_100.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_50 = load_folder(\"small_data_fixed_50\")\n",
    "net_50_pred, err = net_50.test(x)\n",
    "residue = ((net_50_pred - y) / net_50.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_25 = load_folder(\"small_data_fixed_25\")\n",
    "net_25_pred, err = net_25.test(x)\n",
    "residue = ((net_25_pred - y) / net_25.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_12_5 = load_folder(\"small_data_fixed_12_5\")\n",
    "net_12_5_pred, err = net_12_5.test(x)\n",
    "residue = ((net_12_5_pred - y) / net_12_5.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_6_25 = load_folder(\"small_data_fixed_6_25\")\n",
    "net_6_25_pred, err = net_6_25.test(x)\n",
    "residue = ((net_6_25_pred - y) / net_6_25.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_3_125 = load_folder(\"small_data_fixed_3_125\")\n",
    "net_3_125_pred, err = net_3_125.test(x)\n",
    "residue = ((net_3_125_pred - y) / net_3_125.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "\n",
    "d = {'Number of Data': [30067, 15033, 7516, 3758, 1879, 939], 'Scatter': mae, 'Bias': me}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 3758, Number of Validation Data: 417\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 8s - loss: 0.4236 - output_loss: 0.4236 - variance_output_loss: 0.4236 - output_mean_absolute_error: 0.6785 - output_mean_error: -1.4760e-02 - val_loss: 0.4453 - val_output_loss: 0.4453 - val_variance_output_loss: 0.4453 - val_output_mean_absolute_error: 0.6616 - val_output_mean_error: -3.9038e-02\n",
      "Epoch 2/60\n",
      " - 2s - loss: 0.2573 - output_loss: 0.2573 - variance_output_loss: 0.2573 - output_mean_absolute_error: 0.5753 - output_mean_error: -1.6956e-02 - val_loss: 0.3036 - val_output_loss: 0.3035 - val_variance_output_loss: 0.3035 - val_output_mean_absolute_error: 0.5714 - val_output_mean_error: -5.2652e-02\n",
      "Epoch 3/60\n",
      " - 2s - loss: 0.0661 - output_loss: 0.0661 - variance_output_loss: 0.0661 - output_mean_absolute_error: 0.4805 - output_mean_error: -3.6465e-02 - val_loss: -1.8735e-02 - val_output_loss: -1.8777e-02 - val_variance_output_loss: -1.8777e-02 - val_output_mean_absolute_error: 0.4463 - val_output_mean_error: -9.8173e-03\n",
      "Epoch 4/60\n",
      " - 2s - loss: -1.1983e-01 - output_loss: -1.1987e-01 - variance_output_loss: -1.1987e-01 - output_mean_absolute_error: 0.4176 - output_mean_error: -3.1422e-02 - val_loss: -1.9446e-01 - val_output_loss: -1.9450e-01 - val_variance_output_loss: -1.9450e-01 - val_output_mean_absolute_error: 0.3909 - val_output_mean_error: -3.6929e-02\n",
      "Epoch 5/60\n",
      " - 2s - loss: -2.5779e-01 - output_loss: -2.5784e-01 - variance_output_loss: -2.5784e-01 - output_mean_absolute_error: 0.3730 - output_mean_error: -2.4985e-02 - val_loss: -2.6392e-01 - val_output_loss: -2.6396e-01 - val_variance_output_loss: -2.6396e-01 - val_output_mean_absolute_error: 0.3715 - val_output_mean_error: -1.0476e-02\n",
      "Epoch 6/60\n",
      " - 2s - loss: -3.4683e-01 - output_loss: -3.4688e-01 - variance_output_loss: -3.4688e-01 - output_mean_absolute_error: 0.3438 - output_mean_error: -1.6033e-02 - val_loss: -3.5890e-01 - val_output_loss: -3.5894e-01 - val_variance_output_loss: -3.5894e-01 - val_output_mean_absolute_error: 0.3448 - val_output_mean_error: -2.2053e-02\n",
      "Epoch 7/60\n",
      " - 2s - loss: -4.0983e-01 - output_loss: -4.0987e-01 - variance_output_loss: -4.0987e-01 - output_mean_absolute_error: 0.3257 - output_mean_error: -1.0485e-02 - val_loss: -3.9688e-01 - val_output_loss: -3.9692e-01 - val_variance_output_loss: -3.9692e-01 - val_output_mean_absolute_error: 0.3256 - val_output_mean_error: 0.0183\n",
      "Epoch 8/60\n",
      " - 2s - loss: -4.7564e-01 - output_loss: -4.7569e-01 - variance_output_loss: -4.7569e-01 - output_mean_absolute_error: 0.3063 - output_mean_error: -7.5421e-03 - val_loss: -4.5254e-01 - val_output_loss: -4.5258e-01 - val_variance_output_loss: -4.5258e-01 - val_output_mean_absolute_error: 0.3066 - val_output_mean_error: -2.4418e-02\n",
      "Epoch 9/60\n",
      " - 2s - loss: -5.2774e-01 - output_loss: -5.2779e-01 - variance_output_loss: -5.2779e-01 - output_mean_absolute_error: 0.2926 - output_mean_error: -2.1982e-03 - val_loss: -5.1976e-01 - val_output_loss: -5.1980e-01 - val_variance_output_loss: -5.1980e-01 - val_output_mean_absolute_error: 0.2914 - val_output_mean_error: -3.2389e-02\n",
      "Epoch 10/60\n",
      " - 2s - loss: -5.6960e-01 - output_loss: -5.6964e-01 - variance_output_loss: -5.6964e-01 - output_mean_absolute_error: 0.2823 - output_mean_error: -5.4699e-03 - val_loss: -5.5291e-01 - val_output_loss: -5.5296e-01 - val_variance_output_loss: -5.5296e-01 - val_output_mean_absolute_error: 0.2886 - val_output_mean_error: 0.0068\n",
      "Epoch 11/60\n",
      " - 2s - loss: -6.0631e-01 - output_loss: -6.0635e-01 - variance_output_loss: -6.0635e-01 - output_mean_absolute_error: 0.2757 - output_mean_error: -6.5075e-03 - val_loss: -5.9401e-01 - val_output_loss: -5.9406e-01 - val_variance_output_loss: -5.9406e-01 - val_output_mean_absolute_error: 0.2735 - val_output_mean_error: -2.6530e-02\n",
      "Epoch 12/60\n",
      " - 2s - loss: -6.6139e-01 - output_loss: -6.6144e-01 - variance_output_loss: -6.6144e-01 - output_mean_absolute_error: 0.2587 - output_mean_error: -1.5148e-03 - val_loss: -6.5890e-01 - val_output_loss: -6.5894e-01 - val_variance_output_loss: -6.5894e-01 - val_output_mean_absolute_error: 0.2539 - val_output_mean_error: 0.0302\n",
      "Epoch 13/60\n",
      " - 2s - loss: -6.7226e-01 - output_loss: -6.7230e-01 - variance_output_loss: -6.7230e-01 - output_mean_absolute_error: 0.2584 - output_mean_error: -6.3171e-03 - val_loss: -6.7462e-01 - val_output_loss: -6.7466e-01 - val_variance_output_loss: -6.7466e-01 - val_output_mean_absolute_error: 0.2533 - val_output_mean_error: -4.5610e-03\n",
      "Epoch 14/60\n",
      " - 2s - loss: -7.3081e-01 - output_loss: -7.3085e-01 - variance_output_loss: -7.3085e-01 - output_mean_absolute_error: 0.2437 - output_mean_error: -3.8600e-03 - val_loss: -7.4072e-01 - val_output_loss: -7.4077e-01 - val_variance_output_loss: -7.4077e-01 - val_output_mean_absolute_error: 0.2450 - val_output_mean_error: 0.0094\n",
      "Epoch 15/60\n",
      " - 2s - loss: -7.4757e-01 - output_loss: -7.4762e-01 - variance_output_loss: -7.4762e-01 - output_mean_absolute_error: 0.2407 - output_mean_error: -3.7072e-03 - val_loss: -7.4395e-01 - val_output_loss: -7.4400e-01 - val_variance_output_loss: -7.4400e-01 - val_output_mean_absolute_error: 0.2465 - val_output_mean_error: -3.8350e-03\n",
      "Epoch 16/60\n",
      " - 2s - loss: -7.7461e-01 - output_loss: -7.7466e-01 - variance_output_loss: -7.7466e-01 - output_mean_absolute_error: 0.2349 - output_mean_error: -3.7171e-03 - val_loss: -7.7168e-01 - val_output_loss: -7.7173e-01 - val_variance_output_loss: -7.7173e-01 - val_output_mean_absolute_error: 0.2397 - val_output_mean_error: 0.0344\n",
      "Epoch 17/60\n",
      " - 2s - loss: -8.1689e-01 - output_loss: -8.1694e-01 - variance_output_loss: -8.1694e-01 - output_mean_absolute_error: 0.2261 - output_mean_error: -3.3233e-03 - val_loss: -8.1076e-01 - val_output_loss: -8.1081e-01 - val_variance_output_loss: -8.1081e-01 - val_output_mean_absolute_error: 0.2304 - val_output_mean_error: -2.3147e-02\n",
      "Epoch 18/60\n",
      " - 2s - loss: -8.4310e-01 - output_loss: -8.4315e-01 - variance_output_loss: -8.4315e-01 - output_mean_absolute_error: 0.2207 - output_mean_error: -4.7059e-03 - val_loss: -8.3760e-01 - val_output_loss: -8.3765e-01 - val_variance_output_loss: -8.3765e-01 - val_output_mean_absolute_error: 0.2233 - val_output_mean_error: 0.0284\n",
      "Epoch 19/60\n",
      " - 2s - loss: -8.4955e-01 - output_loss: -8.4959e-01 - variance_output_loss: -8.4959e-01 - output_mean_absolute_error: 0.2198 - output_mean_error: -3.8115e-03 - val_loss: -8.5447e-01 - val_output_loss: -8.5452e-01 - val_variance_output_loss: -8.5452e-01 - val_output_mean_absolute_error: 0.2223 - val_output_mean_error: 0.0111\n",
      "Epoch 20/60\n",
      " - 2s - loss: -8.7000e-01 - output_loss: -8.7005e-01 - variance_output_loss: -8.7005e-01 - output_mean_absolute_error: 0.2161 - output_mean_error: -4.8697e-03 - val_loss: -7.9866e-01 - val_output_loss: -7.9871e-01 - val_variance_output_loss: -7.9871e-01 - val_output_mean_absolute_error: 0.2309 - val_output_mean_error: 0.0510\n",
      "Epoch 21/60\n",
      " - 2s - loss: -9.0677e-01 - output_loss: -9.0682e-01 - variance_output_loss: -9.0682e-01 - output_mean_absolute_error: 0.2109 - output_mean_error: -6.8870e-03 - val_loss: -8.8812e-01 - val_output_loss: -8.8817e-01 - val_variance_output_loss: -8.8817e-01 - val_output_mean_absolute_error: 0.2203 - val_output_mean_error: 3.2572e-04\n",
      "Epoch 22/60\n",
      " - 2s - loss: -9.1206e-01 - output_loss: -9.1211e-01 - variance_output_loss: -9.1211e-01 - output_mean_absolute_error: 0.2078 - output_mean_error: -3.9809e-03 - val_loss: -8.9630e-01 - val_output_loss: -8.9635e-01 - val_variance_output_loss: -8.9635e-01 - val_output_mean_absolute_error: 0.2143 - val_output_mean_error: -3.7408e-02\n",
      "Epoch 23/60\n",
      " - 2s - loss: -9.3160e-01 - output_loss: -9.3165e-01 - variance_output_loss: -9.3165e-01 - output_mean_absolute_error: 0.2054 - output_mean_error: -4.6324e-03 - val_loss: -9.0809e-01 - val_output_loss: -9.0814e-01 - val_variance_output_loss: -9.0814e-01 - val_output_mean_absolute_error: 0.2071 - val_output_mean_error: -2.4054e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      " - 2s - loss: -9.4908e-01 - output_loss: -9.4913e-01 - variance_output_loss: -9.4913e-01 - output_mean_absolute_error: 0.2031 - output_mean_error: -8.0418e-03 - val_loss: -9.5041e-01 - val_output_loss: -9.5046e-01 - val_variance_output_loss: -9.5046e-01 - val_output_mean_absolute_error: 0.2018 - val_output_mean_error: 0.0127\n",
      "Epoch 25/60\n",
      " - 2s - loss: -9.5957e-01 - output_loss: -9.5962e-01 - variance_output_loss: -9.5962e-01 - output_mean_absolute_error: 0.2000 - output_mean_error: -4.1495e-03 - val_loss: -9.8065e-01 - val_output_loss: -9.8070e-01 - val_variance_output_loss: -9.8070e-01 - val_output_mean_absolute_error: 0.1983 - val_output_mean_error: -1.7390e-02\n",
      "Epoch 26/60\n",
      " - 2s - loss: -9.7411e-01 - output_loss: -9.7416e-01 - variance_output_loss: -9.7416e-01 - output_mean_absolute_error: 0.1983 - output_mean_error: -6.1365e-03 - val_loss: -9.6121e-01 - val_output_loss: -9.6126e-01 - val_variance_output_loss: -9.6126e-01 - val_output_mean_absolute_error: 0.2073 - val_output_mean_error: -1.8828e-02\n",
      "Epoch 27/60\n",
      " - 2s - loss: -1.0020e+00 - output_loss: -1.0020e+00 - variance_output_loss: -1.0020e+00 - output_mean_absolute_error: 0.1927 - output_mean_error: -7.4363e-03 - val_loss: -9.7236e-01 - val_output_loss: -9.7242e-01 - val_variance_output_loss: -9.7242e-01 - val_output_mean_absolute_error: 0.2044 - val_output_mean_error: -3.7447e-02\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 28/60\n",
      " - 2s - loss: -1.0129e+00 - output_loss: -1.0129e+00 - variance_output_loss: -1.0129e+00 - output_mean_absolute_error: 0.1941 - output_mean_error: -7.0517e-03 - val_loss: -9.6675e-01 - val_output_loss: -9.6680e-01 - val_variance_output_loss: -9.6680e-01 - val_output_mean_absolute_error: 0.2045 - val_output_mean_error: -2.5008e-02\n",
      "Epoch 29/60\n",
      " - 2s - loss: -1.0184e+00 - output_loss: -1.0184e+00 - variance_output_loss: -1.0184e+00 - output_mean_absolute_error: 0.1892 - output_mean_error: -7.9417e-03 - val_loss: -9.7640e-01 - val_output_loss: -9.7645e-01 - val_variance_output_loss: -9.7645e-01 - val_output_mean_absolute_error: 0.2026 - val_output_mean_error: -2.1046e-03\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 30/60\n",
      " - 2s - loss: -1.0313e+00 - output_loss: -1.0313e+00 - variance_output_loss: -1.0313e+00 - output_mean_absolute_error: 0.1886 - output_mean_error: -4.2649e-03 - val_loss: -1.0070e+00 - val_output_loss: -1.0070e+00 - val_variance_output_loss: -1.0070e+00 - val_output_mean_absolute_error: 0.1967 - val_output_mean_error: -6.5931e-03\n",
      "Epoch 31/60\n",
      " - 2s - loss: -1.0367e+00 - output_loss: -1.0368e+00 - variance_output_loss: -1.0368e+00 - output_mean_absolute_error: 0.1903 - output_mean_error: -7.8731e-03 - val_loss: -9.8648e-01 - val_output_loss: -9.8654e-01 - val_variance_output_loss: -9.8654e-01 - val_output_mean_absolute_error: 0.2057 - val_output_mean_error: -1.4492e-02\n",
      "Epoch 32/60\n",
      " - 2s - loss: -1.0569e+00 - output_loss: -1.0569e+00 - variance_output_loss: -1.0569e+00 - output_mean_absolute_error: 0.1835 - output_mean_error: -5.5500e-03 - val_loss: -1.0173e+00 - val_output_loss: -1.0173e+00 - val_variance_output_loss: -1.0173e+00 - val_output_mean_absolute_error: 0.1963 - val_output_mean_error: -3.3330e-03\n",
      "Epoch 33/60\n",
      " - 2s - loss: -1.0453e+00 - output_loss: -1.0453e+00 - variance_output_loss: -1.0453e+00 - output_mean_absolute_error: 0.1884 - output_mean_error: -6.6844e-03 - val_loss: -9.8776e-01 - val_output_loss: -9.8781e-01 - val_variance_output_loss: -9.8781e-01 - val_output_mean_absolute_error: 0.1965 - val_output_mean_error: 0.0186\n",
      "Epoch 34/60\n",
      " - 2s - loss: -1.0467e+00 - output_loss: -1.0468e+00 - variance_output_loss: -1.0468e+00 - output_mean_absolute_error: 0.1871 - output_mean_error: -6.0077e-03 - val_loss: -1.0211e+00 - val_output_loss: -1.0211e+00 - val_variance_output_loss: -1.0211e+00 - val_output_mean_absolute_error: 0.1914 - val_output_mean_error: 0.0036\n",
      "Epoch 35/60\n",
      " - 2s - loss: -1.0458e+00 - output_loss: -1.0459e+00 - variance_output_loss: -1.0459e+00 - output_mean_absolute_error: 0.1870 - output_mean_error: -4.8526e-03 - val_loss: -1.0200e+00 - val_output_loss: -1.0200e+00 - val_variance_output_loss: -1.0200e+00 - val_output_mean_absolute_error: 0.1882 - val_output_mean_error: -1.9904e-02\n",
      "Epoch 36/60\n",
      " - 2s - loss: -1.0517e+00 - output_loss: -1.0517e+00 - variance_output_loss: -1.0517e+00 - output_mean_absolute_error: 0.1863 - output_mean_error: -6.2428e-03 - val_loss: -1.0178e+00 - val_output_loss: -1.0179e+00 - val_variance_output_loss: -1.0179e+00 - val_output_mean_absolute_error: 0.1960 - val_output_mean_error: -1.8156e-02\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 37/60\n",
      " - 2s - loss: -1.0590e+00 - output_loss: -1.0590e+00 - variance_output_loss: -1.0590e+00 - output_mean_absolute_error: 0.1840 - output_mean_error: -6.7760e-03 - val_loss: -1.0305e+00 - val_output_loss: -1.0305e+00 - val_variance_output_loss: -1.0305e+00 - val_output_mean_absolute_error: 0.1940 - val_output_mean_error: 0.0082\n",
      "Epoch 38/60\n",
      " - 2s - loss: -1.0594e+00 - output_loss: -1.0594e+00 - variance_output_loss: -1.0594e+00 - output_mean_absolute_error: 0.1851 - output_mean_error: -6.8744e-03 - val_loss: -9.7581e-01 - val_output_loss: -9.7586e-01 - val_variance_output_loss: -9.7586e-01 - val_output_mean_absolute_error: 0.2071 - val_output_mean_error: -1.2459e-02\n",
      "Epoch 39/60\n",
      " - 2s - loss: -1.0611e+00 - output_loss: -1.0612e+00 - variance_output_loss: -1.0612e+00 - output_mean_absolute_error: 0.1847 - output_mean_error: -5.0437e-03 - val_loss: -9.9699e-01 - val_output_loss: -9.9704e-01 - val_variance_output_loss: -9.9704e-01 - val_output_mean_absolute_error: 0.2030 - val_output_mean_error: -1.9508e-02\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 40/60\n",
      " - 2s - loss: -1.0644e+00 - output_loss: -1.0645e+00 - variance_output_loss: -1.0645e+00 - output_mean_absolute_error: 0.1834 - output_mean_error: -5.8806e-03 - val_loss: -1.0321e+00 - val_output_loss: -1.0321e+00 - val_variance_output_loss: -1.0321e+00 - val_output_mean_absolute_error: 0.2008 - val_output_mean_error: -1.3966e-02\n",
      "Epoch 41/60\n",
      " - 2s - loss: -1.0635e+00 - output_loss: -1.0636e+00 - variance_output_loss: -1.0636e+00 - output_mean_absolute_error: 0.1840 - output_mean_error: -7.0277e-03 - val_loss: -1.0077e+00 - val_output_loss: -1.0077e+00 - val_variance_output_loss: -1.0077e+00 - val_output_mean_absolute_error: 0.1930 - val_output_mean_error: -1.4442e-02\n",
      "Epoch 42/60\n",
      " - 2s - loss: -1.0702e+00 - output_loss: -1.0702e+00 - variance_output_loss: -1.0702e+00 - output_mean_absolute_error: 0.1830 - output_mean_error: -3.6145e-03 - val_loss: -1.0088e+00 - val_output_loss: -1.0088e+00 - val_variance_output_loss: -1.0088e+00 - val_output_mean_absolute_error: 0.1950 - val_output_mean_error: -1.1660e-02\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 43/60\n",
      " - 2s - loss: -1.0668e+00 - output_loss: -1.0669e+00 - variance_output_loss: -1.0669e+00 - output_mean_absolute_error: 0.1847 - output_mean_error: -8.4474e-03 - val_loss: -1.0424e+00 - val_output_loss: -1.0424e+00 - val_variance_output_loss: -1.0424e+00 - val_output_mean_absolute_error: 0.1866 - val_output_mean_error: -2.2814e-02\n",
      "Epoch 44/60\n",
      " - 2s - loss: -1.0687e+00 - output_loss: -1.0687e+00 - variance_output_loss: -1.0687e+00 - output_mean_absolute_error: 0.1834 - output_mean_error: -9.3813e-03 - val_loss: -1.0190e+00 - val_output_loss: -1.0190e+00 - val_variance_output_loss: -1.0190e+00 - val_output_mean_absolute_error: 0.1938 - val_output_mean_error: -1.5113e-02\n",
      "Epoch 45/60\n",
      " - 2s - loss: -1.0702e+00 - output_loss: -1.0703e+00 - variance_output_loss: -1.0703e+00 - output_mean_absolute_error: 0.1828 - output_mean_error: -4.4657e-03 - val_loss: -1.0404e+00 - val_output_loss: -1.0404e+00 - val_variance_output_loss: -1.0404e+00 - val_output_mean_absolute_error: 0.1879 - val_output_mean_error: 9.7810e-04\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 46/60\n",
      " - 2s - loss: -1.0818e+00 - output_loss: -1.0819e+00 - variance_output_loss: -1.0819e+00 - output_mean_absolute_error: 0.1807 - output_mean_error: -5.7402e-03 - val_loss: -1.0384e+00 - val_output_loss: -1.0385e+00 - val_variance_output_loss: -1.0385e+00 - val_output_mean_absolute_error: 0.1883 - val_output_mean_error: -1.4915e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      " - 2s - loss: -1.0760e+00 - output_loss: -1.0761e+00 - variance_output_loss: -1.0761e+00 - output_mean_absolute_error: 0.1811 - output_mean_error: -5.3630e-03 - val_loss: -1.0147e+00 - val_output_loss: -1.0148e+00 - val_variance_output_loss: -1.0148e+00 - val_output_mean_absolute_error: 0.1966 - val_output_mean_error: -1.0728e-02\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 48/60\n",
      " - 2s - loss: -1.0688e+00 - output_loss: -1.0689e+00 - variance_output_loss: -1.0689e+00 - output_mean_absolute_error: 0.1851 - output_mean_error: -7.8469e-03 - val_loss: -1.0242e+00 - val_output_loss: -1.0243e+00 - val_variance_output_loss: -1.0243e+00 - val_output_mean_absolute_error: 0.1959 - val_output_mean_error: -3.7583e-03\n",
      "Epoch 49/60\n",
      " - 2s - loss: -1.0746e+00 - output_loss: -1.0746e+00 - variance_output_loss: -1.0746e+00 - output_mean_absolute_error: 0.1817 - output_mean_error: -5.4842e-03 - val_loss: -1.0322e+00 - val_output_loss: -1.0323e+00 - val_variance_output_loss: -1.0323e+00 - val_output_mean_absolute_error: 0.1930 - val_output_mean_error: 0.0017\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 50/60\n",
      " - 2s - loss: -1.0695e+00 - output_loss: -1.0695e+00 - variance_output_loss: -1.0695e+00 - output_mean_absolute_error: 0.1846 - output_mean_error: -5.9361e-03 - val_loss: -1.0048e+00 - val_output_loss: -1.0049e+00 - val_variance_output_loss: -1.0049e+00 - val_output_mean_absolute_error: 0.1991 - val_output_mean_error: -1.8504e-02\n",
      "Epoch 51/60\n",
      " - 2s - loss: -1.0724e+00 - output_loss: -1.0724e+00 - variance_output_loss: -1.0724e+00 - output_mean_absolute_error: 0.1838 - output_mean_error: -4.7480e-03 - val_loss: -1.0143e+00 - val_output_loss: -1.0144e+00 - val_variance_output_loss: -1.0144e+00 - val_output_mean_absolute_error: 0.1920 - val_output_mean_error: 0.0011\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 52/60\n",
      " - 2s - loss: -1.0777e+00 - output_loss: -1.0778e+00 - variance_output_loss: -1.0778e+00 - output_mean_absolute_error: 0.1825 - output_mean_error: -5.6945e-03 - val_loss: -1.0303e+00 - val_output_loss: -1.0304e+00 - val_variance_output_loss: -1.0304e+00 - val_output_mean_absolute_error: 0.1975 - val_output_mean_error: -1.5560e-02\n",
      "Epoch 53/60\n",
      " - 2s - loss: -1.0790e+00 - output_loss: -1.0791e+00 - variance_output_loss: -1.0791e+00 - output_mean_absolute_error: 0.1825 - output_mean_error: -3.5988e-03 - val_loss: -1.0187e+00 - val_output_loss: -1.0188e+00 - val_variance_output_loss: -1.0188e+00 - val_output_mean_absolute_error: 0.1948 - val_output_mean_error: -1.1391e-02\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 54/60\n",
      " - 2s - loss: -1.0765e+00 - output_loss: -1.0765e+00 - variance_output_loss: -1.0765e+00 - output_mean_absolute_error: 0.1833 - output_mean_error: -5.4363e-03 - val_loss: -1.0248e+00 - val_output_loss: -1.0249e+00 - val_variance_output_loss: -1.0249e+00 - val_output_mean_absolute_error: 0.1895 - val_output_mean_error: -2.2066e-02\n",
      "Epoch 55/60\n",
      " - 2s - loss: -1.0570e+00 - output_loss: -1.0571e+00 - variance_output_loss: -1.0571e+00 - output_mean_absolute_error: 0.1857 - output_mean_error: -4.9391e-03 - val_loss: -1.0133e+00 - val_output_loss: -1.0134e+00 - val_variance_output_loss: -1.0134e+00 - val_output_mean_absolute_error: 0.2008 - val_output_mean_error: -1.8775e-02\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 56/60\n",
      " - 2s - loss: -1.0693e+00 - output_loss: -1.0694e+00 - variance_output_loss: -1.0694e+00 - output_mean_absolute_error: 0.1844 - output_mean_error: -4.8852e-03 - val_loss: -1.0430e+00 - val_output_loss: -1.0431e+00 - val_variance_output_loss: -1.0431e+00 - val_output_mean_absolute_error: 0.1919 - val_output_mean_error: -1.4493e-02\n",
      "Epoch 57/60\n",
      " - 2s - loss: -1.0738e+00 - output_loss: -1.0738e+00 - variance_output_loss: -1.0738e+00 - output_mean_absolute_error: 0.1824 - output_mean_error: -8.3044e-03 - val_loss: -1.0094e+00 - val_output_loss: -1.0095e+00 - val_variance_output_loss: -1.0095e+00 - val_output_mean_absolute_error: 0.2035 - val_output_mean_error: -2.7400e-02\n",
      "Epoch 58/60\n",
      " - 2s - loss: -1.0678e+00 - output_loss: -1.0678e+00 - variance_output_loss: -1.0678e+00 - output_mean_absolute_error: 0.1852 - output_mean_error: -5.8403e-03 - val_loss: -1.0507e+00 - val_output_loss: -1.0507e+00 - val_variance_output_loss: -1.0507e+00 - val_output_mean_absolute_error: 0.1794 - val_output_mean_error: -2.1597e-04\n",
      "Epoch 59/60\n",
      " - 2s - loss: -1.0645e+00 - output_loss: -1.0645e+00 - variance_output_loss: -1.0645e+00 - output_mean_absolute_error: 0.1843 - output_mean_error: -6.7344e-03 - val_loss: -1.0462e+00 - val_output_loss: -1.0462e+00 - val_variance_output_loss: -1.0462e+00 - val_output_mean_absolute_error: 0.1823 - val_output_mean_error: -9.0949e-03\n",
      "Epoch 60/60\n",
      " - 2s - loss: -1.0745e+00 - output_loss: -1.0746e+00 - variance_output_loss: -1.0746e+00 - output_mean_absolute_error: 0.1831 - output_mean_error: -4.0843e-03 - val_loss: -1.0098e+00 - val_output_loss: -1.0099e+00 - val_variance_output_loss: -1.0099e+00 - val_output_mean_absolute_error: 0.1970 - val_output_mean_error: -2.4402e-02\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Completed Training, 145.96s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_adaptive_12_5/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [160, 48, 32, 16, 2]  # reduced size\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_adaptive_12_5'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/8), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 1879, Number of Validation Data: 208\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 7s - loss: 0.4419 - output_loss: 0.4419 - variance_output_loss: 0.4419 - output_mean_absolute_error: 0.6829 - output_mean_error: 0.0184 - val_loss: 0.5748 - val_output_loss: 0.5748 - val_variance_output_loss: 0.5748 - val_output_mean_absolute_error: 0.7303 - val_output_mean_error: -6.5581e-02\n",
      "Epoch 2/60\n",
      " - 1s - loss: 0.4348 - output_loss: 0.4348 - variance_output_loss: 0.4348 - output_mean_absolute_error: 0.6590 - output_mean_error: -1.2866e-02 - val_loss: 0.6000 - val_output_loss: 0.6000 - val_variance_output_loss: 0.6000 - val_output_mean_absolute_error: 0.7598 - val_output_mean_error: -1.1669e-01\n",
      "Epoch 3/60\n",
      " - 1s - loss: 0.4255 - output_loss: 0.4255 - variance_output_loss: 0.4255 - output_mean_absolute_error: 0.6563 - output_mean_error: -1.0410e-02 - val_loss: 0.4040 - val_output_loss: 0.4039 - val_variance_output_loss: 0.4039 - val_output_mean_absolute_error: 0.6566 - val_output_mean_error: -1.9903e-02\n",
      "Epoch 4/60\n",
      " - 1s - loss: 0.2716 - output_loss: 0.2716 - variance_output_loss: 0.2716 - output_mean_absolute_error: 0.5894 - output_mean_error: -1.6161e-02 - val_loss: 0.3226 - val_output_loss: 0.3226 - val_variance_output_loss: 0.3226 - val_output_mean_absolute_error: 0.6144 - val_output_mean_error: -7.0527e-02\n",
      "Epoch 5/60\n",
      " - 1s - loss: 0.2008 - output_loss: 0.2007 - variance_output_loss: 0.2007 - output_mean_absolute_error: 0.5549 - output_mean_error: -2.1611e-02 - val_loss: 0.2197 - val_output_loss: 0.2197 - val_variance_output_loss: 0.2197 - val_output_mean_absolute_error: 0.5685 - val_output_mean_error: -4.8202e-02\n",
      "Epoch 6/60\n",
      " - 1s - loss: 0.0902 - output_loss: 0.0902 - variance_output_loss: 0.0902 - output_mean_absolute_error: 0.5044 - output_mean_error: -1.9918e-02 - val_loss: 0.0927 - val_output_loss: 0.0927 - val_variance_output_loss: 0.0927 - val_output_mean_absolute_error: 0.5090 - val_output_mean_error: -2.2215e-02\n",
      "Epoch 7/60\n",
      " - 1s - loss: 0.0092 - output_loss: 0.0092 - variance_output_loss: 0.0092 - output_mean_absolute_error: 0.4694 - output_mean_error: -3.9647e-02 - val_loss: 0.0808 - val_output_loss: 0.0807 - val_variance_output_loss: 0.0807 - val_output_mean_absolute_error: 0.5164 - val_output_mean_error: -5.5713e-02\n",
      "Epoch 8/60\n",
      " - 1s - loss: -6.9044e-02 - output_loss: -6.9077e-02 - variance_output_loss: -6.9077e-02 - output_mean_absolute_error: 0.4361 - output_mean_error: -3.8736e-02 - val_loss: 0.0253 - val_output_loss: 0.0253 - val_variance_output_loss: 0.0253 - val_output_mean_absolute_error: 0.5131 - val_output_mean_error: -1.2846e-01\n",
      "Epoch 9/60\n",
      " - 1s - loss: -1.5789e-01 - output_loss: -1.5792e-01 - variance_output_loss: -1.5792e-01 - output_mean_absolute_error: 0.3967 - output_mean_error: -3.4859e-02 - val_loss: -1.3946e-01 - val_output_loss: -1.3950e-01 - val_variance_output_loss: -1.3950e-01 - val_output_mean_absolute_error: 0.4216 - val_output_mean_error: -8.3807e-02\n",
      "Epoch 10/60\n",
      " - 1s - loss: -2.2676e-01 - output_loss: -2.2679e-01 - variance_output_loss: -2.2679e-01 - output_mean_absolute_error: 0.3782 - output_mean_error: -3.9316e-02 - val_loss: -1.8583e-01 - val_output_loss: -1.8587e-01 - val_variance_output_loss: -1.8587e-01 - val_output_mean_absolute_error: 0.3987 - val_output_mean_error: -6.6885e-02\n",
      "Epoch 11/60\n",
      " - 1s - loss: -2.5274e-01 - output_loss: -2.5278e-01 - variance_output_loss: -2.5278e-01 - output_mean_absolute_error: 0.3738 - output_mean_error: -5.4577e-02 - val_loss: -2.6916e-01 - val_output_loss: -2.6919e-01 - val_variance_output_loss: -2.6919e-01 - val_output_mean_absolute_error: 0.3730 - val_output_mean_error: -3.3788e-02\n",
      "Epoch 12/60\n",
      " - 1s - loss: -3.3930e-01 - output_loss: -3.3934e-01 - variance_output_loss: -3.3934e-01 - output_mean_absolute_error: 0.3429 - output_mean_error: -3.0454e-02 - val_loss: -2.5830e-01 - val_output_loss: -2.5834e-01 - val_variance_output_loss: -2.5834e-01 - val_output_mean_absolute_error: 0.3731 - val_output_mean_error: -1.4189e-02\n",
      "Epoch 13/60\n",
      " - 1s - loss: -3.5146e-01 - output_loss: -3.5149e-01 - variance_output_loss: -3.5149e-01 - output_mean_absolute_error: 0.3446 - output_mean_error: -4.6633e-02 - val_loss: -3.2221e-01 - val_output_loss: -3.2225e-01 - val_variance_output_loss: -3.2225e-01 - val_output_mean_absolute_error: 0.3691 - val_output_mean_error: -8.4789e-02\n",
      "Epoch 14/60\n",
      " - 1s - loss: -3.9589e-01 - output_loss: -3.9593e-01 - variance_output_loss: -3.9593e-01 - output_mean_absolute_error: 0.3328 - output_mean_error: -4.1000e-02 - val_loss: -3.4804e-01 - val_output_loss: -3.4808e-01 - val_variance_output_loss: -3.4808e-01 - val_output_mean_absolute_error: 0.3511 - val_output_mean_error: -9.7375e-02\n",
      "Epoch 15/60\n",
      " - 1s - loss: -4.2484e-01 - output_loss: -4.2487e-01 - variance_output_loss: -4.2487e-01 - output_mean_absolute_error: 0.3220 - output_mean_error: -4.3515e-02 - val_loss: -3.5130e-01 - val_output_loss: -3.5134e-01 - val_variance_output_loss: -3.5134e-01 - val_output_mean_absolute_error: 0.3554 - val_output_mean_error: -6.6348e-02\n",
      "Epoch 16/60\n",
      " - 1s - loss: -4.7062e-01 - output_loss: -4.7066e-01 - variance_output_loss: -4.7066e-01 - output_mean_absolute_error: 0.3103 - output_mean_error: -4.5811e-02 - val_loss: -4.3612e-01 - val_output_loss: -4.3616e-01 - val_variance_output_loss: -4.3616e-01 - val_output_mean_absolute_error: 0.3229 - val_output_mean_error: -5.0163e-02\n",
      "Epoch 17/60\n",
      " - 1s - loss: -4.7652e-01 - output_loss: -4.7656e-01 - variance_output_loss: -4.7656e-01 - output_mean_absolute_error: 0.3115 - output_mean_error: -4.5380e-02 - val_loss: -4.5304e-01 - val_output_loss: -4.5308e-01 - val_variance_output_loss: -4.5308e-01 - val_output_mean_absolute_error: 0.3193 - val_output_mean_error: -3.9451e-02\n",
      "Epoch 18/60\n",
      " - 1s - loss: -4.9698e-01 - output_loss: -4.9702e-01 - variance_output_loss: -4.9702e-01 - output_mean_absolute_error: 0.3022 - output_mean_error: -4.3623e-02 - val_loss: -5.4620e-01 - val_output_loss: -5.4624e-01 - val_variance_output_loss: -5.4624e-01 - val_output_mean_absolute_error: 0.2952 - val_output_mean_error: -7.2464e-02\n",
      "Epoch 19/60\n",
      " - 1s - loss: -5.2812e-01 - output_loss: -5.2815e-01 - variance_output_loss: -5.2815e-01 - output_mean_absolute_error: 0.2946 - output_mean_error: -3.9589e-02 - val_loss: -4.8046e-01 - val_output_loss: -4.8050e-01 - val_variance_output_loss: -4.8050e-01 - val_output_mean_absolute_error: 0.3204 - val_output_mean_error: -8.3050e-02\n",
      "Epoch 20/60\n",
      " - 1s - loss: -5.4005e-01 - output_loss: -5.4009e-01 - variance_output_loss: -5.4009e-01 - output_mean_absolute_error: 0.2935 - output_mean_error: -4.6693e-02 - val_loss: -5.4248e-01 - val_output_loss: -5.4251e-01 - val_variance_output_loss: -5.4251e-01 - val_output_mean_absolute_error: 0.2996 - val_output_mean_error: -7.0579e-02\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 21/60\n",
      " - 1s - loss: -5.6359e-01 - output_loss: -5.6362e-01 - variance_output_loss: -5.6362e-01 - output_mean_absolute_error: 0.2911 - output_mean_error: -5.0466e-02 - val_loss: -5.5487e-01 - val_output_loss: -5.5490e-01 - val_variance_output_loss: -5.5490e-01 - val_output_mean_absolute_error: 0.2979 - val_output_mean_error: -5.8315e-02\n",
      "Epoch 22/60\n",
      " - 1s - loss: -5.9380e-01 - output_loss: -5.9384e-01 - variance_output_loss: -5.9384e-01 - output_mean_absolute_error: 0.2812 - output_mean_error: -4.6592e-02 - val_loss: -5.7216e-01 - val_output_loss: -5.7220e-01 - val_variance_output_loss: -5.7220e-01 - val_output_mean_absolute_error: 0.2862 - val_output_mean_error: -3.1567e-02\n",
      "Epoch 23/60\n",
      " - 1s - loss: -5.9068e-01 - output_loss: -5.9072e-01 - variance_output_loss: -5.9072e-01 - output_mean_absolute_error: 0.2831 - output_mean_error: -4.6690e-02 - val_loss: -5.7360e-01 - val_output_loss: -5.7364e-01 - val_variance_output_loss: -5.7364e-01 - val_output_mean_absolute_error: 0.2945 - val_output_mean_error: -7.7808e-02\n",
      "Epoch 24/60\n",
      " - 1s - loss: -6.1886e-01 - output_loss: -6.1890e-01 - variance_output_loss: -6.1890e-01 - output_mean_absolute_error: 0.2753 - output_mean_error: -4.7970e-02 - val_loss: -5.8481e-01 - val_output_loss: -5.8484e-01 - val_variance_output_loss: -5.8484e-01 - val_output_mean_absolute_error: 0.2912 - val_output_mean_error: -6.0367e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      " - 1s - loss: -6.1999e-01 - output_loss: -6.2002e-01 - variance_output_loss: -6.2002e-01 - output_mean_absolute_error: 0.2770 - output_mean_error: -4.7253e-02 - val_loss: -5.7606e-01 - val_output_loss: -5.7610e-01 - val_variance_output_loss: -5.7610e-01 - val_output_mean_absolute_error: 0.2799 - val_output_mean_error: -1.5074e-02\n",
      "Epoch 26/60\n",
      " - 1s - loss: -6.4233e-01 - output_loss: -6.4237e-01 - variance_output_loss: -6.4237e-01 - output_mean_absolute_error: 0.2702 - output_mean_error: -4.9055e-02 - val_loss: -5.9083e-01 - val_output_loss: -5.9087e-01 - val_variance_output_loss: -5.9087e-01 - val_output_mean_absolute_error: 0.2864 - val_output_mean_error: -6.1571e-02\n",
      "Epoch 27/60\n",
      " - 1s - loss: -6.3771e-01 - output_loss: -6.3774e-01 - variance_output_loss: -6.3774e-01 - output_mean_absolute_error: 0.2727 - output_mean_error: -4.5161e-02 - val_loss: -5.5470e-01 - val_output_loss: -5.5474e-01 - val_variance_output_loss: -5.5474e-01 - val_output_mean_absolute_error: 0.2904 - val_output_mean_error: -8.3731e-02\n",
      "Epoch 28/60\n",
      " - 1s - loss: -6.5524e-01 - output_loss: -6.5527e-01 - variance_output_loss: -6.5527e-01 - output_mean_absolute_error: 0.2685 - output_mean_error: -5.1841e-02 - val_loss: -6.2623e-01 - val_output_loss: -6.2627e-01 - val_variance_output_loss: -6.2627e-01 - val_output_mean_absolute_error: 0.2747 - val_output_mean_error: -3.2007e-02\n",
      "Epoch 29/60\n",
      " - 1s - loss: -6.6836e-01 - output_loss: -6.6839e-01 - variance_output_loss: -6.6839e-01 - output_mean_absolute_error: 0.2671 - output_mean_error: -5.1056e-02 - val_loss: -6.3817e-01 - val_output_loss: -6.3820e-01 - val_variance_output_loss: -6.3820e-01 - val_output_mean_absolute_error: 0.2742 - val_output_mean_error: -4.6757e-02\n",
      "Epoch 30/60\n",
      " - 1s - loss: -6.7357e-01 - output_loss: -6.7361e-01 - variance_output_loss: -6.7361e-01 - output_mean_absolute_error: 0.2625 - output_mean_error: -4.1177e-02 - val_loss: -5.8641e-01 - val_output_loss: -5.8644e-01 - val_variance_output_loss: -5.8644e-01 - val_output_mean_absolute_error: 0.2869 - val_output_mean_error: -6.1830e-02\n",
      "Epoch 31/60\n",
      " - 1s - loss: -6.7191e-01 - output_loss: -6.7195e-01 - variance_output_loss: -6.7195e-01 - output_mean_absolute_error: 0.2649 - output_mean_error: -4.6891e-02 - val_loss: -6.1020e-01 - val_output_loss: -6.1024e-01 - val_variance_output_loss: -6.1024e-01 - val_output_mean_absolute_error: 0.2859 - val_output_mean_error: -4.5396e-02\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 32/60\n",
      " - 1s - loss: -6.7710e-01 - output_loss: -6.7713e-01 - variance_output_loss: -6.7713e-01 - output_mean_absolute_error: 0.2634 - output_mean_error: -4.8855e-02 - val_loss: -6.6557e-01 - val_output_loss: -6.6561e-01 - val_variance_output_loss: -6.6561e-01 - val_output_mean_absolute_error: 0.2701 - val_output_mean_error: -6.7951e-02\n",
      "Epoch 33/60\n",
      " - 1s - loss: -6.8976e-01 - output_loss: -6.8980e-01 - variance_output_loss: -6.8980e-01 - output_mean_absolute_error: 0.2563 - output_mean_error: -4.2479e-02 - val_loss: -6.4562e-01 - val_output_loss: -6.4566e-01 - val_variance_output_loss: -6.4566e-01 - val_output_mean_absolute_error: 0.2714 - val_output_mean_error: -6.1143e-02\n",
      "Epoch 34/60\n",
      " - 1s - loss: -7.0055e-01 - output_loss: -7.0059e-01 - variance_output_loss: -7.0059e-01 - output_mean_absolute_error: 0.2604 - output_mean_error: -4.9759e-02 - val_loss: -6.4239e-01 - val_output_loss: -6.4243e-01 - val_variance_output_loss: -6.4243e-01 - val_output_mean_absolute_error: 0.2760 - val_output_mean_error: -6.5576e-02\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 35/60\n",
      " - 1s - loss: -6.9963e-01 - output_loss: -6.9967e-01 - variance_output_loss: -6.9967e-01 - output_mean_absolute_error: 0.2592 - output_mean_error: -5.0124e-02 - val_loss: -6.5920e-01 - val_output_loss: -6.5923e-01 - val_variance_output_loss: -6.5923e-01 - val_output_mean_absolute_error: 0.2676 - val_output_mean_error: -5.6165e-02\n",
      "Epoch 36/60\n",
      " - 1s - loss: -6.9475e-01 - output_loss: -6.9479e-01 - variance_output_loss: -6.9479e-01 - output_mean_absolute_error: 0.2610 - output_mean_error: -4.9005e-02 - val_loss: -6.7184e-01 - val_output_loss: -6.7187e-01 - val_variance_output_loss: -6.7187e-01 - val_output_mean_absolute_error: 0.2658 - val_output_mean_error: -5.5591e-02\n",
      "Epoch 37/60\n",
      " - 1s - loss: -7.1592e-01 - output_loss: -7.1596e-01 - variance_output_loss: -7.1596e-01 - output_mean_absolute_error: 0.2548 - output_mean_error: -4.5856e-02 - val_loss: -6.0038e-01 - val_output_loss: -6.0042e-01 - val_variance_output_loss: -6.0042e-01 - val_output_mean_absolute_error: 0.2924 - val_output_mean_error: -9.9091e-02\n",
      "Epoch 38/60\n",
      " - 1s - loss: -7.1783e-01 - output_loss: -7.1786e-01 - variance_output_loss: -7.1786e-01 - output_mean_absolute_error: 0.2543 - output_mean_error: -4.7130e-02 - val_loss: -6.4248e-01 - val_output_loss: -6.4252e-01 - val_variance_output_loss: -6.4252e-01 - val_output_mean_absolute_error: 0.2757 - val_output_mean_error: -6.8485e-02\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 39/60\n",
      " - 1s - loss: -7.0825e-01 - output_loss: -7.0828e-01 - variance_output_loss: -7.0828e-01 - output_mean_absolute_error: 0.2577 - output_mean_error: -5.2510e-02 - val_loss: -6.2695e-01 - val_output_loss: -6.2699e-01 - val_variance_output_loss: -6.2699e-01 - val_output_mean_absolute_error: 0.2821 - val_output_mean_error: -5.6494e-02\n",
      "Epoch 40/60\n",
      " - 1s - loss: -7.1154e-01 - output_loss: -7.1158e-01 - variance_output_loss: -7.1158e-01 - output_mean_absolute_error: 0.2561 - output_mean_error: -4.8627e-02 - val_loss: -6.7928e-01 - val_output_loss: -6.7932e-01 - val_variance_output_loss: -6.7932e-01 - val_output_mean_absolute_error: 0.2616 - val_output_mean_error: -4.4266e-02\n",
      "Epoch 41/60\n",
      " - 1s - loss: -7.1739e-01 - output_loss: -7.1743e-01 - variance_output_loss: -7.1743e-01 - output_mean_absolute_error: 0.2543 - output_mean_error: -4.3517e-02 - val_loss: -6.8675e-01 - val_output_loss: -6.8679e-01 - val_variance_output_loss: -6.8679e-01 - val_output_mean_absolute_error: 0.2664 - val_output_mean_error: -6.6413e-02\n",
      "Epoch 42/60\n",
      " - 1s - loss: -7.1428e-01 - output_loss: -7.1431e-01 - variance_output_loss: -7.1431e-01 - output_mean_absolute_error: 0.2562 - output_mean_error: -4.7282e-02 - val_loss: -6.9843e-01 - val_output_loss: -6.9846e-01 - val_variance_output_loss: -6.9846e-01 - val_output_mean_absolute_error: 0.2610 - val_output_mean_error: -5.0114e-02\n",
      "Epoch 43/60\n",
      " - 1s - loss: -7.1004e-01 - output_loss: -7.1007e-01 - variance_output_loss: -7.1007e-01 - output_mean_absolute_error: 0.2571 - output_mean_error: -4.9552e-02 - val_loss: -7.1167e-01 - val_output_loss: -7.1170e-01 - val_variance_output_loss: -7.1170e-01 - val_output_mean_absolute_error: 0.2492 - val_output_mean_error: -3.5249e-02\n",
      "Epoch 44/60\n",
      " - 1s - loss: -7.1416e-01 - output_loss: -7.1420e-01 - variance_output_loss: -7.1420e-01 - output_mean_absolute_error: 0.2555 - output_mean_error: -4.8074e-02 - val_loss: -6.8667e-01 - val_output_loss: -6.8671e-01 - val_variance_output_loss: -6.8671e-01 - val_output_mean_absolute_error: 0.2677 - val_output_mean_error: -8.1437e-02\n",
      "Epoch 45/60\n",
      " - 1s - loss: -7.1271e-01 - output_loss: -7.1275e-01 - variance_output_loss: -7.1275e-01 - output_mean_absolute_error: 0.2561 - output_mean_error: -4.9583e-02 - val_loss: -6.6597e-01 - val_output_loss: -6.6601e-01 - val_variance_output_loss: -6.6601e-01 - val_output_mean_absolute_error: 0.2770 - val_output_mean_error: -5.1167e-02\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 46/60\n",
      " - 1s - loss: -7.2295e-01 - output_loss: -7.2299e-01 - variance_output_loss: -7.2299e-01 - output_mean_absolute_error: 0.2556 - output_mean_error: -4.6373e-02 - val_loss: -7.0761e-01 - val_output_loss: -7.0764e-01 - val_variance_output_loss: -7.0764e-01 - val_output_mean_absolute_error: 0.2528 - val_output_mean_error: -5.6872e-02\n",
      "Epoch 47/60\n",
      " - 1s - loss: -7.2566e-01 - output_loss: -7.2570e-01 - variance_output_loss: -7.2570e-01 - output_mean_absolute_error: 0.2535 - output_mean_error: -4.6778e-02 - val_loss: -6.6340e-01 - val_output_loss: -6.6344e-01 - val_variance_output_loss: -6.6344e-01 - val_output_mean_absolute_error: 0.2759 - val_output_mean_error: -6.0379e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 48/60\n",
      " - 1s - loss: -7.2763e-01 - output_loss: -7.2766e-01 - variance_output_loss: -7.2766e-01 - output_mean_absolute_error: 0.2531 - output_mean_error: -4.6364e-02 - val_loss: -6.7975e-01 - val_output_loss: -6.7979e-01 - val_variance_output_loss: -6.7979e-01 - val_output_mean_absolute_error: 0.2610 - val_output_mean_error: -4.3606e-02\n",
      "Epoch 49/60\n",
      " - 1s - loss: -7.1042e-01 - output_loss: -7.1045e-01 - variance_output_loss: -7.1045e-01 - output_mean_absolute_error: 0.2556 - output_mean_error: -4.7519e-02 - val_loss: -6.8541e-01 - val_output_loss: -6.8545e-01 - val_variance_output_loss: -6.8545e-01 - val_output_mean_absolute_error: 0.2628 - val_output_mean_error: -4.3982e-02\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 50/60\n",
      " - 1s - loss: -7.2705e-01 - output_loss: -7.2708e-01 - variance_output_loss: -7.2708e-01 - output_mean_absolute_error: 0.2516 - output_mean_error: -4.8473e-02 - val_loss: -6.7938e-01 - val_output_loss: -6.7942e-01 - val_variance_output_loss: -6.7942e-01 - val_output_mean_absolute_error: 0.2586 - val_output_mean_error: -4.5497e-02\n",
      "Epoch 51/60\n",
      " - 1s - loss: -7.3315e-01 - output_loss: -7.3319e-01 - variance_output_loss: -7.3319e-01 - output_mean_absolute_error: 0.2516 - output_mean_error: -4.7689e-02 - val_loss: -6.9292e-01 - val_output_loss: -6.9295e-01 - val_variance_output_loss: -6.9295e-01 - val_output_mean_absolute_error: 0.2628 - val_output_mean_error: -7.6161e-02\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 52/60\n",
      " - 1s - loss: -7.1679e-01 - output_loss: -7.1683e-01 - variance_output_loss: -7.1683e-01 - output_mean_absolute_error: 0.2559 - output_mean_error: -4.4887e-02 - val_loss: -6.9563e-01 - val_output_loss: -6.9567e-01 - val_variance_output_loss: -6.9567e-01 - val_output_mean_absolute_error: 0.2604 - val_output_mean_error: -6.6911e-02\n",
      "Epoch 53/60\n",
      " - 1s - loss: -7.2338e-01 - output_loss: -7.2341e-01 - variance_output_loss: -7.2341e-01 - output_mean_absolute_error: 0.2561 - output_mean_error: -5.0355e-02 - val_loss: -6.7056e-01 - val_output_loss: -6.7059e-01 - val_variance_output_loss: -6.7059e-01 - val_output_mean_absolute_error: 0.2701 - val_output_mean_error: -5.1736e-02\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 54/60\n",
      " - 1s - loss: -7.3201e-01 - output_loss: -7.3205e-01 - variance_output_loss: -7.3205e-01 - output_mean_absolute_error: 0.2507 - output_mean_error: -4.1544e-02 - val_loss: -6.6218e-01 - val_output_loss: -6.6222e-01 - val_variance_output_loss: -6.6222e-01 - val_output_mean_absolute_error: 0.2768 - val_output_mean_error: -5.9612e-02\n",
      "Epoch 55/60\n",
      " - 1s - loss: -7.2595e-01 - output_loss: -7.2599e-01 - variance_output_loss: -7.2599e-01 - output_mean_absolute_error: 0.2525 - output_mean_error: -4.4214e-02 - val_loss: -6.1947e-01 - val_output_loss: -6.1950e-01 - val_variance_output_loss: -6.1950e-01 - val_output_mean_absolute_error: 0.2859 - val_output_mean_error: -6.4901e-02\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 56/60\n",
      " - 1s - loss: -7.2270e-01 - output_loss: -7.2273e-01 - variance_output_loss: -7.2273e-01 - output_mean_absolute_error: 0.2545 - output_mean_error: -5.1423e-02 - val_loss: -6.7558e-01 - val_output_loss: -6.7562e-01 - val_variance_output_loss: -6.7562e-01 - val_output_mean_absolute_error: 0.2617 - val_output_mean_error: -4.5484e-02\n",
      "Epoch 57/60\n",
      " - 1s - loss: -7.3636e-01 - output_loss: -7.3640e-01 - variance_output_loss: -7.3640e-01 - output_mean_absolute_error: 0.2489 - output_mean_error: -4.4060e-02 - val_loss: -6.7112e-01 - val_output_loss: -6.7116e-01 - val_variance_output_loss: -6.7116e-01 - val_output_mean_absolute_error: 0.2747 - val_output_mean_error: -7.2268e-02\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 58/60\n",
      " - 1s - loss: -7.0662e-01 - output_loss: -7.0665e-01 - variance_output_loss: -7.0665e-01 - output_mean_absolute_error: 0.2574 - output_mean_error: -4.7206e-02 - val_loss: -6.4640e-01 - val_output_loss: -6.4644e-01 - val_variance_output_loss: -6.4644e-01 - val_output_mean_absolute_error: 0.2769 - val_output_mean_error: -4.2072e-02\n",
      "Epoch 59/60\n",
      " - 1s - loss: -7.1546e-01 - output_loss: -7.1549e-01 - variance_output_loss: -7.1549e-01 - output_mean_absolute_error: 0.2546 - output_mean_error: -4.4289e-02 - val_loss: -6.2130e-01 - val_output_loss: -6.2134e-01 - val_variance_output_loss: -6.2134e-01 - val_output_mean_absolute_error: 0.2733 - val_output_mean_error: -7.0757e-02\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 60/60\n",
      " - 1s - loss: -7.2503e-01 - output_loss: -7.2507e-01 - variance_output_loss: -7.2507e-01 - output_mean_absolute_error: 0.2532 - output_mean_error: -4.7736e-02 - val_loss: -7.0365e-01 - val_output_loss: -7.0368e-01 - val_variance_output_loss: -7.0368e-01 - val_output_mean_absolute_error: 0.2518 - val_output_mean_error: -4.6315e-02\n",
      "Completed Training, 78.48s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_adaptive_6_25/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [128, 48, 24, 12, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_adaptive_6_25'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/16), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 939, Number of Validation Data: 104\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 6s - loss: 0.4702 - output_loss: 0.4702 - variance_output_loss: 0.4702 - output_mean_absolute_error: 0.6985 - output_mean_error: 0.0070 - val_loss: 0.5654 - val_output_loss: 0.5654 - val_variance_output_loss: 0.5654 - val_output_mean_absolute_error: 0.7411 - val_output_mean_error: -8.1072e-02\n",
      "Epoch 2/60\n",
      " - 1s - loss: 0.4721 - output_loss: 0.4720 - variance_output_loss: 0.4720 - output_mean_absolute_error: 0.6961 - output_mean_error: -1.5609e-02 - val_loss: 0.5563 - val_output_loss: 0.5563 - val_variance_output_loss: 0.5563 - val_output_mean_absolute_error: 0.7070 - val_output_mean_error: -2.0103e-01\n",
      "Epoch 3/60\n",
      " - 1s - loss: 0.4345 - output_loss: 0.4345 - variance_output_loss: 0.4345 - output_mean_absolute_error: 0.6673 - output_mean_error: -3.4875e-02 - val_loss: 0.5412 - val_output_loss: 0.5412 - val_variance_output_loss: 0.5412 - val_output_mean_absolute_error: 0.7242 - val_output_mean_error: -2.1289e-01\n",
      "Epoch 4/60\n",
      " - 1s - loss: 0.4071 - output_loss: 0.4071 - variance_output_loss: 0.4071 - output_mean_absolute_error: 0.6471 - output_mean_error: -1.3065e-03 - val_loss: 0.4862 - val_output_loss: 0.4862 - val_variance_output_loss: 0.4862 - val_output_mean_absolute_error: 0.6668 - val_output_mean_error: -8.8254e-02\n",
      "Epoch 5/60\n",
      " - 1s - loss: 0.4624 - output_loss: 0.4623 - variance_output_loss: 0.4623 - output_mean_absolute_error: 0.6804 - output_mean_error: -1.8865e-02 - val_loss: 0.5154 - val_output_loss: 0.5154 - val_variance_output_loss: 0.5154 - val_output_mean_absolute_error: 0.6777 - val_output_mean_error: -8.8144e-02\n",
      "Epoch 6/60\n",
      " - 1s - loss: 0.4331 - output_loss: 0.4331 - variance_output_loss: 0.4331 - output_mean_absolute_error: 0.6305 - output_mean_error: 0.0211 - val_loss: 0.4674 - val_output_loss: 0.4673 - val_variance_output_loss: 0.4673 - val_output_mean_absolute_error: 0.6494 - val_output_mean_error: -3.8058e-02\n",
      "Epoch 7/60\n",
      " - 1s - loss: 0.4274 - output_loss: 0.4274 - variance_output_loss: 0.4274 - output_mean_absolute_error: 0.6456 - output_mean_error: 0.0022 - val_loss: 0.4208 - val_output_loss: 0.4208 - val_variance_output_loss: 0.4208 - val_output_mean_absolute_error: 0.6333 - val_output_mean_error: -5.7178e-02\n",
      "Epoch 8/60\n",
      " - 1s - loss: 0.3172 - output_loss: 0.3171 - variance_output_loss: 0.3171 - output_mean_absolute_error: 0.5938 - output_mean_error: 0.0278 - val_loss: 0.3388 - val_output_loss: 0.3388 - val_variance_output_loss: 0.3388 - val_output_mean_absolute_error: 0.6161 - val_output_mean_error: -9.6494e-02\n",
      "Epoch 9/60\n",
      " - 1s - loss: 0.3031 - output_loss: 0.3030 - variance_output_loss: 0.3030 - output_mean_absolute_error: 0.6000 - output_mean_error: 0.0194 - val_loss: 0.2597 - val_output_loss: 0.2597 - val_variance_output_loss: 0.2597 - val_output_mean_absolute_error: 0.5966 - val_output_mean_error: -1.3064e-01\n",
      "Epoch 10/60\n",
      " - 1s - loss: 0.2573 - output_loss: 0.2572 - variance_output_loss: 0.2572 - output_mean_absolute_error: 0.5761 - output_mean_error: -1.3565e-02 - val_loss: 0.2290 - val_output_loss: 0.2290 - val_variance_output_loss: 0.2290 - val_output_mean_absolute_error: 0.5585 - val_output_mean_error: -5.8656e-02\n",
      "Epoch 11/60\n",
      " - 1s - loss: 0.2042 - output_loss: 0.2042 - variance_output_loss: 0.2042 - output_mean_absolute_error: 0.5530 - output_mean_error: -3.6337e-03 - val_loss: 0.1745 - val_output_loss: 0.1744 - val_variance_output_loss: 0.1744 - val_output_mean_absolute_error: 0.5244 - val_output_mean_error: 0.0125\n",
      "Epoch 12/60\n",
      " - 1s - loss: 0.1594 - output_loss: 0.1594 - variance_output_loss: 0.1594 - output_mean_absolute_error: 0.5278 - output_mean_error: -1.9879e-02 - val_loss: 0.1555 - val_output_loss: 0.1555 - val_variance_output_loss: 0.1555 - val_output_mean_absolute_error: 0.5134 - val_output_mean_error: -5.1147e-02\n",
      "Epoch 13/60\n",
      " - 1s - loss: 0.1484 - output_loss: 0.1484 - variance_output_loss: 0.1484 - output_mean_absolute_error: 0.5186 - output_mean_error: -1.2578e-02 - val_loss: 0.0731 - val_output_loss: 0.0730 - val_variance_output_loss: 0.0730 - val_output_mean_absolute_error: 0.4969 - val_output_mean_error: -1.4282e-01\n",
      "Epoch 14/60\n",
      " - 1s - loss: 0.1162 - output_loss: 0.1161 - variance_output_loss: 0.1161 - output_mean_absolute_error: 0.5047 - output_mean_error: -4.3581e-02 - val_loss: 0.1547 - val_output_loss: 0.1547 - val_variance_output_loss: 0.1547 - val_output_mean_absolute_error: 0.5106 - val_output_mean_error: 0.0307\n",
      "Epoch 15/60\n",
      " - 1s - loss: 0.0582 - output_loss: 0.0582 - variance_output_loss: 0.0582 - output_mean_absolute_error: 0.4693 - output_mean_error: 5.2059e-04 - val_loss: 0.0050 - val_output_loss: 0.0050 - val_variance_output_loss: 0.0050 - val_output_mean_absolute_error: 0.4519 - val_output_mean_error: -9.1165e-02\n",
      "Epoch 16/60\n",
      " - 1s - loss: 0.0400 - output_loss: 0.0400 - variance_output_loss: 0.0400 - output_mean_absolute_error: 0.4677 - output_mean_error: -3.1751e-02 - val_loss: -4.3598e-02 - val_output_loss: -4.3622e-02 - val_variance_output_loss: -4.3622e-02 - val_output_mean_absolute_error: 0.3933 - val_output_mean_error: 0.0330\n",
      "Epoch 17/60\n",
      " - 1s - loss: 0.0175 - output_loss: 0.0175 - variance_output_loss: 0.0175 - output_mean_absolute_error: 0.4551 - output_mean_error: -1.7920e-02 - val_loss: -1.7925e-02 - val_output_loss: -1.7949e-02 - val_variance_output_loss: -1.7949e-02 - val_output_mean_absolute_error: 0.4310 - val_output_mean_error: -4.8365e-02\n",
      "Epoch 18/60\n",
      " - 1s - loss: -6.8029e-03 - output_loss: -6.8269e-03 - variance_output_loss: -6.8269e-03 - output_mean_absolute_error: 0.4472 - output_mean_error: -3.7846e-02 - val_loss: -6.7034e-03 - val_output_loss: -6.7274e-03 - val_variance_output_loss: -6.7274e-03 - val_output_mean_absolute_error: 0.4620 - val_output_mean_error: -1.3561e-02\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/60\n",
      " - 1s - loss: -4.9825e-02 - output_loss: -4.9849e-02 - variance_output_loss: -4.9849e-02 - output_mean_absolute_error: 0.4265 - output_mean_error: -3.1459e-02 - val_loss: 0.0258 - val_output_loss: 0.0258 - val_variance_output_loss: 0.0258 - val_output_mean_absolute_error: 0.4698 - val_output_mean_error: -7.2050e-02\n",
      "Epoch 20/60\n",
      " - 1s - loss: -3.9432e-02 - output_loss: -3.9456e-02 - variance_output_loss: -3.9456e-02 - output_mean_absolute_error: 0.4322 - output_mean_error: -2.3497e-02 - val_loss: -3.3634e-02 - val_output_loss: -3.3659e-02 - val_variance_output_loss: -3.3659e-02 - val_output_mean_absolute_error: 0.4485 - val_output_mean_error: -9.7328e-02\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 21/60\n",
      " - 1s - loss: -6.1959e-02 - output_loss: -6.1983e-02 - variance_output_loss: -6.1983e-02 - output_mean_absolute_error: 0.4257 - output_mean_error: -5.3121e-02 - val_loss: 0.0022 - val_output_loss: 0.0022 - val_variance_output_loss: 0.0022 - val_output_mean_absolute_error: 0.4638 - val_output_mean_error: -1.0686e-01\n",
      "Epoch 22/60\n",
      " - 1s - loss: -7.4321e-02 - output_loss: -7.4345e-02 - variance_output_loss: -7.4345e-02 - output_mean_absolute_error: 0.4218 - output_mean_error: -3.6412e-02 - val_loss: -8.9803e-02 - val_output_loss: -8.9827e-02 - val_variance_output_loss: -8.9827e-02 - val_output_mean_absolute_error: 0.3998 - val_output_mean_error: -5.8993e-02\n",
      "Epoch 23/60\n",
      " - 1s - loss: -7.5505e-02 - output_loss: -7.5530e-02 - variance_output_loss: -7.5530e-02 - output_mean_absolute_error: 0.4166 - output_mean_error: -3.6991e-02 - val_loss: -1.6753e-02 - val_output_loss: -1.6777e-02 - val_variance_output_loss: -1.6777e-02 - val_output_mean_absolute_error: 0.4253 - val_output_mean_error: -1.5790e-02\n",
      "Epoch 24/60\n",
      " - 1s - loss: -6.3862e-02 - output_loss: -6.3887e-02 - variance_output_loss: -6.3887e-02 - output_mean_absolute_error: 0.4275 - output_mean_error: -4.5461e-02 - val_loss: -5.1243e-02 - val_output_loss: -5.1267e-02 - val_variance_output_loss: -5.1267e-02 - val_output_mean_absolute_error: 0.4326 - val_output_mean_error: -7.9013e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 25/60\n",
      " - 1s - loss: -7.7261e-02 - output_loss: -7.7285e-02 - variance_output_loss: -7.7285e-02 - output_mean_absolute_error: 0.4195 - output_mean_error: -4.3163e-02 - val_loss: 0.0060 - val_output_loss: 0.0060 - val_variance_output_loss: 0.0060 - val_output_mean_absolute_error: 0.4795 - val_output_mean_error: -1.1291e-01\n",
      "Epoch 26/60\n",
      " - 1s - loss: -8.1956e-02 - output_loss: -8.1980e-02 - variance_output_loss: -8.1980e-02 - output_mean_absolute_error: 0.4151 - output_mean_error: -4.0504e-02 - val_loss: -6.1774e-02 - val_output_loss: -6.1798e-02 - val_variance_output_loss: -6.1798e-02 - val_output_mean_absolute_error: 0.4255 - val_output_mean_error: -1.3252e-01\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 27/60\n",
      " - 1s - loss: -7.4838e-02 - output_loss: -7.4862e-02 - variance_output_loss: -7.4862e-02 - output_mean_absolute_error: 0.4176 - output_mean_error: -3.6058e-02 - val_loss: -1.4880e-02 - val_output_loss: -1.4905e-02 - val_variance_output_loss: -1.4905e-02 - val_output_mean_absolute_error: 0.4254 - val_output_mean_error: -4.4931e-02\n",
      "Epoch 28/60\n",
      " - 1s - loss: -8.4649e-02 - output_loss: -8.4674e-02 - variance_output_loss: -8.4674e-02 - output_mean_absolute_error: 0.4180 - output_mean_error: -4.5166e-02 - val_loss: -7.3901e-02 - val_output_loss: -7.3925e-02 - val_variance_output_loss: -7.3925e-02 - val_output_mean_absolute_error: 0.4049 - val_output_mean_error: -5.5512e-02\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 29/60\n",
      " - 1s - loss: -9.9692e-02 - output_loss: -9.9716e-02 - variance_output_loss: -9.9716e-02 - output_mean_absolute_error: 0.4094 - output_mean_error: -3.8057e-02 - val_loss: -6.4064e-02 - val_output_loss: -6.4088e-02 - val_variance_output_loss: -6.4088e-02 - val_output_mean_absolute_error: 0.4349 - val_output_mean_error: -5.6630e-02\n",
      "Epoch 30/60\n",
      " - 1s - loss: -8.3757e-02 - output_loss: -8.3781e-02 - variance_output_loss: -8.3781e-02 - output_mean_absolute_error: 0.4135 - output_mean_error: -3.2001e-02 - val_loss: -6.5574e-02 - val_output_loss: -6.5598e-02 - val_variance_output_loss: -6.5598e-02 - val_output_mean_absolute_error: 0.4173 - val_output_mean_error: -2.7537e-02\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 31/60\n",
      " - 1s - loss: -8.6502e-02 - output_loss: -8.6526e-02 - variance_output_loss: -8.6526e-02 - output_mean_absolute_error: 0.4224 - output_mean_error: -5.7681e-02 - val_loss: -9.8927e-02 - val_output_loss: -9.8951e-02 - val_variance_output_loss: -9.8951e-02 - val_output_mean_absolute_error: 0.3952 - val_output_mean_error: -1.1321e-02\n",
      "Epoch 32/60\n",
      " - 1s - loss: -7.9353e-02 - output_loss: -7.9378e-02 - variance_output_loss: -7.9378e-02 - output_mean_absolute_error: 0.4119 - output_mean_error: -2.8961e-02 - val_loss: -2.2965e-02 - val_output_loss: -2.2989e-02 - val_variance_output_loss: -2.2989e-02 - val_output_mean_absolute_error: 0.4592 - val_output_mean_error: -6.7754e-02\n",
      "Epoch 33/60\n",
      " - 1s - loss: -8.6423e-02 - output_loss: -8.6447e-02 - variance_output_loss: -8.6447e-02 - output_mean_absolute_error: 0.4153 - output_mean_error: -3.7533e-02 - val_loss: -3.2443e-02 - val_output_loss: -3.2467e-02 - val_variance_output_loss: -3.2467e-02 - val_output_mean_absolute_error: 0.4484 - val_output_mean_error: -5.8024e-02\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 34/60\n",
      " - 1s - loss: -7.8449e-02 - output_loss: -7.8474e-02 - variance_output_loss: -7.8474e-02 - output_mean_absolute_error: 0.4177 - output_mean_error: -5.5511e-02 - val_loss: -5.8511e-03 - val_output_loss: -5.8754e-03 - val_variance_output_loss: -5.8754e-03 - val_output_mean_absolute_error: 0.4497 - val_output_mean_error: -1.0247e-01\n",
      "Epoch 35/60\n",
      " - 1s - loss: -9.7502e-02 - output_loss: -9.7526e-02 - variance_output_loss: -9.7526e-02 - output_mean_absolute_error: 0.4082 - output_mean_error: -3.9810e-02 - val_loss: -4.5232e-02 - val_output_loss: -4.5256e-02 - val_variance_output_loss: -4.5256e-02 - val_output_mean_absolute_error: 0.4346 - val_output_mean_error: -5.8944e-02\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 36/60\n",
      " - 1s - loss: -7.5525e-02 - output_loss: -7.5549e-02 - variance_output_loss: -7.5549e-02 - output_mean_absolute_error: 0.4184 - output_mean_error: -3.5361e-02 - val_loss: -2.5875e-02 - val_output_loss: -2.5900e-02 - val_variance_output_loss: -2.5900e-02 - val_output_mean_absolute_error: 0.4502 - val_output_mean_error: -6.2656e-02\n",
      "Epoch 37/60\n",
      " - 1s - loss: -8.3190e-02 - output_loss: -8.3214e-02 - variance_output_loss: -8.3214e-02 - output_mean_absolute_error: 0.4085 - output_mean_error: -3.2393e-02 - val_loss: -6.7465e-02 - val_output_loss: -6.7489e-02 - val_variance_output_loss: -6.7489e-02 - val_output_mean_absolute_error: 0.4292 - val_output_mean_error: -8.8962e-02\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 38/60\n",
      " - 1s - loss: -9.5933e-02 - output_loss: -9.5957e-02 - variance_output_loss: -9.5957e-02 - output_mean_absolute_error: 0.4106 - output_mean_error: -4.2700e-02 - val_loss: -7.7870e-02 - val_output_loss: -7.7894e-02 - val_variance_output_loss: -7.7894e-02 - val_output_mean_absolute_error: 0.4093 - val_output_mean_error: -5.0053e-02\n",
      "Epoch 39/60\n",
      " - 1s - loss: -8.6384e-02 - output_loss: -8.6408e-02 - variance_output_loss: -8.6408e-02 - output_mean_absolute_error: 0.4175 - output_mean_error: -4.7692e-02 - val_loss: -7.2822e-02 - val_output_loss: -7.2846e-02 - val_variance_output_loss: -7.2846e-02 - val_output_mean_absolute_error: 0.4056 - val_output_mean_error: -2.4213e-02\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 40/60\n",
      " - 1s - loss: -9.2657e-02 - output_loss: -9.2681e-02 - variance_output_loss: -9.2681e-02 - output_mean_absolute_error: 0.4104 - output_mean_error: -4.2252e-02 - val_loss: -8.5407e-02 - val_output_loss: -8.5432e-02 - val_variance_output_loss: -8.5432e-02 - val_output_mean_absolute_error: 0.4087 - val_output_mean_error: -9.7826e-02\n",
      "Epoch 41/60\n",
      " - 1s - loss: -8.3768e-02 - output_loss: -8.3792e-02 - variance_output_loss: -8.3792e-02 - output_mean_absolute_error: 0.4163 - output_mean_error: -4.4968e-02 - val_loss: -3.8966e-02 - val_output_loss: -3.8990e-02 - val_variance_output_loss: -3.8990e-02 - val_output_mean_absolute_error: 0.4436 - val_output_mean_error: -8.9658e-02\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 42/60\n",
      " - 1s - loss: -9.2187e-02 - output_loss: -9.2211e-02 - variance_output_loss: -9.2211e-02 - output_mean_absolute_error: 0.4106 - output_mean_error: -3.6953e-02 - val_loss: -8.6588e-02 - val_output_loss: -8.6612e-02 - val_variance_output_loss: -8.6612e-02 - val_output_mean_absolute_error: 0.3994 - val_output_mean_error: -1.7296e-02\n",
      "Epoch 43/60\n",
      " - 1s - loss: -9.7498e-02 - output_loss: -9.7523e-02 - variance_output_loss: -9.7523e-02 - output_mean_absolute_error: 0.4049 - output_mean_error: -3.5690e-02 - val_loss: -7.4883e-02 - val_output_loss: -7.4908e-02 - val_variance_output_loss: -7.4908e-02 - val_output_mean_absolute_error: 0.4132 - val_output_mean_error: -3.0051e-02\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 44/60\n",
      " - 1s - loss: -7.7588e-02 - output_loss: -7.7613e-02 - variance_output_loss: -7.7613e-02 - output_mean_absolute_error: 0.4154 - output_mean_error: -3.8728e-02 - val_loss: -5.3953e-02 - val_output_loss: -5.3977e-02 - val_variance_output_loss: -5.3977e-02 - val_output_mean_absolute_error: 0.4348 - val_output_mean_error: -7.3824e-02\n",
      "Epoch 45/60\n",
      " - 1s - loss: -8.1684e-02 - output_loss: -8.1709e-02 - variance_output_loss: -8.1709e-02 - output_mean_absolute_error: 0.4129 - output_mean_error: -4.1726e-02 - val_loss: -6.8290e-02 - val_output_loss: -6.8314e-02 - val_variance_output_loss: -6.8314e-02 - val_output_mean_absolute_error: 0.4167 - val_output_mean_error: -2.0585e-02\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 46/60\n",
      " - 1s - loss: -7.6823e-02 - output_loss: -7.6848e-02 - variance_output_loss: -7.6848e-02 - output_mean_absolute_error: 0.4233 - output_mean_error: -5.0703e-02 - val_loss: -1.9097e-02 - val_output_loss: -1.9121e-02 - val_variance_output_loss: -1.9121e-02 - val_output_mean_absolute_error: 0.4568 - val_output_mean_error: -1.2133e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      " - 1s - loss: -9.8598e-02 - output_loss: -9.8622e-02 - variance_output_loss: -9.8622e-02 - output_mean_absolute_error: 0.4085 - output_mean_error: -3.8240e-02 - val_loss: -5.5680e-02 - val_output_loss: -5.5705e-02 - val_variance_output_loss: -5.5705e-02 - val_output_mean_absolute_error: 0.4393 - val_output_mean_error: -9.2254e-02\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 48/60\n",
      " - 1s - loss: -8.3559e-02 - output_loss: -8.3583e-02 - variance_output_loss: -8.3583e-02 - output_mean_absolute_error: 0.4116 - output_mean_error: -5.4606e-02 - val_loss: -3.1459e-02 - val_output_loss: -3.1484e-02 - val_variance_output_loss: -3.1484e-02 - val_output_mean_absolute_error: 0.4577 - val_output_mean_error: -9.9469e-02\n",
      "Epoch 49/60\n",
      " - 1s - loss: -9.4751e-02 - output_loss: -9.4775e-02 - variance_output_loss: -9.4775e-02 - output_mean_absolute_error: 0.4115 - output_mean_error: -3.3957e-02 - val_loss: -6.2870e-02 - val_output_loss: -6.2894e-02 - val_variance_output_loss: -6.2894e-02 - val_output_mean_absolute_error: 0.4058 - val_output_mean_error: -2.9947e-02\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 50/60\n",
      " - 1s - loss: -8.2971e-02 - output_loss: -8.2995e-02 - variance_output_loss: -8.2995e-02 - output_mean_absolute_error: 0.4157 - output_mean_error: -4.4403e-02 - val_loss: -6.0044e-02 - val_output_loss: -6.0068e-02 - val_variance_output_loss: -6.0068e-02 - val_output_mean_absolute_error: 0.4304 - val_output_mean_error: -9.8082e-02\n",
      "Epoch 51/60\n",
      " - 1s - loss: -9.1160e-02 - output_loss: -9.1184e-02 - variance_output_loss: -9.1184e-02 - output_mean_absolute_error: 0.4129 - output_mean_error: -4.7797e-02 - val_loss: -9.2266e-02 - val_output_loss: -9.2290e-02 - val_variance_output_loss: -9.2290e-02 - val_output_mean_absolute_error: 0.4129 - val_output_mean_error: -4.6071e-02\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "Epoch 52/60\n",
      " - 1s - loss: -8.8130e-02 - output_loss: -8.8154e-02 - variance_output_loss: -8.8154e-02 - output_mean_absolute_error: 0.4119 - output_mean_error: -4.2459e-02 - val_loss: 8.4395e-04 - val_output_loss: 8.1966e-04 - val_variance_output_loss: 8.1966e-04 - val_output_mean_absolute_error: 0.4578 - val_output_mean_error: -7.2216e-02\n",
      "Epoch 53/60\n",
      " - 1s - loss: -9.5176e-02 - output_loss: -9.5200e-02 - variance_output_loss: -9.5200e-02 - output_mean_absolute_error: 0.4095 - output_mean_error: -3.8670e-02 - val_loss: -2.1017e-02 - val_output_loss: -2.1042e-02 - val_variance_output_loss: -2.1042e-02 - val_output_mean_absolute_error: 0.4557 - val_output_mean_error: -9.6711e-02\n",
      "Epoch 54/60\n",
      " - 1s - loss: -8.7573e-02 - output_loss: -8.7597e-02 - variance_output_loss: -8.7597e-02 - output_mean_absolute_error: 0.4180 - output_mean_error: -4.8905e-02 - val_loss: -8.2392e-02 - val_output_loss: -8.2416e-02 - val_variance_output_loss: -8.2416e-02 - val_output_mean_absolute_error: 0.3987 - val_output_mean_error: -1.0152e-02\n",
      "Epoch 55/60\n",
      " - 1s - loss: -8.3442e-02 - output_loss: -8.3466e-02 - variance_output_loss: -8.3466e-02 - output_mean_absolute_error: 0.4109 - output_mean_error: -4.0770e-02 - val_loss: -8.6938e-02 - val_output_loss: -8.6963e-02 - val_variance_output_loss: -8.6963e-02 - val_output_mean_absolute_error: 0.4056 - val_output_mean_error: -6.0933e-02\n",
      "Epoch 56/60\n",
      " - 1s - loss: -9.8761e-02 - output_loss: -9.8785e-02 - variance_output_loss: -9.8785e-02 - output_mean_absolute_error: 0.4068 - output_mean_error: -4.4788e-02 - val_loss: -3.7743e-02 - val_output_loss: -3.7767e-02 - val_variance_output_loss: -3.7767e-02 - val_output_mean_absolute_error: 0.4463 - val_output_mean_error: -9.9572e-02\n",
      "Epoch 57/60\n",
      " - 1s - loss: -8.5701e-02 - output_loss: -8.5726e-02 - variance_output_loss: -8.5726e-02 - output_mean_absolute_error: 0.4136 - output_mean_error: -2.9196e-02 - val_loss: -4.5837e-02 - val_output_loss: -4.5862e-02 - val_variance_output_loss: -4.5862e-02 - val_output_mean_absolute_error: 0.4525 - val_output_mean_error: -8.5722e-02\n",
      "Epoch 58/60\n",
      " - 1s - loss: -9.2291e-02 - output_loss: -9.2316e-02 - variance_output_loss: -9.2316e-02 - output_mean_absolute_error: 0.4151 - output_mean_error: -5.0729e-02 - val_loss: -1.1346e-01 - val_output_loss: -1.1348e-01 - val_variance_output_loss: -1.1348e-01 - val_output_mean_absolute_error: 0.4076 - val_output_mean_error: -2.6760e-02\n",
      "Epoch 59/60\n",
      " - 1s - loss: -8.9954e-02 - output_loss: -8.9978e-02 - variance_output_loss: -8.9978e-02 - output_mean_absolute_error: 0.4159 - output_mean_error: -4.5068e-02 - val_loss: -1.0015e-01 - val_output_loss: -1.0017e-01 - val_variance_output_loss: -1.0017e-01 - val_output_mean_absolute_error: 0.3934 - val_output_mean_error: -2.9055e-02\n",
      "Epoch 60/60\n",
      " - 1s - loss: -7.5229e-02 - output_loss: -7.5253e-02 - variance_output_loss: -7.5253e-02 - output_mean_absolute_error: 0.4170 - output_mean_error: -3.5900e-02 - val_loss: -6.2621e-02 - val_output_loss: -6.2645e-02 - val_variance_output_loss: -6.2645e-02 - val_output_mean_absolute_error: 0.4273 - val_output_mean_error: -5.8237e-02\n",
      "Completed Training, 42.83s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_adaptive_3_125/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [96, 32, 16, 6, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_adaptive_3_125'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/32), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 109.95s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 106.87s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 105.89s elapsed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Data</th>\n",
       "      <th>Scatter</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3758</td>\n",
       "      <td>0.221780</td>\n",
       "      <td>-0.022680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1879</td>\n",
       "      <td>0.263140</td>\n",
       "      <td>-0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>939</td>\n",
       "      <td>0.426591</td>\n",
       "      <td>-0.000090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Data   Scatter      Bias\n",
       "0            3758  0.221780 -0.022680\n",
       "1            1879  0.263140 -0.001169\n",
       "2             939  0.426591 -0.000090"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.stats import mad_std\n",
    "\n",
    "from astroNN.models import load_folder\n",
    "from astroNN.datasets import H5Loader\n",
    "\n",
    "loader = H5Loader('_highsnr_test')  # continuum normalized dataset\n",
    "loader.load_err = False\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y = loader.load()\n",
    "\n",
    "mae = []\n",
    "me = []\n",
    "\n",
    "net_12_5 = load_folder(\"small_data_adaptive_12_5\")\n",
    "net_12_5_pred, err = net_12_5.test(x)\n",
    "residue = ((net_12_5_pred - y) / net_12_5.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_6_25 = load_folder(\"small_data_adaptive_6_25\")\n",
    "net_6_25_pred, err = net_6_25.test(x)\n",
    "residue = ((net_6_25_pred - y) / net_6_25.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_3_125 = load_folder(\"small_data_adaptive_3_125\")\n",
    "net_3_125_pred, err = net_3_125.test(x)\n",
    "residue = ((net_3_125_pred - y) / net_3_125.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "\n",
    "d = {'Number of Data': [3758, 1879, 939], 'Scatter': mae, 'Bias': me}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
