{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 15033, Number of Validation Data: 1670\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 15s - loss: 0.1852 - output_loss: 0.1852 - variance_output_loss: 0.1852 - output_mean_absolute_error: 0.5726 - output_mean_error: -4.7036e-02 - val_loss: -1.3395e-01 - val_output_loss: -1.3399e-01 - val_variance_output_loss: -1.3399e-01 - val_output_mean_absolute_error: 0.4540 - val_output_mean_error: -7.8906e-02\n",
      "Epoch 2/60\n",
      " - 9s - loss: -3.5270e-01 - output_loss: -3.5274e-01 - variance_output_loss: -3.5274e-01 - output_mean_absolute_error: 0.3750 - output_mean_error: -5.5414e-02 - val_loss: -4.7807e-01 - val_output_loss: -4.7812e-01 - val_variance_output_loss: -4.7812e-01 - val_output_mean_absolute_error: 0.3417 - val_output_mean_error: -9.0919e-02\n",
      "Epoch 3/60\n",
      " - 9s - loss: -6.1332e-01 - output_loss: -6.1337e-01 - variance_output_loss: -6.1337e-01 - output_mean_absolute_error: 0.2909 - output_mean_error: -3.3768e-02 - val_loss: -6.8704e-01 - val_output_loss: -6.8709e-01 - val_variance_output_loss: -6.8709e-01 - val_output_mean_absolute_error: 0.2717 - val_output_mean_error: -4.5009e-02\n",
      "Epoch 4/60\n",
      " - 9s - loss: -7.7622e-01 - output_loss: -7.7627e-01 - variance_output_loss: -7.7627e-01 - output_mean_absolute_error: 0.2400 - output_mean_error: -2.0939e-02 - val_loss: -8.2092e-01 - val_output_loss: -8.2097e-01 - val_variance_output_loss: -8.2097e-01 - val_output_mean_absolute_error: 0.2305 - val_output_mean_error: -5.0615e-02\n",
      "Epoch 5/60\n",
      " - 9s - loss: -8.7958e-01 - output_loss: -8.7963e-01 - variance_output_loss: -8.7963e-01 - output_mean_absolute_error: 0.2127 - output_mean_error: -1.2551e-02 - val_loss: -9.0689e-01 - val_output_loss: -9.0694e-01 - val_variance_output_loss: -9.0694e-01 - val_output_mean_absolute_error: 0.2096 - val_output_mean_error: -5.2356e-02\n",
      "Epoch 6/60\n",
      " - 9s - loss: -9.5767e-01 - output_loss: -9.5772e-01 - variance_output_loss: -9.5772e-01 - output_mean_absolute_error: 0.1992 - output_mean_error: -1.1098e-02 - val_loss: -9.5950e-01 - val_output_loss: -9.5955e-01 - val_variance_output_loss: -9.5955e-01 - val_output_mean_absolute_error: 0.2020 - val_output_mean_error: -3.6878e-02\n",
      "Epoch 7/60\n",
      " - 10s - loss: -1.0215e+00 - output_loss: -1.0216e+00 - variance_output_loss: -1.0216e+00 - output_mean_absolute_error: 0.1869 - output_mean_error: -9.0247e-03 - val_loss: -9.8939e-01 - val_output_loss: -9.8944e-01 - val_variance_output_loss: -9.8944e-01 - val_output_mean_absolute_error: 0.1982 - val_output_mean_error: -4.6845e-02\n",
      "Epoch 8/60\n",
      " - 9s - loss: -1.0619e+00 - output_loss: -1.0619e+00 - variance_output_loss: -1.0619e+00 - output_mean_absolute_error: 0.1807 - output_mean_error: -8.6494e-03 - val_loss: -1.0414e+00 - val_output_loss: -1.0414e+00 - val_variance_output_loss: -1.0414e+00 - val_output_mean_absolute_error: 0.1855 - val_output_mean_error: -2.4043e-02\n",
      "Epoch 9/60\n",
      " - 9s - loss: -1.0902e+00 - output_loss: -1.0902e+00 - variance_output_loss: -1.0902e+00 - output_mean_absolute_error: 0.1773 - output_mean_error: -8.3523e-03 - val_loss: -1.0650e+00 - val_output_loss: -1.0650e+00 - val_variance_output_loss: -1.0650e+00 - val_output_mean_absolute_error: 0.1832 - val_output_mean_error: -3.6371e-02\n",
      "Epoch 10/60\n",
      " - 9s - loss: -1.1231e+00 - output_loss: -1.1232e+00 - variance_output_loss: -1.1232e+00 - output_mean_absolute_error: 0.1723 - output_mean_error: -7.3849e-03 - val_loss: -1.0961e+00 - val_output_loss: -1.0961e+00 - val_variance_output_loss: -1.0961e+00 - val_output_mean_absolute_error: 0.1798 - val_output_mean_error: -1.5147e-02\n",
      "Epoch 11/60\n",
      " - 9s - loss: -1.1423e+00 - output_loss: -1.1424e+00 - variance_output_loss: -1.1424e+00 - output_mean_absolute_error: 0.1688 - output_mean_error: -6.3570e-03 - val_loss: -1.1370e+00 - val_output_loss: -1.1370e+00 - val_variance_output_loss: -1.1370e+00 - val_output_mean_absolute_error: 0.1712 - val_output_mean_error: -5.8037e-03\n",
      "Epoch 12/60\n",
      " - 9s - loss: -1.1653e+00 - output_loss: -1.1654e+00 - variance_output_loss: -1.1654e+00 - output_mean_absolute_error: 0.1671 - output_mean_error: -6.5955e-03 - val_loss: -1.1320e+00 - val_output_loss: -1.1320e+00 - val_variance_output_loss: -1.1320e+00 - val_output_mean_absolute_error: 0.1734 - val_output_mean_error: -2.1347e-02\n",
      "Epoch 13/60\n",
      " - 9s - loss: -1.1752e+00 - output_loss: -1.1752e+00 - variance_output_loss: -1.1752e+00 - output_mean_absolute_error: 0.1657 - output_mean_error: -6.7131e-03 - val_loss: -1.1176e+00 - val_output_loss: -1.1177e+00 - val_variance_output_loss: -1.1177e+00 - val_output_mean_absolute_error: 0.1736 - val_output_mean_error: 0.0259\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/60\n",
      " - 9s - loss: -1.2038e+00 - output_loss: -1.2039e+00 - variance_output_loss: -1.2039e+00 - output_mean_absolute_error: 0.1612 - output_mean_error: -6.6215e-03 - val_loss: -1.1443e+00 - val_output_loss: -1.1443e+00 - val_variance_output_loss: -1.1443e+00 - val_output_mean_absolute_error: 0.1712 - val_output_mean_error: 0.0058\n",
      "Epoch 15/60\n",
      " - 9s - loss: -1.2167e+00 - output_loss: -1.2168e+00 - variance_output_loss: -1.2168e+00 - output_mean_absolute_error: 0.1603 - output_mean_error: -7.5026e-03 - val_loss: -1.1935e+00 - val_output_loss: -1.1935e+00 - val_variance_output_loss: -1.1935e+00 - val_output_mean_absolute_error: 0.1654 - val_output_mean_error: -3.4457e-04\n",
      "Epoch 16/60\n",
      " - 9s - loss: -1.2196e+00 - output_loss: -1.2197e+00 - variance_output_loss: -1.2197e+00 - output_mean_absolute_error: 0.1601 - output_mean_error: -7.0140e-03 - val_loss: -1.1839e+00 - val_output_loss: -1.1840e+00 - val_variance_output_loss: -1.1840e+00 - val_output_mean_absolute_error: 0.1695 - val_output_mean_error: 0.0056\n",
      "Epoch 17/60\n",
      " - 9s - loss: -1.2292e+00 - output_loss: -1.2292e+00 - variance_output_loss: -1.2292e+00 - output_mean_absolute_error: 0.1587 - output_mean_error: -6.7969e-03 - val_loss: -1.1783e+00 - val_output_loss: -1.1784e+00 - val_variance_output_loss: -1.1784e+00 - val_output_mean_absolute_error: 0.1663 - val_output_mean_error: 0.0017\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/60\n",
      " - 9s - loss: -1.2371e+00 - output_loss: -1.2371e+00 - variance_output_loss: -1.2371e+00 - output_mean_absolute_error: 0.1577 - output_mean_error: -6.3005e-03 - val_loss: -1.2107e+00 - val_output_loss: -1.2107e+00 - val_variance_output_loss: -1.2107e+00 - val_output_mean_absolute_error: 0.1627 - val_output_mean_error: -1.9238e-02\n",
      "Epoch 19/60\n",
      " - 9s - loss: -1.2426e+00 - output_loss: -1.2427e+00 - variance_output_loss: -1.2427e+00 - output_mean_absolute_error: 0.1569 - output_mean_error: -6.9473e-03 - val_loss: -1.1848e+00 - val_output_loss: -1.1849e+00 - val_variance_output_loss: -1.1849e+00 - val_output_mean_absolute_error: 0.1659 - val_output_mean_error: 0.0131\n",
      "Epoch 20/60\n",
      " - 9s - loss: -1.2491e+00 - output_loss: -1.2492e+00 - variance_output_loss: -1.2492e+00 - output_mean_absolute_error: 0.1561 - output_mean_error: -6.2422e-03 - val_loss: -1.2008e+00 - val_output_loss: -1.2009e+00 - val_variance_output_loss: -1.2009e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -4.5020e-03\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 21/60\n",
      " - 9s - loss: -1.2541e+00 - output_loss: -1.2541e+00 - variance_output_loss: -1.2541e+00 - output_mean_absolute_error: 0.1552 - output_mean_error: -7.0140e-03 - val_loss: -1.2038e+00 - val_output_loss: -1.2039e+00 - val_variance_output_loss: -1.2039e+00 - val_output_mean_absolute_error: 0.1650 - val_output_mean_error: -1.5228e-02\n",
      "Epoch 22/60\n",
      " - 9s - loss: -1.2554e+00 - output_loss: -1.2555e+00 - variance_output_loss: -1.2555e+00 - output_mean_absolute_error: 0.1556 - output_mean_error: -7.1320e-03 - val_loss: -1.2088e+00 - val_output_loss: -1.2088e+00 - val_variance_output_loss: -1.2088e+00 - val_output_mean_absolute_error: 0.1628 - val_output_mean_error: -2.1817e-02\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/60\n",
      " - 9s - loss: -1.2575e+00 - output_loss: -1.2575e+00 - variance_output_loss: -1.2575e+00 - output_mean_absolute_error: 0.1550 - output_mean_error: -6.5305e-03 - val_loss: -1.2095e+00 - val_output_loss: -1.2095e+00 - val_variance_output_loss: -1.2095e+00 - val_output_mean_absolute_error: 0.1619 - val_output_mean_error: -1.8145e-02\n",
      "Epoch 24/60\n",
      " - 9s - loss: -1.2622e+00 - output_loss: -1.2623e+00 - variance_output_loss: -1.2623e+00 - output_mean_absolute_error: 0.1542 - output_mean_error: -6.7186e-03 - val_loss: -1.2232e+00 - val_output_loss: -1.2233e+00 - val_variance_output_loss: -1.2233e+00 - val_output_mean_absolute_error: 0.1619 - val_output_mean_error: -1.2225e-03\n",
      "Epoch 25/60\n",
      " - 9s - loss: -1.2600e+00 - output_loss: -1.2601e+00 - variance_output_loss: -1.2601e+00 - output_mean_absolute_error: 0.1551 - output_mean_error: -6.8650e-03 - val_loss: -1.2101e+00 - val_output_loss: -1.2102e+00 - val_variance_output_loss: -1.2102e+00 - val_output_mean_absolute_error: 0.1656 - val_output_mean_error: -8.6061e-03\n",
      "Epoch 26/60\n",
      " - 9s - loss: -1.2611e+00 - output_loss: -1.2612e+00 - variance_output_loss: -1.2612e+00 - output_mean_absolute_error: 0.1548 - output_mean_error: -6.8400e-03 - val_loss: -1.2101e+00 - val_output_loss: -1.2102e+00 - val_variance_output_loss: -1.2102e+00 - val_output_mean_absolute_error: 0.1634 - val_output_mean_error: -2.0341e-02\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 27/60\n",
      " - 9s - loss: -1.2636e+00 - output_loss: -1.2637e+00 - variance_output_loss: -1.2637e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -6.9054e-03 - val_loss: -1.2201e+00 - val_output_loss: -1.2201e+00 - val_variance_output_loss: -1.2201e+00 - val_output_mean_absolute_error: 0.1622 - val_output_mean_error: -5.5943e-03\n",
      "Epoch 28/60\n",
      " - 9s - loss: -1.2673e+00 - output_loss: -1.2673e+00 - variance_output_loss: -1.2673e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -7.4681e-03 - val_loss: -1.2090e+00 - val_output_loss: -1.2091e+00 - val_variance_output_loss: -1.2091e+00 - val_output_mean_absolute_error: 0.1643 - val_output_mean_error: -8.3784e-03\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 29/60\n",
      " - 9s - loss: -1.2669e+00 - output_loss: -1.2670e+00 - variance_output_loss: -1.2670e+00 - output_mean_absolute_error: 0.1543 - output_mean_error: -6.6670e-03 - val_loss: -1.2064e+00 - val_output_loss: -1.2065e+00 - val_variance_output_loss: -1.2065e+00 - val_output_mean_absolute_error: 0.1593 - val_output_mean_error: -6.4049e-03\n",
      "Epoch 30/60\n",
      " - 9s - loss: -1.2659e+00 - output_loss: -1.2659e+00 - variance_output_loss: -1.2659e+00 - output_mean_absolute_error: 0.1542 - output_mean_error: -6.7849e-03 - val_loss: -1.2222e+00 - val_output_loss: -1.2222e+00 - val_variance_output_loss: -1.2222e+00 - val_output_mean_absolute_error: 0.1604 - val_output_mean_error: -9.7327e-03\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 31/60\n",
      " - 9s - loss: -1.2710e+00 - output_loss: -1.2710e+00 - variance_output_loss: -1.2710e+00 - output_mean_absolute_error: 0.1534 - output_mean_error: -6.5499e-03 - val_loss: -1.2165e+00 - val_output_loss: -1.2165e+00 - val_variance_output_loss: -1.2165e+00 - val_output_mean_absolute_error: 0.1633 - val_output_mean_error: -8.4457e-03\n",
      "Epoch 32/60\n",
      " - 9s - loss: -1.2719e+00 - output_loss: -1.2719e+00 - variance_output_loss: -1.2719e+00 - output_mean_absolute_error: 0.1532 - output_mean_error: -7.4190e-03 - val_loss: -1.2041e+00 - val_output_loss: -1.2042e+00 - val_variance_output_loss: -1.2042e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -8.3924e-03\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 33/60\n",
      " - 9s - loss: -1.2620e+00 - output_loss: -1.2621e+00 - variance_output_loss: -1.2621e+00 - output_mean_absolute_error: 0.1547 - output_mean_error: -6.2962e-03 - val_loss: -1.2186e+00 - val_output_loss: -1.2187e+00 - val_variance_output_loss: -1.2187e+00 - val_output_mean_absolute_error: 0.1596 - val_output_mean_error: -3.1411e-03\n",
      "Epoch 34/60\n",
      " - 9s - loss: -1.2724e+00 - output_loss: -1.2725e+00 - variance_output_loss: -1.2725e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -6.3959e-03 - val_loss: -1.2471e+00 - val_output_loss: -1.2472e+00 - val_variance_output_loss: -1.2472e+00 - val_output_mean_absolute_error: 0.1600 - val_output_mean_error: -7.6004e-03\n",
      "Epoch 35/60\n",
      " - 9s - loss: -1.2679e+00 - output_loss: -1.2679e+00 - variance_output_loss: -1.2679e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -7.1840e-03 - val_loss: -1.2291e+00 - val_output_loss: -1.2292e+00 - val_variance_output_loss: -1.2292e+00 - val_output_mean_absolute_error: 0.1637 - val_output_mean_error: -1.2144e-02\n",
      "Epoch 36/60\n",
      " - 9s - loss: -1.2687e+00 - output_loss: -1.2688e+00 - variance_output_loss: -1.2688e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -6.2612e-03 - val_loss: -1.1906e+00 - val_output_loss: -1.1907e+00 - val_variance_output_loss: -1.1907e+00 - val_output_mean_absolute_error: 0.1627 - val_output_mean_error: -7.8267e-03\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 37/60\n",
      " - 9s - loss: -1.2695e+00 - output_loss: -1.2696e+00 - variance_output_loss: -1.2696e+00 - output_mean_absolute_error: 0.1538 - output_mean_error: -6.7028e-03 - val_loss: -1.2173e+00 - val_output_loss: -1.2173e+00 - val_variance_output_loss: -1.2173e+00 - val_output_mean_absolute_error: 0.1615 - val_output_mean_error: -1.1769e-02\n",
      "Epoch 38/60\n",
      " - 9s - loss: -1.2636e+00 - output_loss: -1.2636e+00 - variance_output_loss: -1.2636e+00 - output_mean_absolute_error: 0.1548 - output_mean_error: -7.6880e-03 - val_loss: -1.2226e+00 - val_output_loss: -1.2226e+00 - val_variance_output_loss: -1.2226e+00 - val_output_mean_absolute_error: 0.1617 - val_output_mean_error: -7.7972e-03\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 39/60\n",
      " - 9s - loss: -1.2679e+00 - output_loss: -1.2680e+00 - variance_output_loss: -1.2680e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -5.9196e-03 - val_loss: -1.1879e+00 - val_output_loss: -1.1880e+00 - val_variance_output_loss: -1.1880e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -1.0310e-02\n",
      "Epoch 40/60\n",
      " - 9s - loss: -1.2662e+00 - output_loss: -1.2663e+00 - variance_output_loss: -1.2663e+00 - output_mean_absolute_error: 0.1542 - output_mean_error: -6.6073e-03 - val_loss: -1.2324e+00 - val_output_loss: -1.2324e+00 - val_variance_output_loss: -1.2324e+00 - val_output_mean_absolute_error: 0.1601 - val_output_mean_error: -7.2646e-03\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 41/60\n",
      " - 9s - loss: -1.2697e+00 - output_loss: -1.2698e+00 - variance_output_loss: -1.2698e+00 - output_mean_absolute_error: 0.1535 - output_mean_error: -7.1622e-03 - val_loss: -1.2322e+00 - val_output_loss: -1.2323e+00 - val_variance_output_loss: -1.2323e+00 - val_output_mean_absolute_error: 0.1612 - val_output_mean_error: -1.3201e-02\n",
      "Epoch 42/60\n",
      " - 9s - loss: -1.2653e+00 - output_loss: -1.2653e+00 - variance_output_loss: -1.2653e+00 - output_mean_absolute_error: 0.1544 - output_mean_error: -7.9702e-03 - val_loss: -1.2151e+00 - val_output_loss: -1.2152e+00 - val_variance_output_loss: -1.2152e+00 - val_output_mean_absolute_error: 0.1608 - val_output_mean_error: -1.0185e-02\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 43/60\n",
      " - 9s - loss: -1.2685e+00 - output_loss: -1.2685e+00 - variance_output_loss: -1.2685e+00 - output_mean_absolute_error: 0.1535 - output_mean_error: -6.7677e-03 - val_loss: -1.2171e+00 - val_output_loss: -1.2172e+00 - val_variance_output_loss: -1.2172e+00 - val_output_mean_absolute_error: 0.1620 - val_output_mean_error: -9.0127e-03\n",
      "Epoch 44/60\n",
      " - 9s - loss: -1.2643e+00 - output_loss: -1.2644e+00 - variance_output_loss: -1.2644e+00 - output_mean_absolute_error: 0.1554 - output_mean_error: -7.4679e-03 - val_loss: -1.2177e+00 - val_output_loss: -1.2178e+00 - val_variance_output_loss: -1.2178e+00 - val_output_mean_absolute_error: 0.1612 - val_output_mean_error: -9.1430e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 45/60\n",
      " - 9s - loss: -1.2687e+00 - output_loss: -1.2688e+00 - variance_output_loss: -1.2688e+00 - output_mean_absolute_error: 0.1537 - output_mean_error: -6.9174e-03 - val_loss: -1.2275e+00 - val_output_loss: -1.2276e+00 - val_variance_output_loss: -1.2276e+00 - val_output_mean_absolute_error: 0.1610 - val_output_mean_error: -5.4341e-03\n",
      "Epoch 46/60\n",
      " - 9s - loss: -1.2684e+00 - output_loss: -1.2684e+00 - variance_output_loss: -1.2684e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -7.1442e-03 - val_loss: -1.2125e+00 - val_output_loss: -1.2125e+00 - val_variance_output_loss: -1.2125e+00 - val_output_mean_absolute_error: 0.1640 - val_output_mean_error: -1.5527e-02\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 47/60\n",
      " - 9s - loss: -1.2699e+00 - output_loss: -1.2700e+00 - variance_output_loss: -1.2700e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -6.6905e-03 - val_loss: -1.2080e+00 - val_output_loss: -1.2080e+00 - val_variance_output_loss: -1.2080e+00 - val_output_mean_absolute_error: 0.1628 - val_output_mean_error: -9.3021e-03\n",
      "Epoch 48/60\n",
      " - 9s - loss: -1.2647e+00 - output_loss: -1.2648e+00 - variance_output_loss: -1.2648e+00 - output_mean_absolute_error: 0.1540 - output_mean_error: -6.1355e-03 - val_loss: -1.2378e+00 - val_output_loss: -1.2379e+00 - val_variance_output_loss: -1.2379e+00 - val_output_mean_absolute_error: 0.1597 - val_output_mean_error: -8.4778e-03\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 49/60\n",
      " - 9s - loss: -1.2649e+00 - output_loss: -1.2649e+00 - variance_output_loss: -1.2649e+00 - output_mean_absolute_error: 0.1537 - output_mean_error: -5.9456e-03 - val_loss: -1.2141e+00 - val_output_loss: -1.2142e+00 - val_variance_output_loss: -1.2142e+00 - val_output_mean_absolute_error: 0.1630 - val_output_mean_error: -9.6078e-03\n",
      "Epoch 50/60\n",
      " - 9s - loss: -1.2692e+00 - output_loss: -1.2693e+00 - variance_output_loss: -1.2693e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -7.7391e-03 - val_loss: -1.2213e+00 - val_output_loss: -1.2214e+00 - val_variance_output_loss: -1.2214e+00 - val_output_mean_absolute_error: 0.1623 - val_output_mean_error: -8.3724e-03\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "Epoch 51/60\n",
      " - 9s - loss: -1.2686e+00 - output_loss: -1.2687e+00 - variance_output_loss: -1.2687e+00 - output_mean_absolute_error: 0.1540 - output_mean_error: -7.1530e-03 - val_loss: -1.2152e+00 - val_output_loss: -1.2152e+00 - val_variance_output_loss: -1.2152e+00 - val_output_mean_absolute_error: 0.1624 - val_output_mean_error: -7.3985e-03\n",
      "Epoch 52/60\n",
      " - 9s - loss: -1.2675e+00 - output_loss: -1.2676e+00 - variance_output_loss: -1.2676e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -7.9907e-03 - val_loss: -1.2133e+00 - val_output_loss: -1.2133e+00 - val_variance_output_loss: -1.2133e+00 - val_output_mean_absolute_error: 0.1623 - val_output_mean_error: -8.8896e-03\n",
      "Epoch 53/60\n",
      " - 9s - loss: -1.2680e+00 - output_loss: -1.2680e+00 - variance_output_loss: -1.2680e+00 - output_mean_absolute_error: 0.1538 - output_mean_error: -6.4551e-03 - val_loss: -1.2169e+00 - val_output_loss: -1.2170e+00 - val_variance_output_loss: -1.2170e+00 - val_output_mean_absolute_error: 0.1636 - val_output_mean_error: -8.1578e-03\n",
      "Epoch 54/60\n",
      " - 9s - loss: -1.2637e+00 - output_loss: -1.2638e+00 - variance_output_loss: -1.2638e+00 - output_mean_absolute_error: 0.1544 - output_mean_error: -7.3259e-03 - val_loss: -1.2186e+00 - val_output_loss: -1.2187e+00 - val_variance_output_loss: -1.2187e+00 - val_output_mean_absolute_error: 0.1619 - val_output_mean_error: -6.2379e-03\n",
      "Epoch 55/60\n",
      " - 9s - loss: -1.2678e+00 - output_loss: -1.2679e+00 - variance_output_loss: -1.2679e+00 - output_mean_absolute_error: 0.1540 - output_mean_error: -6.5779e-03 - val_loss: -1.2170e+00 - val_output_loss: -1.2171e+00 - val_variance_output_loss: -1.2171e+00 - val_output_mean_absolute_error: 0.1615 - val_output_mean_error: -6.6991e-03\n",
      "Epoch 56/60\n",
      " - 9s - loss: -1.2676e+00 - output_loss: -1.2677e+00 - variance_output_loss: -1.2677e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -5.8322e-03 - val_loss: -1.1925e+00 - val_output_loss: -1.1926e+00 - val_variance_output_loss: -1.1926e+00 - val_output_mean_absolute_error: 0.1620 - val_output_mean_error: -9.0764e-03\n",
      "Epoch 57/60\n",
      " - 9s - loss: -1.2674e+00 - output_loss: -1.2674e+00 - variance_output_loss: -1.2674e+00 - output_mean_absolute_error: 0.1545 - output_mean_error: -7.0725e-03 - val_loss: -1.2233e+00 - val_output_loss: -1.2233e+00 - val_variance_output_loss: -1.2233e+00 - val_output_mean_absolute_error: 0.1603 - val_output_mean_error: -5.4786e-03\n",
      "Epoch 58/60\n",
      " - 9s - loss: -1.2701e+00 - output_loss: -1.2702e+00 - variance_output_loss: -1.2702e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -8.4738e-03 - val_loss: -1.2392e+00 - val_output_loss: -1.2392e+00 - val_variance_output_loss: -1.2392e+00 - val_output_mean_absolute_error: 0.1624 - val_output_mean_error: -7.4900e-03\n",
      "Epoch 59/60\n",
      " - 9s - loss: -1.2673e+00 - output_loss: -1.2674e+00 - variance_output_loss: -1.2674e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -7.7231e-03 - val_loss: -1.1925e+00 - val_output_loss: -1.1925e+00 - val_variance_output_loss: -1.1925e+00 - val_output_mean_absolute_error: 0.1628 - val_output_mean_error: -5.6812e-03\n",
      "Epoch 60/60\n",
      " - 9s - loss: -1.2679e+00 - output_loss: -1.2680e+00 - variance_output_loss: -1.2680e+00 - output_mean_absolute_error: 0.1543 - output_mean_error: -7.2616e-03 - val_loss: -1.2188e+00 - val_output_loss: -1.2189e+00 - val_variance_output_loss: -1.2189e+00 - val_output_mean_absolute_error: 0.1593 - val_output_mean_error: -6.9268e-03\n",
      "Completed Training, 546.60s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_50/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_50'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/2), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 7516, Number of Validation Data: 835\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 10s - loss: 0.3336 - output_loss: 0.3336 - variance_output_loss: 0.3336 - output_mean_absolute_error: 0.6251 - output_mean_error: -2.1928e-02 - val_loss: 0.1246 - val_output_loss: 0.1246 - val_variance_output_loss: 0.1246 - val_output_mean_absolute_error: 0.4977 - val_output_mean_error: -7.2640e-02\n",
      "Epoch 2/60\n",
      " - 5s - loss: -9.7967e-02 - output_loss: -9.8012e-02 - variance_output_loss: -9.8012e-02 - output_mean_absolute_error: 0.4100 - output_mean_error: -6.2073e-02 - val_loss: -2.3634e-01 - val_output_loss: -2.3638e-01 - val_variance_output_loss: -2.3638e-01 - val_output_mean_absolute_error: 0.3814 - val_output_mean_error: -9.2241e-02\n",
      "Epoch 3/60\n",
      " - 5s - loss: -3.7193e-01 - output_loss: -3.7198e-01 - variance_output_loss: -3.7198e-01 - output_mean_absolute_error: 0.3416 - output_mean_error: -4.9012e-02 - val_loss: -4.5664e-01 - val_output_loss: -4.5668e-01 - val_variance_output_loss: -4.5668e-01 - val_output_mean_absolute_error: 0.3231 - val_output_mean_error: -2.8954e-02\n",
      "Epoch 4/60\n",
      " - 5s - loss: -5.2673e-01 - output_loss: -5.2677e-01 - variance_output_loss: -5.2677e-01 - output_mean_absolute_error: 0.2991 - output_mean_error: -3.6364e-02 - val_loss: -5.8556e-01 - val_output_loss: -5.8561e-01 - val_variance_output_loss: -5.8561e-01 - val_output_mean_absolute_error: 0.2835 - val_output_mean_error: -1.4081e-02\n",
      "Epoch 5/60\n",
      " - 5s - loss: -6.4571e-01 - output_loss: -6.4575e-01 - variance_output_loss: -6.4575e-01 - output_mean_absolute_error: 0.2642 - output_mean_error: -2.1464e-02 - val_loss: -6.6848e-01 - val_output_loss: -6.6853e-01 - val_variance_output_loss: -6.6853e-01 - val_output_mean_absolute_error: 0.2603 - val_output_mean_error: 0.0060\n",
      "Epoch 6/60\n",
      " - 4s - loss: -7.2576e-01 - output_loss: -7.2581e-01 - variance_output_loss: -7.2581e-01 - output_mean_absolute_error: 0.2434 - output_mean_error: -1.6988e-02 - val_loss: -7.6558e-01 - val_output_loss: -7.6563e-01 - val_variance_output_loss: -7.6563e-01 - val_output_mean_absolute_error: 0.2352 - val_output_mean_error: 0.0317\n",
      "Epoch 7/60\n",
      " - 4s - loss: -7.8460e-01 - output_loss: -7.8465e-01 - variance_output_loss: -7.8465e-01 - output_mean_absolute_error: 0.2273 - output_mean_error: -1.2541e-02 - val_loss: -7.5825e-01 - val_output_loss: -7.5829e-01 - val_variance_output_loss: -7.5829e-01 - val_output_mean_absolute_error: 0.2333 - val_output_mean_error: 0.0576\n",
      "Epoch 8/60\n",
      " - 4s - loss: -8.3533e-01 - output_loss: -8.3538e-01 - variance_output_loss: -8.3538e-01 - output_mean_absolute_error: 0.2161 - output_mean_error: -9.3723e-03 - val_loss: -8.0536e-01 - val_output_loss: -8.0541e-01 - val_variance_output_loss: -8.0541e-01 - val_output_mean_absolute_error: 0.2221 - val_output_mean_error: -3.4307e-02\n",
      "Epoch 9/60\n",
      " - 4s - loss: -8.8558e-01 - output_loss: -8.8563e-01 - variance_output_loss: -8.8563e-01 - output_mean_absolute_error: 0.2060 - output_mean_error: -7.7806e-03 - val_loss: -8.7030e-01 - val_output_loss: -8.7035e-01 - val_variance_output_loss: -8.7035e-01 - val_output_mean_absolute_error: 0.2134 - val_output_mean_error: 0.0179\n",
      "Epoch 10/60\n",
      " - 5s - loss: -9.1562e-01 - output_loss: -9.1567e-01 - variance_output_loss: -9.1567e-01 - output_mean_absolute_error: 0.1999 - output_mean_error: -7.4214e-03 - val_loss: -9.1523e-01 - val_output_loss: -9.1528e-01 - val_variance_output_loss: -9.1528e-01 - val_output_mean_absolute_error: 0.2003 - val_output_mean_error: -3.0754e-02\n",
      "Epoch 11/60\n",
      " - 5s - loss: -9.4724e-01 - output_loss: -9.4729e-01 - variance_output_loss: -9.4729e-01 - output_mean_absolute_error: 0.1940 - output_mean_error: -6.9983e-03 - val_loss: -8.9769e-01 - val_output_loss: -8.9774e-01 - val_variance_output_loss: -8.9774e-01 - val_output_mean_absolute_error: 0.2028 - val_output_mean_error: 0.0305\n",
      "Epoch 12/60\n",
      " - 5s - loss: -9.6582e-01 - output_loss: -9.6587e-01 - variance_output_loss: -9.6587e-01 - output_mean_absolute_error: 0.1902 - output_mean_error: -5.0393e-03 - val_loss: -9.5805e-01 - val_output_loss: -9.5810e-01 - val_variance_output_loss: -9.5810e-01 - val_output_mean_absolute_error: 0.1915 - val_output_mean_error: -2.9315e-02\n",
      "Epoch 13/60\n",
      " - 5s - loss: -9.9835e-01 - output_loss: -9.9840e-01 - variance_output_loss: -9.9840e-01 - output_mean_absolute_error: 0.1863 - output_mean_error: -3.7388e-03 - val_loss: -9.2779e-01 - val_output_loss: -9.2784e-01 - val_variance_output_loss: -9.2784e-01 - val_output_mean_absolute_error: 0.2021 - val_output_mean_error: 0.0161\n",
      "Epoch 14/60\n",
      " - 5s - loss: -1.0179e+00 - output_loss: -1.0180e+00 - variance_output_loss: -1.0180e+00 - output_mean_absolute_error: 0.1839 - output_mean_error: -5.0946e-03 - val_loss: -1.0303e+00 - val_output_loss: -1.0303e+00 - val_variance_output_loss: -1.0303e+00 - val_output_mean_absolute_error: 0.1827 - val_output_mean_error: -9.3289e-03\n",
      "Epoch 15/60\n",
      " - 5s - loss: -1.0325e+00 - output_loss: -1.0326e+00 - variance_output_loss: -1.0326e+00 - output_mean_absolute_error: 0.1816 - output_mean_error: -5.5605e-03 - val_loss: -1.0344e+00 - val_output_loss: -1.0344e+00 - val_variance_output_loss: -1.0344e+00 - val_output_mean_absolute_error: 0.1834 - val_output_mean_error: -5.6702e-03\n",
      "Epoch 16/60\n",
      " - 4s - loss: -1.0481e+00 - output_loss: -1.0481e+00 - variance_output_loss: -1.0481e+00 - output_mean_absolute_error: 0.1799 - output_mean_error: -6.5995e-03 - val_loss: -1.0320e+00 - val_output_loss: -1.0321e+00 - val_variance_output_loss: -1.0321e+00 - val_output_mean_absolute_error: 0.1846 - val_output_mean_error: -7.3345e-03\n",
      "Epoch 17/60\n",
      " - 4s - loss: -1.0666e+00 - output_loss: -1.0667e+00 - variance_output_loss: -1.0667e+00 - output_mean_absolute_error: 0.1775 - output_mean_error: -5.3084e-03 - val_loss: -1.0563e+00 - val_output_loss: -1.0563e+00 - val_variance_output_loss: -1.0563e+00 - val_output_mean_absolute_error: 0.1816 - val_output_mean_error: 0.0087\n",
      "Epoch 18/60\n",
      " - 4s - loss: -1.0860e+00 - output_loss: -1.0861e+00 - variance_output_loss: -1.0861e+00 - output_mean_absolute_error: 0.1742 - output_mean_error: -5.0769e-03 - val_loss: -1.0321e+00 - val_output_loss: -1.0322e+00 - val_variance_output_loss: -1.0322e+00 - val_output_mean_absolute_error: 0.1825 - val_output_mean_error: -3.5106e-02\n",
      "Epoch 19/60\n",
      " - 5s - loss: -1.1040e+00 - output_loss: -1.1041e+00 - variance_output_loss: -1.1041e+00 - output_mean_absolute_error: 0.1725 - output_mean_error: -6.1717e-03 - val_loss: -1.0549e+00 - val_output_loss: -1.0550e+00 - val_variance_output_loss: -1.0550e+00 - val_output_mean_absolute_error: 0.1786 - val_output_mean_error: -1.9965e-03\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 20/60\n",
      " - 4s - loss: -1.1265e+00 - output_loss: -1.1266e+00 - variance_output_loss: -1.1266e+00 - output_mean_absolute_error: 0.1701 - output_mean_error: -5.8935e-03 - val_loss: -1.0965e+00 - val_output_loss: -1.0965e+00 - val_variance_output_loss: -1.0965e+00 - val_output_mean_absolute_error: 0.1758 - val_output_mean_error: -2.6856e-02\n",
      "Epoch 21/60\n",
      " - 5s - loss: -1.1429e+00 - output_loss: -1.1429e+00 - variance_output_loss: -1.1429e+00 - output_mean_absolute_error: 0.1682 - output_mean_error: -5.8552e-03 - val_loss: -1.0863e+00 - val_output_loss: -1.0863e+00 - val_variance_output_loss: -1.0863e+00 - val_output_mean_absolute_error: 0.1751 - val_output_mean_error: 0.0170\n",
      "Epoch 22/60\n",
      " - 5s - loss: -1.1349e+00 - output_loss: -1.1349e+00 - variance_output_loss: -1.1349e+00 - output_mean_absolute_error: 0.1680 - output_mean_error: -4.7267e-03 - val_loss: -1.1013e+00 - val_output_loss: -1.1014e+00 - val_variance_output_loss: -1.1014e+00 - val_output_mean_absolute_error: 0.1737 - val_output_mean_error: -1.1743e-02\n",
      "Epoch 23/60\n",
      " - 4s - loss: -1.1463e+00 - output_loss: -1.1464e+00 - variance_output_loss: -1.1464e+00 - output_mean_absolute_error: 0.1686 - output_mean_error: -6.4485e-03 - val_loss: -1.1047e+00 - val_output_loss: -1.1047e+00 - val_variance_output_loss: -1.1047e+00 - val_output_mean_absolute_error: 0.1747 - val_output_mean_error: 2.6419e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      " - 4s - loss: -1.1534e+00 - output_loss: -1.1534e+00 - variance_output_loss: -1.1534e+00 - output_mean_absolute_error: 0.1657 - output_mean_error: -5.7820e-03 - val_loss: -1.1079e+00 - val_output_loss: -1.1080e+00 - val_variance_output_loss: -1.1080e+00 - val_output_mean_absolute_error: 0.1729 - val_output_mean_error: 0.0056\n",
      "Epoch 25/60\n",
      " - 4s - loss: -1.1642e+00 - output_loss: -1.1643e+00 - variance_output_loss: -1.1643e+00 - output_mean_absolute_error: 0.1649 - output_mean_error: -5.8232e-03 - val_loss: -1.1229e+00 - val_output_loss: -1.1230e+00 - val_variance_output_loss: -1.1230e+00 - val_output_mean_absolute_error: 0.1713 - val_output_mean_error: -2.1227e-02\n",
      "Epoch 26/60\n",
      " - 5s - loss: -1.1669e+00 - output_loss: -1.1669e+00 - variance_output_loss: -1.1669e+00 - output_mean_absolute_error: 0.1645 - output_mean_error: -5.3876e-03 - val_loss: -1.1397e+00 - val_output_loss: -1.1397e+00 - val_variance_output_loss: -1.1397e+00 - val_output_mean_absolute_error: 0.1702 - val_output_mean_error: -1.9760e-02\n",
      "Epoch 27/60\n",
      " - 5s - loss: -1.1800e+00 - output_loss: -1.1801e+00 - variance_output_loss: -1.1801e+00 - output_mean_absolute_error: 0.1630 - output_mean_error: -6.1604e-03 - val_loss: -1.1371e+00 - val_output_loss: -1.1371e+00 - val_variance_output_loss: -1.1371e+00 - val_output_mean_absolute_error: 0.1712 - val_output_mean_error: -2.8694e-02\n",
      "Epoch 28/60\n",
      " - 4s - loss: -1.1608e+00 - output_loss: -1.1609e+00 - variance_output_loss: -1.1609e+00 - output_mean_absolute_error: 0.1661 - output_mean_error: -6.4487e-03 - val_loss: -1.1269e+00 - val_output_loss: -1.1270e+00 - val_variance_output_loss: -1.1270e+00 - val_output_mean_absolute_error: 0.1721 - val_output_mean_error: -1.7990e-03\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 29/60\n",
      " - 4s - loss: -1.1823e+00 - output_loss: -1.1824e+00 - variance_output_loss: -1.1824e+00 - output_mean_absolute_error: 0.1628 - output_mean_error: -4.2886e-03 - val_loss: -1.1600e+00 - val_output_loss: -1.1600e+00 - val_variance_output_loss: -1.1600e+00 - val_output_mean_absolute_error: 0.1653 - val_output_mean_error: 0.0157\n",
      "Epoch 30/60\n",
      " - 5s - loss: -1.1933e+00 - output_loss: -1.1934e+00 - variance_output_loss: -1.1934e+00 - output_mean_absolute_error: 0.1616 - output_mean_error: -6.5533e-03 - val_loss: -1.1648e+00 - val_output_loss: -1.1648e+00 - val_variance_output_loss: -1.1648e+00 - val_output_mean_absolute_error: 0.1634 - val_output_mean_error: -2.3764e-03\n",
      "Epoch 31/60\n",
      " - 5s - loss: -1.1934e+00 - output_loss: -1.1934e+00 - variance_output_loss: -1.1934e+00 - output_mean_absolute_error: 0.1613 - output_mean_error: -6.3115e-03 - val_loss: -1.1677e+00 - val_output_loss: -1.1678e+00 - val_variance_output_loss: -1.1678e+00 - val_output_mean_absolute_error: 0.1660 - val_output_mean_error: -1.0782e-02\n",
      "Epoch 32/60\n",
      " - 4s - loss: -1.1946e+00 - output_loss: -1.1947e+00 - variance_output_loss: -1.1947e+00 - output_mean_absolute_error: 0.1615 - output_mean_error: -5.3200e-03 - val_loss: -1.1328e+00 - val_output_loss: -1.1329e+00 - val_variance_output_loss: -1.1329e+00 - val_output_mean_absolute_error: 0.1689 - val_output_mean_error: -2.2390e-02\n",
      "Epoch 33/60\n",
      " - 5s - loss: -1.1965e+00 - output_loss: -1.1966e+00 - variance_output_loss: -1.1966e+00 - output_mean_absolute_error: 0.1614 - output_mean_error: -6.1644e-03 - val_loss: -1.1736e+00 - val_output_loss: -1.1736e+00 - val_variance_output_loss: -1.1736e+00 - val_output_mean_absolute_error: 0.1657 - val_output_mean_error: 0.0127\n",
      "Epoch 34/60\n",
      " - 5s - loss: -1.2085e+00 - output_loss: -1.2086e+00 - variance_output_loss: -1.2086e+00 - output_mean_absolute_error: 0.1601 - output_mean_error: -6.0654e-03 - val_loss: -1.1650e+00 - val_output_loss: -1.1650e+00 - val_variance_output_loss: -1.1650e+00 - val_output_mean_absolute_error: 0.1668 - val_output_mean_error: 0.0071\n",
      "Epoch 35/60\n",
      " - 5s - loss: -1.2081e+00 - output_loss: -1.2081e+00 - variance_output_loss: -1.2081e+00 - output_mean_absolute_error: 0.1604 - output_mean_error: -6.5283e-03 - val_loss: -1.1139e+00 - val_output_loss: -1.1139e+00 - val_variance_output_loss: -1.1139e+00 - val_output_mean_absolute_error: 0.1740 - val_output_mean_error: 0.0034\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 36/60\n",
      " - 5s - loss: -1.2120e+00 - output_loss: -1.2121e+00 - variance_output_loss: -1.2121e+00 - output_mean_absolute_error: 0.1596 - output_mean_error: -4.6962e-03 - val_loss: -1.1626e+00 - val_output_loss: -1.1627e+00 - val_variance_output_loss: -1.1627e+00 - val_output_mean_absolute_error: 0.1675 - val_output_mean_error: -3.7290e-03\n",
      "Epoch 37/60\n",
      " - 5s - loss: -1.2123e+00 - output_loss: -1.2123e+00 - variance_output_loss: -1.2123e+00 - output_mean_absolute_error: 0.1602 - output_mean_error: -5.2038e-03 - val_loss: -1.1303e+00 - val_output_loss: -1.1303e+00 - val_variance_output_loss: -1.1303e+00 - val_output_mean_absolute_error: 0.1737 - val_output_mean_error: -1.6635e-02\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 38/60\n",
      " - 4s - loss: -1.2108e+00 - output_loss: -1.2108e+00 - variance_output_loss: -1.2108e+00 - output_mean_absolute_error: 0.1596 - output_mean_error: -6.0381e-03 - val_loss: -1.1531e+00 - val_output_loss: -1.1532e+00 - val_variance_output_loss: -1.1532e+00 - val_output_mean_absolute_error: 0.1700 - val_output_mean_error: -1.4939e-02\n",
      "Epoch 39/60\n",
      " - 4s - loss: -1.2292e+00 - output_loss: -1.2293e+00 - variance_output_loss: -1.2293e+00 - output_mean_absolute_error: 0.1570 - output_mean_error: -7.2654e-03 - val_loss: -1.1507e+00 - val_output_loss: -1.1507e+00 - val_variance_output_loss: -1.1507e+00 - val_output_mean_absolute_error: 0.1664 - val_output_mean_error: -3.2568e-03\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 40/60\n",
      " - 4s - loss: -1.2175e+00 - output_loss: -1.2176e+00 - variance_output_loss: -1.2176e+00 - output_mean_absolute_error: 0.1598 - output_mean_error: -6.2211e-03 - val_loss: -1.1650e+00 - val_output_loss: -1.1650e+00 - val_variance_output_loss: -1.1650e+00 - val_output_mean_absolute_error: 0.1677 - val_output_mean_error: -6.0767e-03\n",
      "Epoch 41/60\n",
      " - 4s - loss: -1.2277e+00 - output_loss: -1.2278e+00 - variance_output_loss: -1.2278e+00 - output_mean_absolute_error: 0.1559 - output_mean_error: -4.6766e-03 - val_loss: -1.1356e+00 - val_output_loss: -1.1357e+00 - val_variance_output_loss: -1.1357e+00 - val_output_mean_absolute_error: 0.1671 - val_output_mean_error: -9.7732e-04\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 42/60\n",
      " - 4s - loss: -1.2126e+00 - output_loss: -1.2127e+00 - variance_output_loss: -1.2127e+00 - output_mean_absolute_error: 0.1600 - output_mean_error: -7.0283e-03 - val_loss: -1.1645e+00 - val_output_loss: -1.1645e+00 - val_variance_output_loss: -1.1645e+00 - val_output_mean_absolute_error: 0.1691 - val_output_mean_error: -5.0310e-03\n",
      "Epoch 43/60\n",
      " - 5s - loss: -1.2231e+00 - output_loss: -1.2232e+00 - variance_output_loss: -1.2232e+00 - output_mean_absolute_error: 0.1576 - output_mean_error: -5.1369e-03 - val_loss: -1.1697e+00 - val_output_loss: -1.1698e+00 - val_variance_output_loss: -1.1698e+00 - val_output_mean_absolute_error: 0.1662 - val_output_mean_error: -8.4658e-03\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 44/60\n",
      " - 4s - loss: -1.2250e+00 - output_loss: -1.2250e+00 - variance_output_loss: -1.2250e+00 - output_mean_absolute_error: 0.1577 - output_mean_error: -5.8167e-03 - val_loss: -1.1729e+00 - val_output_loss: -1.1729e+00 - val_variance_output_loss: -1.1729e+00 - val_output_mean_absolute_error: 0.1645 - val_output_mean_error: -6.2165e-03\n",
      "Epoch 45/60\n",
      " - 4s - loss: -1.2224e+00 - output_loss: -1.2225e+00 - variance_output_loss: -1.2225e+00 - output_mean_absolute_error: 0.1578 - output_mean_error: -6.5054e-03 - val_loss: -1.1425e+00 - val_output_loss: -1.1425e+00 - val_variance_output_loss: -1.1425e+00 - val_output_mean_absolute_error: 0.1699 - val_output_mean_error: -1.4964e-02\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 46/60\n",
      " - 4s - loss: -1.2176e+00 - output_loss: -1.2177e+00 - variance_output_loss: -1.2177e+00 - output_mean_absolute_error: 0.1580 - output_mean_error: -5.2517e-03 - val_loss: -1.1955e+00 - val_output_loss: -1.1955e+00 - val_variance_output_loss: -1.1955e+00 - val_output_mean_absolute_error: 0.1638 - val_output_mean_error: -9.5697e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      " - 4s - loss: -1.2233e+00 - output_loss: -1.2234e+00 - variance_output_loss: -1.2234e+00 - output_mean_absolute_error: 0.1577 - output_mean_error: -5.8325e-03 - val_loss: -1.1536e+00 - val_output_loss: -1.1536e+00 - val_variance_output_loss: -1.1536e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -5.9521e-03\n",
      "Epoch 48/60\n",
      " - 4s - loss: -1.2177e+00 - output_loss: -1.2177e+00 - variance_output_loss: -1.2177e+00 - output_mean_absolute_error: 0.1595 - output_mean_error: -7.0635e-03 - val_loss: -1.1671e+00 - val_output_loss: -1.1671e+00 - val_variance_output_loss: -1.1671e+00 - val_output_mean_absolute_error: 0.1665 - val_output_mean_error: -8.5970e-03\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 49/60\n",
      " - 4s - loss: -1.2250e+00 - output_loss: -1.2250e+00 - variance_output_loss: -1.2250e+00 - output_mean_absolute_error: 0.1573 - output_mean_error: -5.0689e-03 - val_loss: -1.1638e+00 - val_output_loss: -1.1639e+00 - val_variance_output_loss: -1.1639e+00 - val_output_mean_absolute_error: 0.1667 - val_output_mean_error: -6.1507e-03\n",
      "Epoch 50/60\n",
      " - 4s - loss: -1.2248e+00 - output_loss: -1.2248e+00 - variance_output_loss: -1.2248e+00 - output_mean_absolute_error: 0.1578 - output_mean_error: -6.9660e-03 - val_loss: -1.1856e+00 - val_output_loss: -1.1856e+00 - val_variance_output_loss: -1.1856e+00 - val_output_mean_absolute_error: 0.1615 - val_output_mean_error: -1.5237e-03\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 51/60\n",
      " - 5s - loss: -1.2251e+00 - output_loss: -1.2252e+00 - variance_output_loss: -1.2252e+00 - output_mean_absolute_error: 0.1575 - output_mean_error: -6.2238e-03 - val_loss: -1.1791e+00 - val_output_loss: -1.1792e+00 - val_variance_output_loss: -1.1792e+00 - val_output_mean_absolute_error: 0.1675 - val_output_mean_error: -7.2171e-03\n",
      "Epoch 52/60\n",
      " - 5s - loss: -1.2259e+00 - output_loss: -1.2260e+00 - variance_output_loss: -1.2260e+00 - output_mean_absolute_error: 0.1583 - output_mean_error: -6.5885e-03 - val_loss: -1.1882e+00 - val_output_loss: -1.1882e+00 - val_variance_output_loss: -1.1882e+00 - val_output_mean_absolute_error: 0.1633 - val_output_mean_error: -7.8710e-03\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 53/60\n",
      " - 4s - loss: -1.2221e+00 - output_loss: -1.2222e+00 - variance_output_loss: -1.2222e+00 - output_mean_absolute_error: 0.1578 - output_mean_error: -5.5872e-03 - val_loss: -1.1820e+00 - val_output_loss: -1.1820e+00 - val_variance_output_loss: -1.1820e+00 - val_output_mean_absolute_error: 0.1668 - val_output_mean_error: -1.0032e-02\n",
      "Epoch 54/60\n",
      " - 4s - loss: -1.2192e+00 - output_loss: -1.2192e+00 - variance_output_loss: -1.2192e+00 - output_mean_absolute_error: 0.1581 - output_mean_error: -3.0214e-03 - val_loss: -1.1788e+00 - val_output_loss: -1.1789e+00 - val_variance_output_loss: -1.1789e+00 - val_output_mean_absolute_error: 0.1639 - val_output_mean_error: -6.2348e-03\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 55/60\n",
      " - 4s - loss: -1.2185e+00 - output_loss: -1.2186e+00 - variance_output_loss: -1.2186e+00 - output_mean_absolute_error: 0.1592 - output_mean_error: -4.8130e-03 - val_loss: -1.1816e+00 - val_output_loss: -1.1816e+00 - val_variance_output_loss: -1.1816e+00 - val_output_mean_absolute_error: 0.1651 - val_output_mean_error: -8.3036e-03\n",
      "Epoch 56/60\n",
      " - 5s - loss: -1.2289e+00 - output_loss: -1.2289e+00 - variance_output_loss: -1.2289e+00 - output_mean_absolute_error: 0.1580 - output_mean_error: -5.4008e-03 - val_loss: -1.1639e+00 - val_output_loss: -1.1639e+00 - val_variance_output_loss: -1.1639e+00 - val_output_mean_absolute_error: 0.1664 - val_output_mean_error: -5.0749e-03\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 57/60\n",
      " - 4s - loss: -1.2253e+00 - output_loss: -1.2253e+00 - variance_output_loss: -1.2253e+00 - output_mean_absolute_error: 0.1575 - output_mean_error: -6.6607e-03 - val_loss: -1.1796e+00 - val_output_loss: -1.1797e+00 - val_variance_output_loss: -1.1797e+00 - val_output_mean_absolute_error: 0.1639 - val_output_mean_error: -9.4413e-03\n",
      "Epoch 58/60\n",
      " - 4s - loss: -1.2210e+00 - output_loss: -1.2211e+00 - variance_output_loss: -1.2211e+00 - output_mean_absolute_error: 0.1583 - output_mean_error: -6.5592e-03 - val_loss: -1.1708e+00 - val_output_loss: -1.1709e+00 - val_variance_output_loss: -1.1709e+00 - val_output_mean_absolute_error: 0.1641 - val_output_mean_error: -1.8710e-03\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 59/60\n",
      " - 4s - loss: -1.2148e+00 - output_loss: -1.2149e+00 - variance_output_loss: -1.2149e+00 - output_mean_absolute_error: 0.1595 - output_mean_error: -7.1776e-03 - val_loss: -1.1794e+00 - val_output_loss: -1.1795e+00 - val_variance_output_loss: -1.1795e+00 - val_output_mean_absolute_error: 0.1625 - val_output_mean_error: -9.0460e-03\n",
      "Epoch 60/60\n",
      " - 4s - loss: -1.2196e+00 - output_loss: -1.2196e+00 - variance_output_loss: -1.2196e+00 - output_mean_absolute_error: 0.1586 - output_mean_error: -5.3842e-03 - val_loss: -1.1772e+00 - val_output_loss: -1.1773e+00 - val_variance_output_loss: -1.1773e+00 - val_output_mean_absolute_error: 0.1670 - val_output_mean_error: -7.4797e-03\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Completed Training, 279.65s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_25/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_25'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/4), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 3758, Number of Validation Data: 417\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 8s - loss: 0.3842 - output_loss: 0.3842 - variance_output_loss: 0.3842 - output_mean_absolute_error: 0.6283 - output_mean_error: -2.4548e-02 - val_loss: 0.3116 - val_output_loss: 0.3115 - val_variance_output_loss: 0.3115 - val_output_mean_absolute_error: 0.5525 - val_output_mean_error: -6.4697e-02\n",
      "Epoch 2/60\n",
      " - 2s - loss: 0.1690 - output_loss: 0.1689 - variance_output_loss: 0.1689 - output_mean_absolute_error: 0.5009 - output_mean_error: -4.5530e-02 - val_loss: 0.0521 - val_output_loss: 0.0520 - val_variance_output_loss: 0.0520 - val_output_mean_absolute_error: 0.4406 - val_output_mean_error: -7.7326e-03\n",
      "Epoch 3/60\n",
      " - 2s - loss: -4.9196e-02 - output_loss: -4.9241e-02 - variance_output_loss: -4.9241e-02 - output_mean_absolute_error: 0.4141 - output_mean_error: -3.4218e-02 - val_loss: -1.5913e-01 - val_output_loss: -1.5918e-01 - val_variance_output_loss: -1.5918e-01 - val_output_mean_absolute_error: 0.3780 - val_output_mean_error: -3.7097e-02\n",
      "Epoch 4/60\n",
      " - 2s - loss: -2.2725e-01 - output_loss: -2.2729e-01 - variance_output_loss: -2.2729e-01 - output_mean_absolute_error: 0.3743 - output_mean_error: -2.7714e-02 - val_loss: -2.8475e-01 - val_output_loss: -2.8480e-01 - val_variance_output_loss: -2.8480e-01 - val_output_mean_absolute_error: 0.3548 - val_output_mean_error: -3.7382e-02\n",
      "Epoch 5/60\n",
      " - 2s - loss: -3.6693e-01 - output_loss: -3.6698e-01 - variance_output_loss: -3.6698e-01 - output_mean_absolute_error: 0.3375 - output_mean_error: -2.0541e-02 - val_loss: -3.8855e-01 - val_output_loss: -3.8859e-01 - val_variance_output_loss: -3.8859e-01 - val_output_mean_absolute_error: 0.3323 - val_output_mean_error: -5.6551e-02\n",
      "Epoch 6/60\n",
      " - 2s - loss: -4.6549e-01 - output_loss: -4.6554e-01 - variance_output_loss: -4.6554e-01 - output_mean_absolute_error: 0.3118 - output_mean_error: -1.8691e-02 - val_loss: -5.0727e-01 - val_output_loss: -5.0732e-01 - val_variance_output_loss: -5.0732e-01 - val_output_mean_absolute_error: 0.2967 - val_output_mean_error: -8.0704e-03\n",
      "Epoch 7/60\n",
      " - 2s - loss: -5.2841e-01 - output_loss: -5.2846e-01 - variance_output_loss: -5.2846e-01 - output_mean_absolute_error: 0.2935 - output_mean_error: -1.7775e-02 - val_loss: -5.2047e-01 - val_output_loss: -5.2052e-01 - val_variance_output_loss: -5.2052e-01 - val_output_mean_absolute_error: 0.3035 - val_output_mean_error: -5.3648e-02\n",
      "Epoch 8/60\n",
      " - 2s - loss: -5.9966e-01 - output_loss: -5.9971e-01 - variance_output_loss: -5.9971e-01 - output_mean_absolute_error: 0.2730 - output_mean_error: -1.2692e-02 - val_loss: -5.8831e-01 - val_output_loss: -5.8836e-01 - val_variance_output_loss: -5.8836e-01 - val_output_mean_absolute_error: 0.2798 - val_output_mean_error: -5.9223e-02\n",
      "Epoch 9/60\n",
      " - 2s - loss: -6.4985e-01 - output_loss: -6.4990e-01 - variance_output_loss: -6.4990e-01 - output_mean_absolute_error: 0.2618 - output_mean_error: -1.5420e-02 - val_loss: -6.7147e-01 - val_output_loss: -6.7152e-01 - val_variance_output_loss: -6.7152e-01 - val_output_mean_absolute_error: 0.2563 - val_output_mean_error: -3.5672e-02\n",
      "Epoch 10/60\n",
      " - 2s - loss: -6.9783e-01 - output_loss: -6.9788e-01 - variance_output_loss: -6.9788e-01 - output_mean_absolute_error: 0.2490 - output_mean_error: -9.9447e-03 - val_loss: -6.8279e-01 - val_output_loss: -6.8284e-01 - val_variance_output_loss: -6.8284e-01 - val_output_mean_absolute_error: 0.2502 - val_output_mean_error: -4.2199e-02\n",
      "Epoch 11/60\n",
      " - 2s - loss: -7.2516e-01 - output_loss: -7.2521e-01 - variance_output_loss: -7.2521e-01 - output_mean_absolute_error: 0.2430 - output_mean_error: -1.4133e-02 - val_loss: -7.4018e-01 - val_output_loss: -7.4023e-01 - val_variance_output_loss: -7.4023e-01 - val_output_mean_absolute_error: 0.2380 - val_output_mean_error: -4.5638e-02\n",
      "Epoch 12/60\n",
      " - 2s - loss: -7.7436e-01 - output_loss: -7.7441e-01 - variance_output_loss: -7.7441e-01 - output_mean_absolute_error: 0.2322 - output_mean_error: -1.2843e-02 - val_loss: -7.4875e-01 - val_output_loss: -7.4880e-01 - val_variance_output_loss: -7.4880e-01 - val_output_mean_absolute_error: 0.2295 - val_output_mean_error: 0.0062\n",
      "Epoch 13/60\n",
      " - 2s - loss: -7.9746e-01 - output_loss: -7.9751e-01 - variance_output_loss: -7.9751e-01 - output_mean_absolute_error: 0.2274 - output_mean_error: -1.3328e-02 - val_loss: -7.1858e-01 - val_output_loss: -7.1863e-01 - val_variance_output_loss: -7.1863e-01 - val_output_mean_absolute_error: 0.2428 - val_output_mean_error: -6.2389e-02\n",
      "Epoch 14/60\n",
      " - 2s - loss: -8.1677e-01 - output_loss: -8.1682e-01 - variance_output_loss: -8.1682e-01 - output_mean_absolute_error: 0.2233 - output_mean_error: -1.0832e-02 - val_loss: -7.5459e-01 - val_output_loss: -7.5464e-01 - val_variance_output_loss: -7.5464e-01 - val_output_mean_absolute_error: 0.2384 - val_output_mean_error: -7.6253e-02\n",
      "Epoch 15/60\n",
      " - 2s - loss: -8.4725e-01 - output_loss: -8.4730e-01 - variance_output_loss: -8.4730e-01 - output_mean_absolute_error: 0.2169 - output_mean_error: -1.2935e-02 - val_loss: -8.1183e-01 - val_output_loss: -8.1188e-01 - val_variance_output_loss: -8.1188e-01 - val_output_mean_absolute_error: 0.2167 - val_output_mean_error: 0.0237\n",
      "Epoch 16/60\n",
      " - 2s - loss: -8.9089e-01 - output_loss: -8.9094e-01 - variance_output_loss: -8.9094e-01 - output_mean_absolute_error: 0.2085 - output_mean_error: -9.2699e-03 - val_loss: -8.4265e-01 - val_output_loss: -8.4270e-01 - val_variance_output_loss: -8.4270e-01 - val_output_mean_absolute_error: 0.2223 - val_output_mean_error: -1.8327e-02\n",
      "Epoch 17/60\n",
      " - 2s - loss: -9.0736e-01 - output_loss: -9.0741e-01 - variance_output_loss: -9.0741e-01 - output_mean_absolute_error: 0.2055 - output_mean_error: -9.4055e-03 - val_loss: -8.8886e-01 - val_output_loss: -8.8891e-01 - val_variance_output_loss: -8.8891e-01 - val_output_mean_absolute_error: 0.2058 - val_output_mean_error: -2.5665e-02\n",
      "Epoch 18/60\n",
      " - 2s - loss: -9.2775e-01 - output_loss: -9.2780e-01 - variance_output_loss: -9.2780e-01 - output_mean_absolute_error: 0.2024 - output_mean_error: -1.0618e-02 - val_loss: -8.9436e-01 - val_output_loss: -8.9441e-01 - val_variance_output_loss: -8.9441e-01 - val_output_mean_absolute_error: 0.2073 - val_output_mean_error: -1.1726e-02\n",
      "Epoch 19/60\n",
      " - 2s - loss: -9.4683e-01 - output_loss: -9.4688e-01 - variance_output_loss: -9.4688e-01 - output_mean_absolute_error: 0.1993 - output_mean_error: -1.0950e-02 - val_loss: -9.0546e-01 - val_output_loss: -9.0551e-01 - val_variance_output_loss: -9.0551e-01 - val_output_mean_absolute_error: 0.2036 - val_output_mean_error: -1.3554e-02\n",
      "Epoch 20/60\n",
      " - 2s - loss: -9.5733e-01 - output_loss: -9.5738e-01 - variance_output_loss: -9.5738e-01 - output_mean_absolute_error: 0.1972 - output_mean_error: -8.8248e-03 - val_loss: -8.9856e-01 - val_output_loss: -8.9862e-01 - val_variance_output_loss: -8.9862e-01 - val_output_mean_absolute_error: 0.2079 - val_output_mean_error: -8.6442e-02\n",
      "Epoch 21/60\n",
      " - 2s - loss: -9.8637e-01 - output_loss: -9.8642e-01 - variance_output_loss: -9.8642e-01 - output_mean_absolute_error: 0.1912 - output_mean_error: -8.5780e-03 - val_loss: -9.2565e-01 - val_output_loss: -9.2570e-01 - val_variance_output_loss: -9.2570e-01 - val_output_mean_absolute_error: 0.2007 - val_output_mean_error: -4.5157e-02\n",
      "Epoch 22/60\n",
      " - 2s - loss: -1.0054e+00 - output_loss: -1.0054e+00 - variance_output_loss: -1.0054e+00 - output_mean_absolute_error: 0.1899 - output_mean_error: -1.1678e-02 - val_loss: -9.7620e-01 - val_output_loss: -9.7625e-01 - val_variance_output_loss: -9.7625e-01 - val_output_mean_absolute_error: 0.2003 - val_output_mean_error: -1.7063e-02\n",
      "Epoch 23/60\n",
      " - 2s - loss: -1.0180e+00 - output_loss: -1.0180e+00 - variance_output_loss: -1.0180e+00 - output_mean_absolute_error: 0.1880 - output_mean_error: -8.2609e-03 - val_loss: -9.0951e-01 - val_output_loss: -9.0956e-01 - val_variance_output_loss: -9.0956e-01 - val_output_mean_absolute_error: 0.2061 - val_output_mean_error: -4.4496e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      " - 2s - loss: -1.0293e+00 - output_loss: -1.0293e+00 - variance_output_loss: -1.0293e+00 - output_mean_absolute_error: 0.1845 - output_mean_error: -6.8864e-03 - val_loss: -9.1224e-01 - val_output_loss: -9.1229e-01 - val_variance_output_loss: -9.1229e-01 - val_output_mean_absolute_error: 0.1973 - val_output_mean_error: -4.2558e-02\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 25/60\n",
      " - 2s - loss: -1.0479e+00 - output_loss: -1.0479e+00 - variance_output_loss: -1.0479e+00 - output_mean_absolute_error: 0.1841 - output_mean_error: -1.1628e-02 - val_loss: -1.0201e+00 - val_output_loss: -1.0201e+00 - val_variance_output_loss: -1.0201e+00 - val_output_mean_absolute_error: 0.1876 - val_output_mean_error: 0.0031\n",
      "Epoch 26/60\n",
      " - 2s - loss: -1.0663e+00 - output_loss: -1.0663e+00 - variance_output_loss: -1.0663e+00 - output_mean_absolute_error: 0.1803 - output_mean_error: -9.6866e-03 - val_loss: -1.0150e+00 - val_output_loss: -1.0151e+00 - val_variance_output_loss: -1.0151e+00 - val_output_mean_absolute_error: 0.1937 - val_output_mean_error: -9.0252e-03\n",
      "Epoch 27/60\n",
      " - 2s - loss: -1.0735e+00 - output_loss: -1.0736e+00 - variance_output_loss: -1.0736e+00 - output_mean_absolute_error: 0.1795 - output_mean_error: -8.5681e-03 - val_loss: -1.0395e+00 - val_output_loss: -1.0396e+00 - val_variance_output_loss: -1.0396e+00 - val_output_mean_absolute_error: 0.1789 - val_output_mean_error: -1.9537e-02\n",
      "Epoch 28/60\n",
      " - 2s - loss: -1.0816e+00 - output_loss: -1.0817e+00 - variance_output_loss: -1.0817e+00 - output_mean_absolute_error: 0.1766 - output_mean_error: -9.4063e-03 - val_loss: -1.0192e+00 - val_output_loss: -1.0192e+00 - val_variance_output_loss: -1.0192e+00 - val_output_mean_absolute_error: 0.1844 - val_output_mean_error: -1.0422e-02\n",
      "Epoch 29/60\n",
      " - 2s - loss: -1.0821e+00 - output_loss: -1.0822e+00 - variance_output_loss: -1.0822e+00 - output_mean_absolute_error: 0.1789 - output_mean_error: -1.0113e-02 - val_loss: -1.0745e+00 - val_output_loss: -1.0746e+00 - val_variance_output_loss: -1.0746e+00 - val_output_mean_absolute_error: 0.1759 - val_output_mean_error: 8.6055e-04\n",
      "Epoch 30/60\n",
      " - 2s - loss: -1.0892e+00 - output_loss: -1.0892e+00 - variance_output_loss: -1.0892e+00 - output_mean_absolute_error: 0.1779 - output_mean_error: -7.4594e-03 - val_loss: -1.0554e+00 - val_output_loss: -1.0554e+00 - val_variance_output_loss: -1.0554e+00 - val_output_mean_absolute_error: 0.1854 - val_output_mean_error: -2.1346e-02\n",
      "Epoch 31/60\n",
      " - 2s - loss: -1.1073e+00 - output_loss: -1.1074e+00 - variance_output_loss: -1.1074e+00 - output_mean_absolute_error: 0.1735 - output_mean_error: -1.0816e-02 - val_loss: -1.0568e+00 - val_output_loss: -1.0569e+00 - val_variance_output_loss: -1.0569e+00 - val_output_mean_absolute_error: 0.1815 - val_output_mean_error: -2.6119e-02\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 32/60\n",
      " - 2s - loss: -1.1052e+00 - output_loss: -1.1053e+00 - variance_output_loss: -1.1053e+00 - output_mean_absolute_error: 0.1743 - output_mean_error: -8.4881e-03 - val_loss: -1.0961e+00 - val_output_loss: -1.0961e+00 - val_variance_output_loss: -1.0961e+00 - val_output_mean_absolute_error: 0.1719 - val_output_mean_error: -8.2183e-03\n",
      "Epoch 33/60\n",
      " - 2s - loss: -1.1049e+00 - output_loss: -1.1049e+00 - variance_output_loss: -1.1049e+00 - output_mean_absolute_error: 0.1749 - output_mean_error: -9.8245e-03 - val_loss: -1.1066e+00 - val_output_loss: -1.1067e+00 - val_variance_output_loss: -1.1067e+00 - val_output_mean_absolute_error: 0.1738 - val_output_mean_error: -9.7245e-03\n",
      "Epoch 34/60\n",
      " - 2s - loss: -1.1154e+00 - output_loss: -1.1154e+00 - variance_output_loss: -1.1154e+00 - output_mean_absolute_error: 0.1749 - output_mean_error: -1.0359e-02 - val_loss: -1.0385e+00 - val_output_loss: -1.0385e+00 - val_variance_output_loss: -1.0385e+00 - val_output_mean_absolute_error: 0.1853 - val_output_mean_error: -2.2988e-02\n",
      "Epoch 35/60\n",
      " - 2s - loss: -1.1242e+00 - output_loss: -1.1243e+00 - variance_output_loss: -1.1243e+00 - output_mean_absolute_error: 0.1727 - output_mean_error: -8.3304e-03 - val_loss: -1.0935e+00 - val_output_loss: -1.0935e+00 - val_variance_output_loss: -1.0935e+00 - val_output_mean_absolute_error: 0.1775 - val_output_mean_error: -2.5112e-02\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 36/60\n",
      " - 2s - loss: -1.1343e+00 - output_loss: -1.1343e+00 - variance_output_loss: -1.1343e+00 - output_mean_absolute_error: 0.1723 - output_mean_error: -1.1414e-02 - val_loss: -1.0773e+00 - val_output_loss: -1.0773e+00 - val_variance_output_loss: -1.0773e+00 - val_output_mean_absolute_error: 0.1776 - val_output_mean_error: -2.1830e-02\n",
      "Epoch 37/60\n",
      " - 2s - loss: -1.1203e+00 - output_loss: -1.1203e+00 - variance_output_loss: -1.1203e+00 - output_mean_absolute_error: 0.1742 - output_mean_error: -7.8693e-03 - val_loss: -1.0320e+00 - val_output_loss: -1.0321e+00 - val_variance_output_loss: -1.0321e+00 - val_output_mean_absolute_error: 0.1834 - val_output_mean_error: -2.6410e-02\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 38/60\n",
      " - 2s - loss: -1.1360e+00 - output_loss: -1.1360e+00 - variance_output_loss: -1.1360e+00 - output_mean_absolute_error: 0.1720 - output_mean_error: -1.3181e-02 - val_loss: -1.0942e+00 - val_output_loss: -1.0942e+00 - val_variance_output_loss: -1.0942e+00 - val_output_mean_absolute_error: 0.1697 - val_output_mean_error: -1.2205e-02\n",
      "Epoch 39/60\n",
      " - 3s - loss: -1.1416e+00 - output_loss: -1.1416e+00 - variance_output_loss: -1.1416e+00 - output_mean_absolute_error: 0.1680 - output_mean_error: -6.1838e-03 - val_loss: -1.0701e+00 - val_output_loss: -1.0702e+00 - val_variance_output_loss: -1.0702e+00 - val_output_mean_absolute_error: 0.1829 - val_output_mean_error: -2.4805e-02\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 40/60\n",
      " - 2s - loss: -1.1331e+00 - output_loss: -1.1331e+00 - variance_output_loss: -1.1331e+00 - output_mean_absolute_error: 0.1709 - output_mean_error: -9.8291e-03 - val_loss: -1.0866e+00 - val_output_loss: -1.0867e+00 - val_variance_output_loss: -1.0867e+00 - val_output_mean_absolute_error: 0.1772 - val_output_mean_error: -2.1289e-02\n",
      "Epoch 41/60\n",
      " - 2s - loss: -1.1424e+00 - output_loss: -1.1424e+00 - variance_output_loss: -1.1424e+00 - output_mean_absolute_error: 0.1699 - output_mean_error: -1.0603e-02 - val_loss: -1.0608e+00 - val_output_loss: -1.0608e+00 - val_variance_output_loss: -1.0608e+00 - val_output_mean_absolute_error: 0.1856 - val_output_mean_error: -2.0839e-02\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 42/60\n",
      " - 2s - loss: -1.1448e+00 - output_loss: -1.1449e+00 - variance_output_loss: -1.1449e+00 - output_mean_absolute_error: 0.1710 - output_mean_error: -9.7425e-03 - val_loss: -1.0632e+00 - val_output_loss: -1.0632e+00 - val_variance_output_loss: -1.0632e+00 - val_output_mean_absolute_error: 0.1849 - val_output_mean_error: -2.0485e-02\n",
      "Epoch 43/60\n",
      " - 2s - loss: -1.1334e+00 - output_loss: -1.1335e+00 - variance_output_loss: -1.1335e+00 - output_mean_absolute_error: 0.1705 - output_mean_error: -8.4269e-03 - val_loss: -1.0760e+00 - val_output_loss: -1.0760e+00 - val_variance_output_loss: -1.0760e+00 - val_output_mean_absolute_error: 0.1777 - val_output_mean_error: -1.7582e-02\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 44/60\n",
      " - 2s - loss: -1.1307e+00 - output_loss: -1.1308e+00 - variance_output_loss: -1.1308e+00 - output_mean_absolute_error: 0.1726 - output_mean_error: -9.7759e-03 - val_loss: -1.0555e+00 - val_output_loss: -1.0556e+00 - val_variance_output_loss: -1.0556e+00 - val_output_mean_absolute_error: 0.1834 - val_output_mean_error: -2.3400e-02\n",
      "Epoch 45/60\n",
      " - 2s - loss: -1.1386e+00 - output_loss: -1.1387e+00 - variance_output_loss: -1.1387e+00 - output_mean_absolute_error: 0.1705 - output_mean_error: -8.4499e-03 - val_loss: -1.0722e+00 - val_output_loss: -1.0723e+00 - val_variance_output_loss: -1.0723e+00 - val_output_mean_absolute_error: 0.1856 - val_output_mean_error: -2.1502e-02\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 46/60\n",
      " - 2s - loss: -1.1406e+00 - output_loss: -1.1407e+00 - variance_output_loss: -1.1407e+00 - output_mean_absolute_error: 0.1699 - output_mean_error: -9.1234e-03 - val_loss: -1.0959e+00 - val_output_loss: -1.0959e+00 - val_variance_output_loss: -1.0959e+00 - val_output_mean_absolute_error: 0.1757 - val_output_mean_error: -2.3133e-02\n",
      "Epoch 47/60\n",
      " - 2s - loss: -1.1416e+00 - output_loss: -1.1416e+00 - variance_output_loss: -1.1416e+00 - output_mean_absolute_error: 0.1706 - output_mean_error: -1.2100e-02 - val_loss: -1.0475e+00 - val_output_loss: -1.0476e+00 - val_variance_output_loss: -1.0476e+00 - val_output_mean_absolute_error: 0.1944 - val_output_mean_error: -3.4219e-02\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 48/60\n",
      " - 2s - loss: -1.1421e+00 - output_loss: -1.1421e+00 - variance_output_loss: -1.1421e+00 - output_mean_absolute_error: 0.1702 - output_mean_error: -1.0724e-02 - val_loss: -1.1291e+00 - val_output_loss: -1.1292e+00 - val_variance_output_loss: -1.1292e+00 - val_output_mean_absolute_error: 0.1671 - val_output_mean_error: -1.6242e-02\n",
      "Epoch 49/60\n",
      " - 2s - loss: -1.1394e+00 - output_loss: -1.1395e+00 - variance_output_loss: -1.1395e+00 - output_mean_absolute_error: 0.1700 - output_mean_error: -9.7056e-03 - val_loss: -1.0756e+00 - val_output_loss: -1.0757e+00 - val_variance_output_loss: -1.0757e+00 - val_output_mean_absolute_error: 0.1781 - val_output_mean_error: -1.3530e-02\n",
      "Epoch 50/60\n",
      " - 2s - loss: -1.1377e+00 - output_loss: -1.1378e+00 - variance_output_loss: -1.1378e+00 - output_mean_absolute_error: 0.1707 - output_mean_error: -1.0127e-02 - val_loss: -1.0862e+00 - val_output_loss: -1.0863e+00 - val_variance_output_loss: -1.0863e+00 - val_output_mean_absolute_error: 0.1813 - val_output_mean_error: -2.8924e-02\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 51/60\n",
      " - 2s - loss: -1.1386e+00 - output_loss: -1.1387e+00 - variance_output_loss: -1.1387e+00 - output_mean_absolute_error: 0.1701 - output_mean_error: -1.1188e-02 - val_loss: -1.1080e+00 - val_output_loss: -1.1080e+00 - val_variance_output_loss: -1.1080e+00 - val_output_mean_absolute_error: 0.1775 - val_output_mean_error: -1.9039e-02\n",
      "Epoch 52/60\n",
      " - 2s - loss: -1.1410e+00 - output_loss: -1.1411e+00 - variance_output_loss: -1.1411e+00 - output_mean_absolute_error: 0.1709 - output_mean_error: -8.6073e-03 - val_loss: -1.1344e+00 - val_output_loss: -1.1345e+00 - val_variance_output_loss: -1.1345e+00 - val_output_mean_absolute_error: 0.1626 - val_output_mean_error: -1.3311e-02\n",
      "Epoch 53/60\n",
      " - 2s - loss: -1.1429e+00 - output_loss: -1.1430e+00 - variance_output_loss: -1.1430e+00 - output_mean_absolute_error: 0.1703 - output_mean_error: -8.6400e-03 - val_loss: -1.0768e+00 - val_output_loss: -1.0768e+00 - val_variance_output_loss: -1.0768e+00 - val_output_mean_absolute_error: 0.1848 - val_output_mean_error: -2.0573e-02\n",
      "Epoch 54/60\n",
      " - 2s - loss: -1.1356e+00 - output_loss: -1.1356e+00 - variance_output_loss: -1.1356e+00 - output_mean_absolute_error: 0.1718 - output_mean_error: -7.7087e-03 - val_loss: -1.0812e+00 - val_output_loss: -1.0813e+00 - val_variance_output_loss: -1.0813e+00 - val_output_mean_absolute_error: 0.1823 - val_output_mean_error: -2.6663e-02\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 55/60\n",
      " - 2s - loss: -1.1396e+00 - output_loss: -1.1397e+00 - variance_output_loss: -1.1397e+00 - output_mean_absolute_error: 0.1714 - output_mean_error: -1.1278e-02 - val_loss: -1.0982e+00 - val_output_loss: -1.0982e+00 - val_variance_output_loss: -1.0982e+00 - val_output_mean_absolute_error: 0.1751 - val_output_mean_error: -1.7232e-02\n",
      "Epoch 56/60\n",
      " - 2s - loss: -1.1417e+00 - output_loss: -1.1417e+00 - variance_output_loss: -1.1417e+00 - output_mean_absolute_error: 0.1687 - output_mean_error: -6.9109e-03 - val_loss: -1.0589e+00 - val_output_loss: -1.0590e+00 - val_variance_output_loss: -1.0590e+00 - val_output_mean_absolute_error: 0.1796 - val_output_mean_error: -2.4753e-02\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 57/60\n",
      " - 2s - loss: -1.1460e+00 - output_loss: -1.1460e+00 - variance_output_loss: -1.1460e+00 - output_mean_absolute_error: 0.1698 - output_mean_error: -9.2753e-03 - val_loss: -1.0561e+00 - val_output_loss: -1.0561e+00 - val_variance_output_loss: -1.0561e+00 - val_output_mean_absolute_error: 0.1748 - val_output_mean_error: -1.7296e-02\n",
      "Epoch 58/60\n",
      " - 2s - loss: -1.1471e+00 - output_loss: -1.1472e+00 - variance_output_loss: -1.1472e+00 - output_mean_absolute_error: 0.1686 - output_mean_error: -8.6204e-03 - val_loss: -1.0804e+00 - val_output_loss: -1.0804e+00 - val_variance_output_loss: -1.0804e+00 - val_output_mean_absolute_error: 0.1802 - val_output_mean_error: -3.2713e-02\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 59/60\n",
      " - 2s - loss: -1.1316e+00 - output_loss: -1.1316e+00 - variance_output_loss: -1.1316e+00 - output_mean_absolute_error: 0.1730 - output_mean_error: -9.5940e-03 - val_loss: -1.1079e+00 - val_output_loss: -1.1080e+00 - val_variance_output_loss: -1.1080e+00 - val_output_mean_absolute_error: 0.1706 - val_output_mean_error: -1.1242e-02\n",
      "Epoch 60/60\n",
      " - 2s - loss: -1.1411e+00 - output_loss: -1.1412e+00 - variance_output_loss: -1.1412e+00 - output_mean_absolute_error: 0.1700 - output_mean_error: -1.0534e-02 - val_loss: -1.0914e+00 - val_output_loss: -1.0914e+00 - val_variance_output_loss: -1.0914e+00 - val_output_mean_absolute_error: 0.1681 - val_output_mean_error: -1.2959e-02\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Completed Training, 145.63s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_12_5/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_12_5'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/8), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 1879, Number of Validation Data: 208\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 7s - loss: 0.4630 - output_loss: 0.4630 - variance_output_loss: 0.4630 - output_mean_absolute_error: 0.6878 - output_mean_error: -1.6965e-02 - val_loss: 0.4029 - val_output_loss: 0.4028 - val_variance_output_loss: 0.4028 - val_output_mean_absolute_error: 0.6419 - val_output_mean_error: 0.0384\n",
      "Epoch 2/60\n",
      " - 1s - loss: 0.3730 - output_loss: 0.3730 - variance_output_loss: 0.3730 - output_mean_absolute_error: 0.6413 - output_mean_error: 0.0092 - val_loss: 0.3034 - val_output_loss: 0.3033 - val_variance_output_loss: 0.3033 - val_output_mean_absolute_error: 0.6012 - val_output_mean_error: 0.0455\n",
      "Epoch 3/60\n",
      " - 1s - loss: 0.3309 - output_loss: 0.3309 - variance_output_loss: 0.3309 - output_mean_absolute_error: 0.6127 - output_mean_error: -3.6293e-02 - val_loss: 0.3209 - val_output_loss: 0.3209 - val_variance_output_loss: 0.3209 - val_output_mean_absolute_error: 0.5756 - val_output_mean_error: -9.1030e-02\n",
      "Epoch 4/60\n",
      " - 1s - loss: 0.2151 - output_loss: 0.2151 - variance_output_loss: 0.2151 - output_mean_absolute_error: 0.5389 - output_mean_error: -8.2430e-02 - val_loss: 0.0585 - val_output_loss: 0.0584 - val_variance_output_loss: 0.0584 - val_output_mean_absolute_error: 0.4666 - val_output_mean_error: -4.0060e-02\n",
      "Epoch 5/60\n",
      " - 1s - loss: 0.0853 - output_loss: 0.0853 - variance_output_loss: 0.0853 - output_mean_absolute_error: 0.4846 - output_mean_error: -7.3145e-02 - val_loss: 0.0692 - val_output_loss: 0.0691 - val_variance_output_loss: 0.0691 - val_output_mean_absolute_error: 0.4714 - val_output_mean_error: -1.4367e-01\n",
      "Epoch 6/60\n",
      " - 1s - loss: -4.5025e-02 - output_loss: -4.5071e-02 - variance_output_loss: -4.5071e-02 - output_mean_absolute_error: 0.4328 - output_mean_error: -8.2231e-02 - val_loss: -4.9256e-02 - val_output_loss: -4.9301e-02 - val_variance_output_loss: -4.9301e-02 - val_output_mean_absolute_error: 0.4292 - val_output_mean_error: -9.6950e-02\n",
      "Epoch 7/60\n",
      " - 1s - loss: -1.2890e-01 - output_loss: -1.2895e-01 - variance_output_loss: -1.2895e-01 - output_mean_absolute_error: 0.4042 - output_mean_error: -8.3693e-02 - val_loss: -1.4110e-01 - val_output_loss: -1.4115e-01 - val_variance_output_loss: -1.4115e-01 - val_output_mean_absolute_error: 0.3979 - val_output_mean_error: -8.8111e-02\n",
      "Epoch 8/60\n",
      " - 1s - loss: -2.2688e-01 - output_loss: -2.2693e-01 - variance_output_loss: -2.2693e-01 - output_mean_absolute_error: 0.3689 - output_mean_error: -6.0569e-02 - val_loss: -2.6349e-01 - val_output_loss: -2.6353e-01 - val_variance_output_loss: -2.6353e-01 - val_output_mean_absolute_error: 0.3524 - val_output_mean_error: -3.8541e-02\n",
      "Epoch 9/60\n",
      " - 1s - loss: -3.0322e-01 - output_loss: -3.0326e-01 - variance_output_loss: -3.0326e-01 - output_mean_absolute_error: 0.3498 - output_mean_error: -5.7888e-02 - val_loss: -3.1359e-01 - val_output_loss: -3.1363e-01 - val_variance_output_loss: -3.1363e-01 - val_output_mean_absolute_error: 0.3345 - val_output_mean_error: -4.0748e-02\n",
      "Epoch 10/60\n",
      " - 1s - loss: -3.5619e-01 - output_loss: -3.5624e-01 - variance_output_loss: -3.5624e-01 - output_mean_absolute_error: 0.3326 - output_mean_error: -4.3836e-02 - val_loss: -3.3867e-01 - val_output_loss: -3.3872e-01 - val_variance_output_loss: -3.3872e-01 - val_output_mean_absolute_error: 0.3351 - val_output_mean_error: -6.8089e-02\n",
      "Epoch 11/60\n",
      " - 1s - loss: -4.1278e-01 - output_loss: -4.1283e-01 - variance_output_loss: -4.1283e-01 - output_mean_absolute_error: 0.3224 - output_mean_error: -5.1028e-02 - val_loss: -4.0815e-01 - val_output_loss: -4.0819e-01 - val_variance_output_loss: -4.0819e-01 - val_output_mean_absolute_error: 0.3133 - val_output_mean_error: -3.4107e-02\n",
      "Epoch 12/60\n",
      " - 1s - loss: -4.6738e-01 - output_loss: -4.6742e-01 - variance_output_loss: -4.6742e-01 - output_mean_absolute_error: 0.3023 - output_mean_error: -3.6269e-02 - val_loss: -4.6034e-01 - val_output_loss: -4.6039e-01 - val_variance_output_loss: -4.6039e-01 - val_output_mean_absolute_error: 0.3045 - val_output_mean_error: -9.4840e-03\n",
      "Epoch 13/60\n",
      " - 1s - loss: -4.9838e-01 - output_loss: -4.9843e-01 - variance_output_loss: -4.9843e-01 - output_mean_absolute_error: 0.2997 - output_mean_error: -4.2958e-02 - val_loss: -4.4332e-01 - val_output_loss: -4.4337e-01 - val_variance_output_loss: -4.4337e-01 - val_output_mean_absolute_error: 0.3238 - val_output_mean_error: -3.7109e-02\n",
      "Epoch 14/60\n",
      " - 1s - loss: -5.5177e-01 - output_loss: -5.5182e-01 - variance_output_loss: -5.5182e-01 - output_mean_absolute_error: 0.2846 - output_mean_error: -3.6495e-02 - val_loss: -5.0153e-01 - val_output_loss: -5.0157e-01 - val_variance_output_loss: -5.0157e-01 - val_output_mean_absolute_error: 0.3016 - val_output_mean_error: -6.3861e-02\n",
      "Epoch 15/60\n",
      " - 1s - loss: -5.6646e-01 - output_loss: -5.6651e-01 - variance_output_loss: -5.6651e-01 - output_mean_absolute_error: 0.2844 - output_mean_error: -4.1555e-02 - val_loss: -5.2089e-01 - val_output_loss: -5.2094e-01 - val_variance_output_loss: -5.2094e-01 - val_output_mean_absolute_error: 0.2922 - val_output_mean_error: 0.0057\n",
      "Epoch 16/60\n",
      " - 1s - loss: -5.9729e-01 - output_loss: -5.9734e-01 - variance_output_loss: -5.9734e-01 - output_mean_absolute_error: 0.2738 - output_mean_error: -3.1151e-02 - val_loss: -5.8708e-01 - val_output_loss: -5.8713e-01 - val_variance_output_loss: -5.8713e-01 - val_output_mean_absolute_error: 0.2836 - val_output_mean_error: -6.7759e-02\n",
      "Epoch 17/60\n",
      " - 1s - loss: -6.2803e-01 - output_loss: -6.2807e-01 - variance_output_loss: -6.2807e-01 - output_mean_absolute_error: 0.2691 - output_mean_error: -3.6872e-02 - val_loss: -5.9784e-01 - val_output_loss: -5.9789e-01 - val_variance_output_loss: -5.9789e-01 - val_output_mean_absolute_error: 0.2712 - val_output_mean_error: -1.8966e-02\n",
      "Epoch 18/60\n",
      " - 1s - loss: -6.6489e-01 - output_loss: -6.6493e-01 - variance_output_loss: -6.6493e-01 - output_mean_absolute_error: 0.2581 - output_mean_error: -3.4598e-02 - val_loss: -6.0518e-01 - val_output_loss: -6.0523e-01 - val_variance_output_loss: -6.0523e-01 - val_output_mean_absolute_error: 0.2725 - val_output_mean_error: -5.3479e-02\n",
      "Epoch 19/60\n",
      " - 1s - loss: -6.9343e-01 - output_loss: -6.9347e-01 - variance_output_loss: -6.9347e-01 - output_mean_absolute_error: 0.2547 - output_mean_error: -3.4226e-02 - val_loss: -6.6675e-01 - val_output_loss: -6.6680e-01 - val_variance_output_loss: -6.6680e-01 - val_output_mean_absolute_error: 0.2527 - val_output_mean_error: -4.1324e-02\n",
      "Epoch 20/60\n",
      " - 1s - loss: -7.2535e-01 - output_loss: -7.2540e-01 - variance_output_loss: -7.2540e-01 - output_mean_absolute_error: 0.2428 - output_mean_error: -2.8086e-02 - val_loss: -7.0672e-01 - val_output_loss: -7.0677e-01 - val_variance_output_loss: -7.0677e-01 - val_output_mean_absolute_error: 0.2493 - val_output_mean_error: -9.6192e-03\n",
      "Epoch 21/60\n",
      " - 1s - loss: -7.1645e-01 - output_loss: -7.1650e-01 - variance_output_loss: -7.1650e-01 - output_mean_absolute_error: 0.2477 - output_mean_error: -3.1484e-02 - val_loss: -7.2228e-01 - val_output_loss: -7.2233e-01 - val_variance_output_loss: -7.2233e-01 - val_output_mean_absolute_error: 0.2471 - val_output_mean_error: -6.0309e-02\n",
      "Epoch 22/60\n",
      " - 1s - loss: -7.4614e-01 - output_loss: -7.4619e-01 - variance_output_loss: -7.4619e-01 - output_mean_absolute_error: 0.2377 - output_mean_error: -2.7407e-02 - val_loss: -7.0088e-01 - val_output_loss: -7.0093e-01 - val_variance_output_loss: -7.0093e-01 - val_output_mean_absolute_error: 0.2446 - val_output_mean_error: 0.0049\n",
      "Epoch 23/60\n",
      " - 1s - loss: -7.7467e-01 - output_loss: -7.7472e-01 - variance_output_loss: -7.7472e-01 - output_mean_absolute_error: 0.2352 - output_mean_error: -3.0578e-02 - val_loss: -7.2213e-01 - val_output_loss: -7.2218e-01 - val_variance_output_loss: -7.2218e-01 - val_output_mean_absolute_error: 0.2524 - val_output_mean_error: -4.4718e-02\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 24/60\n",
      " - 1s - loss: -8.0586e-01 - output_loss: -8.0591e-01 - variance_output_loss: -8.0591e-01 - output_mean_absolute_error: 0.2264 - output_mean_error: -2.5595e-02 - val_loss: -7.9753e-01 - val_output_loss: -7.9758e-01 - val_variance_output_loss: -7.9758e-01 - val_output_mean_absolute_error: 0.2227 - val_output_mean_error: -2.6394e-02\n",
      "Epoch 25/60\n",
      " - 1s - loss: -8.0176e-01 - output_loss: -8.0181e-01 - variance_output_loss: -8.0181e-01 - output_mean_absolute_error: 0.2302 - output_mean_error: -3.3232e-02 - val_loss: -7.7099e-01 - val_output_loss: -7.7104e-01 - val_variance_output_loss: -7.7104e-01 - val_output_mean_absolute_error: 0.2351 - val_output_mean_error: -1.9732e-02\n",
      "Epoch 26/60\n",
      " - 1s - loss: -8.1148e-01 - output_loss: -8.1153e-01 - variance_output_loss: -8.1153e-01 - output_mean_absolute_error: 0.2267 - output_mean_error: -2.5745e-02 - val_loss: -7.6193e-01 - val_output_loss: -7.6198e-01 - val_variance_output_loss: -7.6198e-01 - val_output_mean_absolute_error: 0.2386 - val_output_mean_error: -3.6202e-02\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 27/60\n",
      " - 1s - loss: -8.3753e-01 - output_loss: -8.3758e-01 - variance_output_loss: -8.3758e-01 - output_mean_absolute_error: 0.2218 - output_mean_error: -2.6462e-02 - val_loss: -7.6361e-01 - val_output_loss: -7.6367e-01 - val_variance_output_loss: -7.6367e-01 - val_output_mean_absolute_error: 0.2336 - val_output_mean_error: -5.5672e-02\n",
      "Epoch 28/60\n",
      " - 1s - loss: -8.2559e-01 - output_loss: -8.2565e-01 - variance_output_loss: -8.2565e-01 - output_mean_absolute_error: 0.2232 - output_mean_error: -2.6512e-02 - val_loss: -7.8509e-01 - val_output_loss: -7.8514e-01 - val_variance_output_loss: -7.8514e-01 - val_output_mean_absolute_error: 0.2306 - val_output_mean_error: -3.3274e-02\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 29/60\n",
      " - 1s - loss: -8.3776e-01 - output_loss: -8.3781e-01 - variance_output_loss: -8.3781e-01 - output_mean_absolute_error: 0.2222 - output_mean_error: -2.8711e-02 - val_loss: -7.6206e-01 - val_output_loss: -7.6211e-01 - val_variance_output_loss: -7.6211e-01 - val_output_mean_absolute_error: 0.2364 - val_output_mean_error: -3.0377e-02\n",
      "Epoch 30/60\n",
      " - 1s - loss: -8.5056e-01 - output_loss: -8.5061e-01 - variance_output_loss: -8.5061e-01 - output_mean_absolute_error: 0.2196 - output_mean_error: -2.7410e-02 - val_loss: -7.9205e-01 - val_output_loss: -7.9210e-01 - val_variance_output_loss: -7.9210e-01 - val_output_mean_absolute_error: 0.2253 - val_output_mean_error: -4.6637e-02\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 31/60\n",
      " - 1s - loss: -8.4316e-01 - output_loss: -8.4321e-01 - variance_output_loss: -8.4321e-01 - output_mean_absolute_error: 0.2203 - output_mean_error: -2.8391e-02 - val_loss: -7.3924e-01 - val_output_loss: -7.3929e-01 - val_variance_output_loss: -7.3929e-01 - val_output_mean_absolute_error: 0.2422 - val_output_mean_error: -2.5078e-02\n",
      "Epoch 32/60\n",
      " - 1s - loss: -8.5373e-01 - output_loss: -8.5378e-01 - variance_output_loss: -8.5378e-01 - output_mean_absolute_error: 0.2186 - output_mean_error: -2.7113e-02 - val_loss: -7.9824e-01 - val_output_loss: -7.9829e-01 - val_variance_output_loss: -7.9829e-01 - val_output_mean_absolute_error: 0.2318 - val_output_mean_error: -3.2333e-02\n",
      "Epoch 33/60\n",
      " - 1s - loss: -8.4921e-01 - output_loss: -8.4926e-01 - variance_output_loss: -8.4926e-01 - output_mean_absolute_error: 0.2221 - output_mean_error: -2.7227e-02 - val_loss: -7.4529e-01 - val_output_loss: -7.4534e-01 - val_variance_output_loss: -7.4534e-01 - val_output_mean_absolute_error: 0.2314 - val_output_mean_error: -8.3097e-03\n",
      "Epoch 34/60\n",
      " - 1s - loss: -8.5486e-01 - output_loss: -8.5491e-01 - variance_output_loss: -8.5491e-01 - output_mean_absolute_error: 0.2175 - output_mean_error: -2.6315e-02 - val_loss: -7.6045e-01 - val_output_loss: -7.6050e-01 - val_variance_output_loss: -7.6050e-01 - val_output_mean_absolute_error: 0.2395 - val_output_mean_error: -5.2022e-02\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 35/60\n",
      " - 1s - loss: -8.4980e-01 - output_loss: -8.4985e-01 - variance_output_loss: -8.4985e-01 - output_mean_absolute_error: 0.2191 - output_mean_error: -2.6480e-02 - val_loss: -8.0367e-01 - val_output_loss: -8.0372e-01 - val_variance_output_loss: -8.0372e-01 - val_output_mean_absolute_error: 0.2304 - val_output_mean_error: 0.0013\n",
      "Epoch 36/60\n",
      " - 1s - loss: -8.5827e-01 - output_loss: -8.5832e-01 - variance_output_loss: -8.5832e-01 - output_mean_absolute_error: 0.2175 - output_mean_error: -2.6187e-02 - val_loss: -8.0854e-01 - val_output_loss: -8.0859e-01 - val_variance_output_loss: -8.0859e-01 - val_output_mean_absolute_error: 0.2262 - val_output_mean_error: -4.6407e-02\n",
      "Epoch 37/60\n",
      " - 1s - loss: -8.4509e-01 - output_loss: -8.4514e-01 - variance_output_loss: -8.4514e-01 - output_mean_absolute_error: 0.2209 - output_mean_error: -2.9792e-02 - val_loss: -8.0884e-01 - val_output_loss: -8.0889e-01 - val_variance_output_loss: -8.0889e-01 - val_output_mean_absolute_error: 0.2224 - val_output_mean_error: -1.0824e-02\n",
      "Epoch 38/60\n",
      " - 1s - loss: -8.5948e-01 - output_loss: -8.5953e-01 - variance_output_loss: -8.5953e-01 - output_mean_absolute_error: 0.2159 - output_mean_error: -2.4522e-02 - val_loss: -8.4230e-01 - val_output_loss: -8.4235e-01 - val_variance_output_loss: -8.4235e-01 - val_output_mean_absolute_error: 0.2200 - val_output_mean_error: -2.7907e-02\n",
      "Epoch 39/60\n",
      " - 1s - loss: -8.5081e-01 - output_loss: -8.5086e-01 - variance_output_loss: -8.5086e-01 - output_mean_absolute_error: 0.2200 - output_mean_error: -2.6984e-02 - val_loss: -7.8203e-01 - val_output_loss: -7.8208e-01 - val_variance_output_loss: -7.8208e-01 - val_output_mean_absolute_error: 0.2346 - val_output_mean_error: -3.0000e-02\n",
      "Epoch 40/60\n",
      " - 1s - loss: -8.6053e-01 - output_loss: -8.6058e-01 - variance_output_loss: -8.6058e-01 - output_mean_absolute_error: 0.2188 - output_mean_error: -2.8619e-02 - val_loss: -8.1763e-01 - val_output_loss: -8.1768e-01 - val_variance_output_loss: -8.1768e-01 - val_output_mean_absolute_error: 0.2273 - val_output_mean_error: -3.4445e-02\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 41/60\n",
      " - 1s - loss: -8.7455e-01 - output_loss: -8.7460e-01 - variance_output_loss: -8.7460e-01 - output_mean_absolute_error: 0.2147 - output_mean_error: -2.2479e-02 - val_loss: -7.8404e-01 - val_output_loss: -7.8409e-01 - val_variance_output_loss: -7.8409e-01 - val_output_mean_absolute_error: 0.2282 - val_output_mean_error: -3.3316e-02\n",
      "Epoch 42/60\n",
      " - 1s - loss: -8.6116e-01 - output_loss: -8.6121e-01 - variance_output_loss: -8.6121e-01 - output_mean_absolute_error: 0.2181 - output_mean_error: -2.7682e-02 - val_loss: -8.0213e-01 - val_output_loss: -8.0218e-01 - val_variance_output_loss: -8.0218e-01 - val_output_mean_absolute_error: 0.2303 - val_output_mean_error: -3.3412e-02\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 43/60\n",
      " - 1s - loss: -8.5276e-01 - output_loss: -8.5281e-01 - variance_output_loss: -8.5281e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.7068e-02 - val_loss: -8.1750e-01 - val_output_loss: -8.1755e-01 - val_variance_output_loss: -8.1755e-01 - val_output_mean_absolute_error: 0.2254 - val_output_mean_error: -3.0011e-02\n",
      "Epoch 44/60\n",
      " - 1s - loss: -8.5653e-01 - output_loss: -8.5658e-01 - variance_output_loss: -8.5658e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.8189e-02 - val_loss: -7.9744e-01 - val_output_loss: -7.9749e-01 - val_variance_output_loss: -7.9749e-01 - val_output_mean_absolute_error: 0.2356 - val_output_mean_error: -3.2064e-02\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 45/60\n",
      " - 1s - loss: -8.6308e-01 - output_loss: -8.6313e-01 - variance_output_loss: -8.6313e-01 - output_mean_absolute_error: 0.2163 - output_mean_error: -2.2857e-02 - val_loss: -8.0846e-01 - val_output_loss: -8.0851e-01 - val_variance_output_loss: -8.0851e-01 - val_output_mean_absolute_error: 0.2250 - val_output_mean_error: -2.9214e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/60\n",
      " - 1s - loss: -8.5248e-01 - output_loss: -8.5253e-01 - variance_output_loss: -8.5253e-01 - output_mean_absolute_error: 0.2189 - output_mean_error: -2.8606e-02 - val_loss: -7.8174e-01 - val_output_loss: -7.8179e-01 - val_variance_output_loss: -7.8179e-01 - val_output_mean_absolute_error: 0.2349 - val_output_mean_error: -2.2638e-02\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 47/60\n",
      " - 1s - loss: -8.5219e-01 - output_loss: -8.5224e-01 - variance_output_loss: -8.5224e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.4259e-02 - val_loss: -8.4288e-01 - val_output_loss: -8.4293e-01 - val_variance_output_loss: -8.4293e-01 - val_output_mean_absolute_error: 0.2190 - val_output_mean_error: -2.6133e-02\n",
      "Epoch 48/60\n",
      " - 1s - loss: -8.6340e-01 - output_loss: -8.6346e-01 - variance_output_loss: -8.6346e-01 - output_mean_absolute_error: 0.2176 - output_mean_error: -3.0914e-02 - val_loss: -7.9581e-01 - val_output_loss: -7.9586e-01 - val_variance_output_loss: -7.9586e-01 - val_output_mean_absolute_error: 0.2273 - val_output_mean_error: -1.1548e-02\n",
      "Epoch 49/60\n",
      " - 1s - loss: -8.4937e-01 - output_loss: -8.4943e-01 - variance_output_loss: -8.4943e-01 - output_mean_absolute_error: 0.2205 - output_mean_error: -3.0583e-02 - val_loss: -7.9666e-01 - val_output_loss: -7.9671e-01 - val_variance_output_loss: -7.9671e-01 - val_output_mean_absolute_error: 0.2322 - val_output_mean_error: -3.8083e-02\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 50/60\n",
      " - 1s - loss: -8.6280e-01 - output_loss: -8.6285e-01 - variance_output_loss: -8.6285e-01 - output_mean_absolute_error: 0.2165 - output_mean_error: -2.4932e-02 - val_loss: -7.8482e-01 - val_output_loss: -7.8488e-01 - val_variance_output_loss: -7.8488e-01 - val_output_mean_absolute_error: 0.2352 - val_output_mean_error: -2.4251e-02\n",
      "Epoch 51/60\n",
      " - 1s - loss: -8.6471e-01 - output_loss: -8.6476e-01 - variance_output_loss: -8.6476e-01 - output_mean_absolute_error: 0.2166 - output_mean_error: -2.6203e-02 - val_loss: -7.8671e-01 - val_output_loss: -7.8676e-01 - val_variance_output_loss: -7.8676e-01 - val_output_mean_absolute_error: 0.2257 - val_output_mean_error: -2.2793e-02\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 52/60\n",
      " - 1s - loss: -8.6474e-01 - output_loss: -8.6479e-01 - variance_output_loss: -8.6479e-01 - output_mean_absolute_error: 0.2173 - output_mean_error: -2.9252e-02 - val_loss: -7.5581e-01 - val_output_loss: -7.5586e-01 - val_variance_output_loss: -7.5586e-01 - val_output_mean_absolute_error: 0.2368 - val_output_mean_error: -3.0232e-02\n",
      "Epoch 53/60\n",
      " - 1s - loss: -8.6116e-01 - output_loss: -8.6121e-01 - variance_output_loss: -8.6121e-01 - output_mean_absolute_error: 0.2169 - output_mean_error: -2.4582e-02 - val_loss: -8.2189e-01 - val_output_loss: -8.2194e-01 - val_variance_output_loss: -8.2194e-01 - val_output_mean_absolute_error: 0.2193 - val_output_mean_error: -2.0764e-02\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 54/60\n",
      " - 1s - loss: -8.6539e-01 - output_loss: -8.6544e-01 - variance_output_loss: -8.6544e-01 - output_mean_absolute_error: 0.2174 - output_mean_error: -2.9423e-02 - val_loss: -8.2636e-01 - val_output_loss: -8.2641e-01 - val_variance_output_loss: -8.2641e-01 - val_output_mean_absolute_error: 0.2195 - val_output_mean_error: -2.7064e-02\n",
      "Epoch 55/60\n",
      " - 1s - loss: -8.4854e-01 - output_loss: -8.4859e-01 - variance_output_loss: -8.4859e-01 - output_mean_absolute_error: 0.2185 - output_mean_error: -2.4577e-02 - val_loss: -8.0316e-01 - val_output_loss: -8.0321e-01 - val_variance_output_loss: -8.0321e-01 - val_output_mean_absolute_error: 0.2347 - val_output_mean_error: -2.4151e-02\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 56/60\n",
      " - 1s - loss: -8.4959e-01 - output_loss: -8.4964e-01 - variance_output_loss: -8.4964e-01 - output_mean_absolute_error: 0.2189 - output_mean_error: -2.8588e-02 - val_loss: -8.1500e-01 - val_output_loss: -8.1505e-01 - val_variance_output_loss: -8.1505e-01 - val_output_mean_absolute_error: 0.2267 - val_output_mean_error: -3.3707e-02\n",
      "Epoch 57/60\n",
      " - 1s - loss: -8.7571e-01 - output_loss: -8.7576e-01 - variance_output_loss: -8.7576e-01 - output_mean_absolute_error: 0.2126 - output_mean_error: -2.3711e-02 - val_loss: -7.7255e-01 - val_output_loss: -7.7260e-01 - val_variance_output_loss: -7.7260e-01 - val_output_mean_absolute_error: 0.2360 - val_output_mean_error: -2.8271e-02\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 58/60\n",
      " - 1s - loss: -8.5666e-01 - output_loss: -8.5671e-01 - variance_output_loss: -8.5671e-01 - output_mean_absolute_error: 0.2197 - output_mean_error: -2.4424e-02 - val_loss: -7.8550e-01 - val_output_loss: -7.8555e-01 - val_variance_output_loss: -7.8555e-01 - val_output_mean_absolute_error: 0.2327 - val_output_mean_error: -2.9433e-02\n",
      "Epoch 59/60\n",
      " - 1s - loss: -8.5500e-01 - output_loss: -8.5505e-01 - variance_output_loss: -8.5505e-01 - output_mean_absolute_error: 0.2182 - output_mean_error: -2.6217e-02 - val_loss: -8.1519e-01 - val_output_loss: -8.1524e-01 - val_variance_output_loss: -8.1524e-01 - val_output_mean_absolute_error: 0.2181 - val_output_mean_error: -3.0092e-02\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 60/60\n",
      " - 1s - loss: -8.5664e-01 - output_loss: -8.5669e-01 - variance_output_loss: -8.5669e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.9202e-02 - val_loss: -8.5742e-01 - val_output_loss: -8.5747e-01 - val_variance_output_loss: -8.5747e-01 - val_output_mean_absolute_error: 0.2175 - val_output_mean_error: -1.8125e-02\n",
      "Completed Training, 79.97s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_model_fixed_6_25/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_6_25'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/16), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 939, Number of Validation Data: 104\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 6s - loss: 0.4819 - output_loss: 0.4818 - variance_output_loss: 0.4818 - output_mean_absolute_error: 0.7017 - output_mean_error: -1.3248e-02 - val_loss: 0.3123 - val_output_loss: 0.3123 - val_variance_output_loss: 0.3123 - val_output_mean_absolute_error: 0.5688 - val_output_mean_error: 0.1058\n",
      "Epoch 2/60\n",
      " - 1s - loss: 0.4943 - output_loss: 0.4943 - variance_output_loss: 0.4943 - output_mean_absolute_error: 0.7097 - output_mean_error: -3.2834e-02 - val_loss: 0.3214 - val_output_loss: 0.3214 - val_variance_output_loss: 0.3214 - val_output_mean_absolute_error: 0.5853 - val_output_mean_error: 0.1485\n",
      "Epoch 3/60\n",
      " - 1s - loss: 0.4216 - output_loss: 0.4216 - variance_output_loss: 0.4216 - output_mean_absolute_error: 0.6613 - output_mean_error: 2.8559e-04 - val_loss: 0.2772 - val_output_loss: 0.2772 - val_variance_output_loss: 0.2772 - val_output_mean_absolute_error: 0.5943 - val_output_mean_error: 0.0958\n",
      "Epoch 4/60\n",
      " - 1s - loss: 0.4263 - output_loss: 0.4262 - variance_output_loss: 0.4262 - output_mean_absolute_error: 0.6677 - output_mean_error: -1.3007e-02 - val_loss: 0.3557 - val_output_loss: 0.3557 - val_variance_output_loss: 0.3557 - val_output_mean_absolute_error: 0.6158 - val_output_mean_error: 0.1037\n",
      "Epoch 5/60\n",
      " - 1s - loss: 0.4606 - output_loss: 0.4605 - variance_output_loss: 0.4605 - output_mean_absolute_error: 0.6763 - output_mean_error: -2.5260e-02 - val_loss: 0.2662 - val_output_loss: 0.2662 - val_variance_output_loss: 0.2662 - val_output_mean_absolute_error: 0.5593 - val_output_mean_error: 0.0353\n",
      "Epoch 6/60\n",
      " - 1s - loss: 0.3704 - output_loss: 0.3704 - variance_output_loss: 0.3704 - output_mean_absolute_error: 0.6203 - output_mean_error: -2.9312e-04 - val_loss: 0.2248 - val_output_loss: 0.2248 - val_variance_output_loss: 0.2248 - val_output_mean_absolute_error: 0.5530 - val_output_mean_error: 0.0982\n",
      "Epoch 7/60\n",
      " - 1s - loss: 0.3301 - output_loss: 0.3301 - variance_output_loss: 0.3301 - output_mean_absolute_error: 0.5980 - output_mean_error: -4.0815e-02 - val_loss: 0.1797 - val_output_loss: 0.1796 - val_variance_output_loss: 0.1796 - val_output_mean_absolute_error: 0.5331 - val_output_mean_error: 0.0693\n",
      "Epoch 8/60\n",
      " - 1s - loss: 0.2657 - output_loss: 0.2656 - variance_output_loss: 0.2656 - output_mean_absolute_error: 0.5735 - output_mean_error: -1.9646e-02 - val_loss: 0.1433 - val_output_loss: 0.1433 - val_variance_output_loss: 0.1433 - val_output_mean_absolute_error: 0.5159 - val_output_mean_error: 0.0285\n",
      "Epoch 9/60\n",
      " - 1s - loss: 0.2135 - output_loss: 0.2134 - variance_output_loss: 0.2134 - output_mean_absolute_error: 0.5436 - output_mean_error: -6.3124e-02 - val_loss: 0.0816 - val_output_loss: 0.0816 - val_variance_output_loss: 0.0816 - val_output_mean_absolute_error: 0.4859 - val_output_mean_error: 0.0258\n",
      "Epoch 10/60\n",
      " - 1s - loss: 0.1302 - output_loss: 0.1301 - variance_output_loss: 0.1301 - output_mean_absolute_error: 0.5178 - output_mean_error: -3.8115e-02 - val_loss: 0.0280 - val_output_loss: 0.0279 - val_variance_output_loss: 0.0279 - val_output_mean_absolute_error: 0.4641 - val_output_mean_error: 0.0908\n",
      "Epoch 11/60\n",
      " - 1s - loss: 0.1017 - output_loss: 0.1016 - variance_output_loss: 0.1016 - output_mean_absolute_error: 0.5104 - output_mean_error: -4.8163e-02 - val_loss: -1.0692e-02 - val_output_loss: -1.0738e-02 - val_variance_output_loss: -1.0738e-02 - val_output_mean_absolute_error: 0.4391 - val_output_mean_error: -1.7737e-02\n",
      "Epoch 12/60\n",
      " - 1s - loss: 0.0199 - output_loss: 0.0199 - variance_output_loss: 0.0199 - output_mean_absolute_error: 0.4753 - output_mean_error: -5.9459e-02 - val_loss: -6.2743e-02 - val_output_loss: -6.2789e-02 - val_variance_output_loss: -6.2789e-02 - val_output_mean_absolute_error: 0.4369 - val_output_mean_error: -1.1720e-02\n",
      "Epoch 13/60\n",
      " - 1s - loss: -1.7830e-02 - output_loss: -1.7875e-02 - variance_output_loss: -1.7875e-02 - output_mean_absolute_error: 0.4658 - output_mean_error: -6.4620e-02 - val_loss: -1.3310e-01 - val_output_loss: -1.3315e-01 - val_variance_output_loss: -1.3315e-01 - val_output_mean_absolute_error: 0.4006 - val_output_mean_error: -1.0067e-03\n",
      "Epoch 14/60\n",
      " - 1s - loss: -6.9499e-02 - output_loss: -6.9545e-02 - variance_output_loss: -6.9545e-02 - output_mean_absolute_error: 0.4461 - output_mean_error: -6.1632e-02 - val_loss: -1.5680e-01 - val_output_loss: -1.5685e-01 - val_variance_output_loss: -1.5685e-01 - val_output_mean_absolute_error: 0.3978 - val_output_mean_error: 0.0206\n",
      "Epoch 15/60\n",
      " - 1s - loss: -9.5932e-02 - output_loss: -9.5978e-02 - variance_output_loss: -9.5978e-02 - output_mean_absolute_error: 0.4455 - output_mean_error: -9.0086e-02 - val_loss: -2.0262e-01 - val_output_loss: -2.0267e-01 - val_variance_output_loss: -2.0267e-01 - val_output_mean_absolute_error: 0.3622 - val_output_mean_error: 0.0118\n",
      "Epoch 16/60\n",
      " - 1s - loss: -1.6332e-01 - output_loss: -1.6337e-01 - variance_output_loss: -1.6337e-01 - output_mean_absolute_error: 0.4176 - output_mean_error: -6.0686e-02 - val_loss: -2.0568e-01 - val_output_loss: -2.0573e-01 - val_variance_output_loss: -2.0573e-01 - val_output_mean_absolute_error: 0.3893 - val_output_mean_error: -4.6918e-02\n",
      "Epoch 17/60\n",
      " - 1s - loss: -1.6616e-01 - output_loss: -1.6620e-01 - variance_output_loss: -1.6620e-01 - output_mean_absolute_error: 0.4225 - output_mean_error: -8.3032e-02 - val_loss: -2.2810e-01 - val_output_loss: -2.2815e-01 - val_variance_output_loss: -2.2815e-01 - val_output_mean_absolute_error: 0.3907 - val_output_mean_error: -4.5269e-02\n",
      "Epoch 18/60\n",
      " - 1s - loss: -2.2477e-01 - output_loss: -2.2482e-01 - variance_output_loss: -2.2482e-01 - output_mean_absolute_error: 0.4000 - output_mean_error: -6.5321e-02 - val_loss: -2.5105e-01 - val_output_loss: -2.5110e-01 - val_variance_output_loss: -2.5110e-01 - val_output_mean_absolute_error: 0.3590 - val_output_mean_error: -3.8811e-02\n",
      "Epoch 19/60\n",
      " - 1s - loss: -2.4958e-01 - output_loss: -2.4962e-01 - variance_output_loss: -2.4962e-01 - output_mean_absolute_error: 0.3924 - output_mean_error: -7.8512e-02 - val_loss: -3.1833e-01 - val_output_loss: -3.1838e-01 - val_variance_output_loss: -3.1838e-01 - val_output_mean_absolute_error: 0.3552 - val_output_mean_error: 0.0195\n",
      "Epoch 20/60\n",
      " - 1s - loss: -2.6593e-01 - output_loss: -2.6598e-01 - variance_output_loss: -2.6598e-01 - output_mean_absolute_error: 0.3857 - output_mean_error: -7.4378e-02 - val_loss: -3.0016e-01 - val_output_loss: -3.0021e-01 - val_variance_output_loss: -3.0021e-01 - val_output_mean_absolute_error: 0.3718 - val_output_mean_error: -5.9437e-02\n",
      "Epoch 21/60\n",
      " - 1s - loss: -2.9294e-01 - output_loss: -2.9298e-01 - variance_output_loss: -2.9298e-01 - output_mean_absolute_error: 0.3794 - output_mean_error: -6.9863e-02 - val_loss: -3.5708e-01 - val_output_loss: -3.5713e-01 - val_variance_output_loss: -3.5713e-01 - val_output_mean_absolute_error: 0.3410 - val_output_mean_error: -3.2643e-02\n",
      "Epoch 22/60\n",
      " - 1s - loss: -3.1864e-01 - output_loss: -3.1869e-01 - variance_output_loss: -3.1869e-01 - output_mean_absolute_error: 0.3710 - output_mean_error: -6.7801e-02 - val_loss: -3.8196e-01 - val_output_loss: -3.8200e-01 - val_variance_output_loss: -3.8200e-01 - val_output_mean_absolute_error: 0.3329 - val_output_mean_error: -1.0257e-02\n",
      "Epoch 23/60\n",
      " - 1s - loss: -3.5316e-01 - output_loss: -3.5321e-01 - variance_output_loss: -3.5321e-01 - output_mean_absolute_error: 0.3577 - output_mean_error: -5.5498e-02 - val_loss: -3.7921e-01 - val_output_loss: -3.7926e-01 - val_variance_output_loss: -3.7926e-01 - val_output_mean_absolute_error: 0.3483 - val_output_mean_error: -4.3060e-02\n",
      "Epoch 24/60\n",
      " - 1s - loss: -3.6394e-01 - output_loss: -3.6398e-01 - variance_output_loss: -3.6398e-01 - output_mean_absolute_error: 0.3587 - output_mean_error: -7.1982e-02 - val_loss: -4.5015e-01 - val_output_loss: -4.5020e-01 - val_variance_output_loss: -4.5020e-01 - val_output_mean_absolute_error: 0.3130 - val_output_mean_error: -6.9040e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      " - 1s - loss: -3.9155e-01 - output_loss: -3.9159e-01 - variance_output_loss: -3.9159e-01 - output_mean_absolute_error: 0.3500 - output_mean_error: -5.5693e-02 - val_loss: -3.6585e-01 - val_output_loss: -3.6589e-01 - val_variance_output_loss: -3.6589e-01 - val_output_mean_absolute_error: 0.3403 - val_output_mean_error: 0.0425\n",
      "Epoch 26/60\n",
      " - 1s - loss: -4.0286e-01 - output_loss: -4.0290e-01 - variance_output_loss: -4.0290e-01 - output_mean_absolute_error: 0.3461 - output_mean_error: -6.3673e-02 - val_loss: -3.7752e-01 - val_output_loss: -3.7757e-01 - val_variance_output_loss: -3.7757e-01 - val_output_mean_absolute_error: 0.3405 - val_output_mean_error: 0.0625\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 27/60\n",
      " - 1s - loss: -4.3230e-01 - output_loss: -4.3234e-01 - variance_output_loss: -4.3234e-01 - output_mean_absolute_error: 0.3341 - output_mean_error: -5.5570e-02 - val_loss: -4.2472e-01 - val_output_loss: -4.2476e-01 - val_variance_output_loss: -4.2476e-01 - val_output_mean_absolute_error: 0.3247 - val_output_mean_error: -2.5207e-02\n",
      "Epoch 28/60\n",
      " - 1s - loss: -4.3255e-01 - output_loss: -4.3260e-01 - variance_output_loss: -4.3260e-01 - output_mean_absolute_error: 0.3346 - output_mean_error: -5.3318e-02 - val_loss: -4.6593e-01 - val_output_loss: -4.6598e-01 - val_variance_output_loss: -4.6598e-01 - val_output_mean_absolute_error: 0.3049 - val_output_mean_error: 3.8070e-04\n",
      "Epoch 29/60\n",
      " - 1s - loss: -4.4733e-01 - output_loss: -4.4738e-01 - variance_output_loss: -4.4738e-01 - output_mean_absolute_error: 0.3338 - output_mean_error: -6.0701e-02 - val_loss: -4.8591e-01 - val_output_loss: -4.8595e-01 - val_variance_output_loss: -4.8595e-01 - val_output_mean_absolute_error: 0.3070 - val_output_mean_error: -8.8801e-03\n",
      "Epoch 30/60\n",
      " - 1s - loss: -4.6619e-01 - output_loss: -4.6624e-01 - variance_output_loss: -4.6624e-01 - output_mean_absolute_error: 0.3263 - output_mean_error: -6.3640e-02 - val_loss: -4.6178e-01 - val_output_loss: -4.6183e-01 - val_variance_output_loss: -4.6183e-01 - val_output_mean_absolute_error: 0.3140 - val_output_mean_error: 0.0047\n",
      "Epoch 31/60\n",
      " - 1s - loss: -4.7116e-01 - output_loss: -4.7120e-01 - variance_output_loss: -4.7120e-01 - output_mean_absolute_error: 0.3214 - output_mean_error: -3.8253e-02 - val_loss: -4.4829e-01 - val_output_loss: -4.4834e-01 - val_variance_output_loss: -4.4834e-01 - val_output_mean_absolute_error: 0.3299 - val_output_mean_error: -5.1166e-02\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 32/60\n",
      " - 1s - loss: -4.7837e-01 - output_loss: -4.7842e-01 - variance_output_loss: -4.7842e-01 - output_mean_absolute_error: 0.3233 - output_mean_error: -5.9977e-02 - val_loss: -5.4922e-01 - val_output_loss: -5.4927e-01 - val_variance_output_loss: -5.4927e-01 - val_output_mean_absolute_error: 0.2923 - val_output_mean_error: -1.4871e-02\n",
      "Epoch 33/60\n",
      " - 1s - loss: -4.7344e-01 - output_loss: -4.7348e-01 - variance_output_loss: -4.7348e-01 - output_mean_absolute_error: 0.3228 - output_mean_error: -4.8075e-02 - val_loss: -4.5497e-01 - val_output_loss: -4.5502e-01 - val_variance_output_loss: -4.5502e-01 - val_output_mean_absolute_error: 0.3094 - val_output_mean_error: -3.4269e-02\n",
      "Epoch 34/60\n",
      " - 1s - loss: -4.7747e-01 - output_loss: -4.7752e-01 - variance_output_loss: -4.7752e-01 - output_mean_absolute_error: 0.3239 - output_mean_error: -6.1079e-02 - val_loss: -4.9368e-01 - val_output_loss: -4.9373e-01 - val_variance_output_loss: -4.9373e-01 - val_output_mean_absolute_error: 0.2996 - val_output_mean_error: -2.3666e-02\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 35/60\n",
      " - 1s - loss: -5.0255e-01 - output_loss: -5.0260e-01 - variance_output_loss: -5.0260e-01 - output_mean_absolute_error: 0.3103 - output_mean_error: -3.5684e-02 - val_loss: -5.3201e-01 - val_output_loss: -5.3206e-01 - val_variance_output_loss: -5.3206e-01 - val_output_mean_absolute_error: 0.2864 - val_output_mean_error: -4.4030e-02\n",
      "Epoch 36/60\n",
      " - 1s - loss: -4.8141e-01 - output_loss: -4.8146e-01 - variance_output_loss: -4.8146e-01 - output_mean_absolute_error: 0.3252 - output_mean_error: -6.2617e-02 - val_loss: -4.7752e-01 - val_output_loss: -4.7757e-01 - val_variance_output_loss: -4.7757e-01 - val_output_mean_absolute_error: 0.2981 - val_output_mean_error: -1.4426e-02\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 37/60\n",
      " - 1s - loss: -4.9291e-01 - output_loss: -4.9296e-01 - variance_output_loss: -4.9296e-01 - output_mean_absolute_error: 0.3157 - output_mean_error: -5.0730e-02 - val_loss: -4.9534e-01 - val_output_loss: -4.9539e-01 - val_variance_output_loss: -4.9539e-01 - val_output_mean_absolute_error: 0.3034 - val_output_mean_error: 0.0026\n",
      "Epoch 38/60\n",
      " - 1s - loss: -5.0091e-01 - output_loss: -5.0096e-01 - variance_output_loss: -5.0096e-01 - output_mean_absolute_error: 0.3135 - output_mean_error: -4.3708e-02 - val_loss: -4.8732e-01 - val_output_loss: -4.8737e-01 - val_variance_output_loss: -4.8737e-01 - val_output_mean_absolute_error: 0.3181 - val_output_mean_error: -3.9015e-02\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 39/60\n",
      " - 1s - loss: -4.9591e-01 - output_loss: -4.9596e-01 - variance_output_loss: -4.9596e-01 - output_mean_absolute_error: 0.3158 - output_mean_error: -5.3267e-02 - val_loss: -4.6304e-01 - val_output_loss: -4.6309e-01 - val_variance_output_loss: -4.6309e-01 - val_output_mean_absolute_error: 0.3124 - val_output_mean_error: -1.7426e-02\n",
      "Epoch 40/60\n",
      " - 1s - loss: -4.9733e-01 - output_loss: -4.9738e-01 - variance_output_loss: -4.9738e-01 - output_mean_absolute_error: 0.3177 - output_mean_error: -5.4160e-02 - val_loss: -4.8406e-01 - val_output_loss: -4.8411e-01 - val_variance_output_loss: -4.8411e-01 - val_output_mean_absolute_error: 0.2986 - val_output_mean_error: -7.4843e-03\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 41/60\n",
      " - 1s - loss: -4.8962e-01 - output_loss: -4.8966e-01 - variance_output_loss: -4.8966e-01 - output_mean_absolute_error: 0.3158 - output_mean_error: -4.6726e-02 - val_loss: -5.3549e-01 - val_output_loss: -5.3554e-01 - val_variance_output_loss: -5.3554e-01 - val_output_mean_absolute_error: 0.2890 - val_output_mean_error: -3.8561e-03\n",
      "Epoch 42/60\n",
      " - 1s - loss: -5.1477e-01 - output_loss: -5.1481e-01 - variance_output_loss: -5.1481e-01 - output_mean_absolute_error: 0.3105 - output_mean_error: -5.4747e-02 - val_loss: -5.6296e-01 - val_output_loss: -5.6300e-01 - val_variance_output_loss: -5.6300e-01 - val_output_mean_absolute_error: 0.2868 - val_output_mean_error: -3.0884e-02\n",
      "Epoch 43/60\n",
      " - 1s - loss: -4.9731e-01 - output_loss: -4.9736e-01 - variance_output_loss: -4.9736e-01 - output_mean_absolute_error: 0.3183 - output_mean_error: -5.4092e-02 - val_loss: -4.5754e-01 - val_output_loss: -4.5758e-01 - val_variance_output_loss: -4.5758e-01 - val_output_mean_absolute_error: 0.3043 - val_output_mean_error: -1.3168e-02\n",
      "Epoch 44/60\n",
      " - 1s - loss: -5.0740e-01 - output_loss: -5.0745e-01 - variance_output_loss: -5.0745e-01 - output_mean_absolute_error: 0.3126 - output_mean_error: -4.6624e-02 - val_loss: -5.2231e-01 - val_output_loss: -5.2236e-01 - val_variance_output_loss: -5.2236e-01 - val_output_mean_absolute_error: 0.3122 - val_output_mean_error: -3.6513e-02\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 45/60\n",
      " - 1s - loss: -5.0443e-01 - output_loss: -5.0448e-01 - variance_output_loss: -5.0448e-01 - output_mean_absolute_error: 0.3157 - output_mean_error: -5.6487e-02 - val_loss: -5.0937e-01 - val_output_loss: -5.0942e-01 - val_variance_output_loss: -5.0942e-01 - val_output_mean_absolute_error: 0.2945 - val_output_mean_error: -7.8778e-03\n",
      "Epoch 46/60\n",
      " - 1s - loss: -4.9401e-01 - output_loss: -4.9405e-01 - variance_output_loss: -4.9405e-01 - output_mean_absolute_error: 0.3202 - output_mean_error: -6.1656e-02 - val_loss: -5.0086e-01 - val_output_loss: -5.0090e-01 - val_variance_output_loss: -5.0090e-01 - val_output_mean_absolute_error: 0.2982 - val_output_mean_error: 0.0047\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      " - 1s - loss: -4.9778e-01 - output_loss: -4.9783e-01 - variance_output_loss: -4.9783e-01 - output_mean_absolute_error: 0.3133 - output_mean_error: -4.7610e-02 - val_loss: -5.1586e-01 - val_output_loss: -5.1591e-01 - val_variance_output_loss: -5.1591e-01 - val_output_mean_absolute_error: 0.3034 - val_output_mean_error: -3.8256e-02\n",
      "Epoch 48/60\n",
      " - 1s - loss: -5.0118e-01 - output_loss: -5.0123e-01 - variance_output_loss: -5.0123e-01 - output_mean_absolute_error: 0.3108 - output_mean_error: -4.7081e-02 - val_loss: -4.9944e-01 - val_output_loss: -4.9949e-01 - val_variance_output_loss: -4.9949e-01 - val_output_mean_absolute_error: 0.3030 - val_output_mean_error: -2.4089e-02\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 49/60\n",
      " - 1s - loss: -4.8121e-01 - output_loss: -4.8126e-01 - variance_output_loss: -4.8126e-01 - output_mean_absolute_error: 0.3236 - output_mean_error: -5.4614e-02 - val_loss: -5.0913e-01 - val_output_loss: -5.0918e-01 - val_variance_output_loss: -5.0918e-01 - val_output_mean_absolute_error: 0.3025 - val_output_mean_error: -3.0631e-02\n",
      "Epoch 50/60\n",
      " - 1s - loss: -5.0957e-01 - output_loss: -5.0962e-01 - variance_output_loss: -5.0962e-01 - output_mean_absolute_error: 0.3113 - output_mean_error: -5.4415e-02 - val_loss: -5.2001e-01 - val_output_loss: -5.2006e-01 - val_variance_output_loss: -5.2006e-01 - val_output_mean_absolute_error: 0.3023 - val_output_mean_error: -2.8331e-02\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 51/60\n",
      " - 1s - loss: -4.9922e-01 - output_loss: -4.9927e-01 - variance_output_loss: -4.9927e-01 - output_mean_absolute_error: 0.3171 - output_mean_error: -5.8330e-02 - val_loss: -5.3667e-01 - val_output_loss: -5.3672e-01 - val_variance_output_loss: -5.3672e-01 - val_output_mean_absolute_error: 0.2887 - val_output_mean_error: -3.8947e-02\n",
      "Epoch 52/60\n",
      " - 1s - loss: -4.8920e-01 - output_loss: -4.8924e-01 - variance_output_loss: -4.8924e-01 - output_mean_absolute_error: 0.3175 - output_mean_error: -5.0056e-02 - val_loss: -5.1326e-01 - val_output_loss: -5.1331e-01 - val_variance_output_loss: -5.1331e-01 - val_output_mean_absolute_error: 0.3062 - val_output_mean_error: -2.3995e-02\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 53/60\n",
      " - 1s - loss: -5.0437e-01 - output_loss: -5.0442e-01 - variance_output_loss: -5.0442e-01 - output_mean_absolute_error: 0.3136 - output_mean_error: -5.7288e-02 - val_loss: -5.5612e-01 - val_output_loss: -5.5616e-01 - val_variance_output_loss: -5.5616e-01 - val_output_mean_absolute_error: 0.2842 - val_output_mean_error: -8.4786e-03\n",
      "Epoch 54/60\n",
      " - 1s - loss: -4.9956e-01 - output_loss: -4.9961e-01 - variance_output_loss: -4.9961e-01 - output_mean_absolute_error: 0.3166 - output_mean_error: -4.9170e-02 - val_loss: -5.3616e-01 - val_output_loss: -5.3621e-01 - val_variance_output_loss: -5.3621e-01 - val_output_mean_absolute_error: 0.2952 - val_output_mean_error: -2.8191e-02\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 55/60\n",
      " - 1s - loss: -4.9695e-01 - output_loss: -4.9700e-01 - variance_output_loss: -4.9700e-01 - output_mean_absolute_error: 0.3169 - output_mean_error: -5.5658e-02 - val_loss: -4.6742e-01 - val_output_loss: -4.6747e-01 - val_variance_output_loss: -4.6747e-01 - val_output_mean_absolute_error: 0.3099 - val_output_mean_error: -9.5522e-03\n",
      "Epoch 56/60\n",
      " - 1s - loss: -5.0825e-01 - output_loss: -5.0829e-01 - variance_output_loss: -5.0829e-01 - output_mean_absolute_error: 0.3092 - output_mean_error: -4.9394e-02 - val_loss: -5.2277e-01 - val_output_loss: -5.2282e-01 - val_variance_output_loss: -5.2282e-01 - val_output_mean_absolute_error: 0.2989 - val_output_mean_error: -3.2881e-02\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 57/60\n",
      " - 1s - loss: -4.9849e-01 - output_loss: -4.9853e-01 - variance_output_loss: -4.9853e-01 - output_mean_absolute_error: 0.3180 - output_mean_error: -5.5852e-02 - val_loss: -4.8574e-01 - val_output_loss: -4.8579e-01 - val_variance_output_loss: -4.8579e-01 - val_output_mean_absolute_error: 0.3074 - val_output_mean_error: -1.7344e-02\n",
      "Epoch 58/60\n",
      " - 1s - loss: -5.0945e-01 - output_loss: -5.0950e-01 - variance_output_loss: -5.0950e-01 - output_mean_absolute_error: 0.3115 - output_mean_error: -4.7934e-02 - val_loss: -4.9841e-01 - val_output_loss: -4.9846e-01 - val_variance_output_loss: -4.9846e-01 - val_output_mean_absolute_error: 0.3116 - val_output_mean_error: -2.9869e-02\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 59/60\n",
      " - 1s - loss: -4.9243e-01 - output_loss: -4.9248e-01 - variance_output_loss: -4.9248e-01 - output_mean_absolute_error: 0.3188 - output_mean_error: -5.5068e-02 - val_loss: -5.2097e-01 - val_output_loss: -5.2102e-01 - val_variance_output_loss: -5.2102e-01 - val_output_mean_absolute_error: 0.3036 - val_output_mean_error: -2.9526e-02\n",
      "Epoch 60/60\n",
      " - 1s - loss: -5.0795e-01 - output_loss: -5.0800e-01 - variance_output_loss: -5.0800e-01 - output_mean_absolute_error: 0.3122 - output_mean_error: -4.8119e-02 - val_loss: -4.8745e-01 - val_output_loss: -4.8750e-01 - val_variance_output_loss: -4.8750e-01 - val_output_mean_absolute_error: 0.3085 - val_output_mean_error: -2.2517e-02\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Completed Training, 44.04s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_3_125/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_3_125'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/32), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Evaluation\n",
      "Completed Evaluation, 5.84s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Evaluation\n",
      "Completed Evaluation, 5.04s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Evaluation\n",
      "Completed Evaluation, 5.51s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Evaluation\n",
      "Completed Evaluation, 5.96s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Evaluation\n",
      "Completed Evaluation, 6.36s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Evaluation\n",
      "Completed Evaluation, 6.83s elapsed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Data</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30067</td>\n",
       "      <td>0.238201</td>\n",
       "      <td>0.005933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15033</td>\n",
       "      <td>0.256239</td>\n",
       "      <td>0.001109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7516</td>\n",
       "      <td>0.260530</td>\n",
       "      <td>0.006653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3758</td>\n",
       "      <td>0.268408</td>\n",
       "      <td>0.011879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1879</td>\n",
       "      <td>0.326041</td>\n",
       "      <td>-0.021223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>939</td>\n",
       "      <td>0.407609</td>\n",
       "      <td>-0.017856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Data  Mean Absolute Error      Bias\n",
       "0           30067             0.238201  0.005933\n",
       "1           15033             0.256239  0.001109\n",
       "2            7516             0.260530  0.006653\n",
       "3            3758             0.268408  0.011879\n",
       "4            1879             0.326041 -0.021223\n",
       "5             939             0.407609 -0.017856"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from astroNN.models import load_folder\n",
    "from astroNN.datasets import H5Loader\n",
    "import pandas as pd\n",
    "\n",
    "loader = H5Loader('_highsnr_test')  # continuum normalized dataset\n",
    "loader.load_err = False\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y = loader.load()\n",
    "\n",
    "mae = []\n",
    "me = []\n",
    "\n",
    "net_100 = load_folder(\"astroNN_0617_run001\")  # this is the main model we used\n",
    "net_100_eval = net_100.evaluate(x, y)\n",
    "mae.append(net_100_eval['output_mean_absolute_error'])\n",
    "me.append(net_100_eval['output_mean_error'])\n",
    "\n",
    "net_50 = load_folder(\"small_data_fixed_50\")\n",
    "net_50_eval = net_50.evaluate(x, y)\n",
    "mae.append(net_50_eval['output_mean_absolute_error'])\n",
    "me.append(net_50_eval['output_mean_error'])\n",
    "\n",
    "net_25 = load_folder(\"small_data_fixed_25\")\n",
    "net_25_eval = net_25.evaluate(x, y)\n",
    "mae.append(net_25_eval['output_mean_absolute_error'])\n",
    "me.append(net_25_eval['output_mean_error'])\n",
    "\n",
    "net_12_5 = load_folder(\"small_data_fixed_12_5\")\n",
    "net_12_5_eval = net_12_5.evaluate(x, y)\n",
    "mae.append(net_12_5_eval['output_mean_absolute_error'])\n",
    "me.append(net_12_5_eval['output_mean_error'])\n",
    "\n",
    "net_6_25 = load_folder(\"small_data_fixed_6_25\")\n",
    "net_6_25_eval = net_6_25.evaluate(x, y)\n",
    "mae.append(net_6_25_eval['output_mean_absolute_error'])\n",
    "me.append(net_6_25_eval['output_mean_error'])\n",
    "\n",
    "net_3_125 = load_folder(\"small_data_fixed_3_125\")\n",
    "net_3_125_eval = net_3_125.evaluate(x, y)\n",
    "mae.append(net_3_125_eval['output_mean_absolute_error'])\n",
    "me.append(net_3_125_eval['output_mean_error'])\n",
    "\n",
    "d = {'Number of Data': [30067, 15033, 7516, 3758, 1879, 939], 'Mean Absolute Error': mae, 'Bias': me}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [160, 48, 32, 16, 2]  # reduced size\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_adaptive_50'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/2), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [128, 48, 24, 12, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_adaptive_25'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/4), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
