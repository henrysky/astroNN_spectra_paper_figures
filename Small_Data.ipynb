{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 15033, Number of Validation Data: 1670\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 15s - loss: 0.1852 - output_loss: 0.1852 - variance_output_loss: 0.1852 - output_mean_absolute_error: 0.5726 - output_mean_error: -4.7036e-02 - val_loss: -1.3395e-01 - val_output_loss: -1.3399e-01 - val_variance_output_loss: -1.3399e-01 - val_output_mean_absolute_error: 0.4540 - val_output_mean_error: -7.8906e-02\n",
      "Epoch 2/60\n",
      " - 9s - loss: -3.5270e-01 - output_loss: -3.5274e-01 - variance_output_loss: -3.5274e-01 - output_mean_absolute_error: 0.3750 - output_mean_error: -5.5414e-02 - val_loss: -4.7807e-01 - val_output_loss: -4.7812e-01 - val_variance_output_loss: -4.7812e-01 - val_output_mean_absolute_error: 0.3417 - val_output_mean_error: -9.0919e-02\n",
      "Epoch 3/60\n",
      " - 9s - loss: -6.1332e-01 - output_loss: -6.1337e-01 - variance_output_loss: -6.1337e-01 - output_mean_absolute_error: 0.2909 - output_mean_error: -3.3768e-02 - val_loss: -6.8704e-01 - val_output_loss: -6.8709e-01 - val_variance_output_loss: -6.8709e-01 - val_output_mean_absolute_error: 0.2717 - val_output_mean_error: -4.5009e-02\n",
      "Epoch 4/60\n",
      " - 9s - loss: -7.7622e-01 - output_loss: -7.7627e-01 - variance_output_loss: -7.7627e-01 - output_mean_absolute_error: 0.2400 - output_mean_error: -2.0939e-02 - val_loss: -8.2092e-01 - val_output_loss: -8.2097e-01 - val_variance_output_loss: -8.2097e-01 - val_output_mean_absolute_error: 0.2305 - val_output_mean_error: -5.0615e-02\n",
      "Epoch 5/60\n",
      " - 9s - loss: -8.7958e-01 - output_loss: -8.7963e-01 - variance_output_loss: -8.7963e-01 - output_mean_absolute_error: 0.2127 - output_mean_error: -1.2551e-02 - val_loss: -9.0689e-01 - val_output_loss: -9.0694e-01 - val_variance_output_loss: -9.0694e-01 - val_output_mean_absolute_error: 0.2096 - val_output_mean_error: -5.2356e-02\n",
      "Epoch 6/60\n",
      " - 9s - loss: -9.5767e-01 - output_loss: -9.5772e-01 - variance_output_loss: -9.5772e-01 - output_mean_absolute_error: 0.1992 - output_mean_error: -1.1098e-02 - val_loss: -9.5950e-01 - val_output_loss: -9.5955e-01 - val_variance_output_loss: -9.5955e-01 - val_output_mean_absolute_error: 0.2020 - val_output_mean_error: -3.6878e-02\n",
      "Epoch 7/60\n",
      " - 10s - loss: -1.0215e+00 - output_loss: -1.0216e+00 - variance_output_loss: -1.0216e+00 - output_mean_absolute_error: 0.1869 - output_mean_error: -9.0247e-03 - val_loss: -9.8939e-01 - val_output_loss: -9.8944e-01 - val_variance_output_loss: -9.8944e-01 - val_output_mean_absolute_error: 0.1982 - val_output_mean_error: -4.6845e-02\n",
      "Epoch 8/60\n",
      " - 9s - loss: -1.0619e+00 - output_loss: -1.0619e+00 - variance_output_loss: -1.0619e+00 - output_mean_absolute_error: 0.1807 - output_mean_error: -8.6494e-03 - val_loss: -1.0414e+00 - val_output_loss: -1.0414e+00 - val_variance_output_loss: -1.0414e+00 - val_output_mean_absolute_error: 0.1855 - val_output_mean_error: -2.4043e-02\n",
      "Epoch 9/60\n",
      " - 9s - loss: -1.0902e+00 - output_loss: -1.0902e+00 - variance_output_loss: -1.0902e+00 - output_mean_absolute_error: 0.1773 - output_mean_error: -8.3523e-03 - val_loss: -1.0650e+00 - val_output_loss: -1.0650e+00 - val_variance_output_loss: -1.0650e+00 - val_output_mean_absolute_error: 0.1832 - val_output_mean_error: -3.6371e-02\n",
      "Epoch 10/60\n",
      " - 9s - loss: -1.1231e+00 - output_loss: -1.1232e+00 - variance_output_loss: -1.1232e+00 - output_mean_absolute_error: 0.1723 - output_mean_error: -7.3849e-03 - val_loss: -1.0961e+00 - val_output_loss: -1.0961e+00 - val_variance_output_loss: -1.0961e+00 - val_output_mean_absolute_error: 0.1798 - val_output_mean_error: -1.5147e-02\n",
      "Epoch 11/60\n",
      " - 9s - loss: -1.1423e+00 - output_loss: -1.1424e+00 - variance_output_loss: -1.1424e+00 - output_mean_absolute_error: 0.1688 - output_mean_error: -6.3570e-03 - val_loss: -1.1370e+00 - val_output_loss: -1.1370e+00 - val_variance_output_loss: -1.1370e+00 - val_output_mean_absolute_error: 0.1712 - val_output_mean_error: -5.8037e-03\n",
      "Epoch 12/60\n",
      " - 9s - loss: -1.1653e+00 - output_loss: -1.1654e+00 - variance_output_loss: -1.1654e+00 - output_mean_absolute_error: 0.1671 - output_mean_error: -6.5955e-03 - val_loss: -1.1320e+00 - val_output_loss: -1.1320e+00 - val_variance_output_loss: -1.1320e+00 - val_output_mean_absolute_error: 0.1734 - val_output_mean_error: -2.1347e-02\n",
      "Epoch 13/60\n",
      " - 9s - loss: -1.1752e+00 - output_loss: -1.1752e+00 - variance_output_loss: -1.1752e+00 - output_mean_absolute_error: 0.1657 - output_mean_error: -6.7131e-03 - val_loss: -1.1176e+00 - val_output_loss: -1.1177e+00 - val_variance_output_loss: -1.1177e+00 - val_output_mean_absolute_error: 0.1736 - val_output_mean_error: 0.0259\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/60\n",
      " - 9s - loss: -1.2038e+00 - output_loss: -1.2039e+00 - variance_output_loss: -1.2039e+00 - output_mean_absolute_error: 0.1612 - output_mean_error: -6.6215e-03 - val_loss: -1.1443e+00 - val_output_loss: -1.1443e+00 - val_variance_output_loss: -1.1443e+00 - val_output_mean_absolute_error: 0.1712 - val_output_mean_error: 0.0058\n",
      "Epoch 15/60\n",
      " - 9s - loss: -1.2167e+00 - output_loss: -1.2168e+00 - variance_output_loss: -1.2168e+00 - output_mean_absolute_error: 0.1603 - output_mean_error: -7.5026e-03 - val_loss: -1.1935e+00 - val_output_loss: -1.1935e+00 - val_variance_output_loss: -1.1935e+00 - val_output_mean_absolute_error: 0.1654 - val_output_mean_error: -3.4457e-04\n",
      "Epoch 16/60\n",
      " - 9s - loss: -1.2196e+00 - output_loss: -1.2197e+00 - variance_output_loss: -1.2197e+00 - output_mean_absolute_error: 0.1601 - output_mean_error: -7.0140e-03 - val_loss: -1.1839e+00 - val_output_loss: -1.1840e+00 - val_variance_output_loss: -1.1840e+00 - val_output_mean_absolute_error: 0.1695 - val_output_mean_error: 0.0056\n",
      "Epoch 17/60\n",
      " - 9s - loss: -1.2292e+00 - output_loss: -1.2292e+00 - variance_output_loss: -1.2292e+00 - output_mean_absolute_error: 0.1587 - output_mean_error: -6.7969e-03 - val_loss: -1.1783e+00 - val_output_loss: -1.1784e+00 - val_variance_output_loss: -1.1784e+00 - val_output_mean_absolute_error: 0.1663 - val_output_mean_error: 0.0017\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/60\n",
      " - 9s - loss: -1.2371e+00 - output_loss: -1.2371e+00 - variance_output_loss: -1.2371e+00 - output_mean_absolute_error: 0.1577 - output_mean_error: -6.3005e-03 - val_loss: -1.2107e+00 - val_output_loss: -1.2107e+00 - val_variance_output_loss: -1.2107e+00 - val_output_mean_absolute_error: 0.1627 - val_output_mean_error: -1.9238e-02\n",
      "Epoch 19/60\n",
      " - 9s - loss: -1.2426e+00 - output_loss: -1.2427e+00 - variance_output_loss: -1.2427e+00 - output_mean_absolute_error: 0.1569 - output_mean_error: -6.9473e-03 - val_loss: -1.1848e+00 - val_output_loss: -1.1849e+00 - val_variance_output_loss: -1.1849e+00 - val_output_mean_absolute_error: 0.1659 - val_output_mean_error: 0.0131\n",
      "Epoch 20/60\n",
      " - 9s - loss: -1.2491e+00 - output_loss: -1.2492e+00 - variance_output_loss: -1.2492e+00 - output_mean_absolute_error: 0.1561 - output_mean_error: -6.2422e-03 - val_loss: -1.2008e+00 - val_output_loss: -1.2009e+00 - val_variance_output_loss: -1.2009e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -4.5020e-03\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 21/60\n",
      " - 9s - loss: -1.2541e+00 - output_loss: -1.2541e+00 - variance_output_loss: -1.2541e+00 - output_mean_absolute_error: 0.1552 - output_mean_error: -7.0140e-03 - val_loss: -1.2038e+00 - val_output_loss: -1.2039e+00 - val_variance_output_loss: -1.2039e+00 - val_output_mean_absolute_error: 0.1650 - val_output_mean_error: -1.5228e-02\n",
      "Epoch 22/60\n",
      " - 9s - loss: -1.2554e+00 - output_loss: -1.2555e+00 - variance_output_loss: -1.2555e+00 - output_mean_absolute_error: 0.1556 - output_mean_error: -7.1320e-03 - val_loss: -1.2088e+00 - val_output_loss: -1.2088e+00 - val_variance_output_loss: -1.2088e+00 - val_output_mean_absolute_error: 0.1628 - val_output_mean_error: -2.1817e-02\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/60\n",
      " - 9s - loss: -1.2575e+00 - output_loss: -1.2575e+00 - variance_output_loss: -1.2575e+00 - output_mean_absolute_error: 0.1550 - output_mean_error: -6.5305e-03 - val_loss: -1.2095e+00 - val_output_loss: -1.2095e+00 - val_variance_output_loss: -1.2095e+00 - val_output_mean_absolute_error: 0.1619 - val_output_mean_error: -1.8145e-02\n",
      "Epoch 24/60\n",
      " - 9s - loss: -1.2622e+00 - output_loss: -1.2623e+00 - variance_output_loss: -1.2623e+00 - output_mean_absolute_error: 0.1542 - output_mean_error: -6.7186e-03 - val_loss: -1.2232e+00 - val_output_loss: -1.2233e+00 - val_variance_output_loss: -1.2233e+00 - val_output_mean_absolute_error: 0.1619 - val_output_mean_error: -1.2225e-03\n",
      "Epoch 25/60\n",
      " - 9s - loss: -1.2600e+00 - output_loss: -1.2601e+00 - variance_output_loss: -1.2601e+00 - output_mean_absolute_error: 0.1551 - output_mean_error: -6.8650e-03 - val_loss: -1.2101e+00 - val_output_loss: -1.2102e+00 - val_variance_output_loss: -1.2102e+00 - val_output_mean_absolute_error: 0.1656 - val_output_mean_error: -8.6061e-03\n",
      "Epoch 26/60\n",
      " - 9s - loss: -1.2611e+00 - output_loss: -1.2612e+00 - variance_output_loss: -1.2612e+00 - output_mean_absolute_error: 0.1548 - output_mean_error: -6.8400e-03 - val_loss: -1.2101e+00 - val_output_loss: -1.2102e+00 - val_variance_output_loss: -1.2102e+00 - val_output_mean_absolute_error: 0.1634 - val_output_mean_error: -2.0341e-02\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 27/60\n",
      " - 9s - loss: -1.2636e+00 - output_loss: -1.2637e+00 - variance_output_loss: -1.2637e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -6.9054e-03 - val_loss: -1.2201e+00 - val_output_loss: -1.2201e+00 - val_variance_output_loss: -1.2201e+00 - val_output_mean_absolute_error: 0.1622 - val_output_mean_error: -5.5943e-03\n",
      "Epoch 28/60\n",
      " - 9s - loss: -1.2673e+00 - output_loss: -1.2673e+00 - variance_output_loss: -1.2673e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -7.4681e-03 - val_loss: -1.2090e+00 - val_output_loss: -1.2091e+00 - val_variance_output_loss: -1.2091e+00 - val_output_mean_absolute_error: 0.1643 - val_output_mean_error: -8.3784e-03\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 29/60\n",
      " - 9s - loss: -1.2669e+00 - output_loss: -1.2670e+00 - variance_output_loss: -1.2670e+00 - output_mean_absolute_error: 0.1543 - output_mean_error: -6.6670e-03 - val_loss: -1.2064e+00 - val_output_loss: -1.2065e+00 - val_variance_output_loss: -1.2065e+00 - val_output_mean_absolute_error: 0.1593 - val_output_mean_error: -6.4049e-03\n",
      "Epoch 30/60\n",
      " - 9s - loss: -1.2659e+00 - output_loss: -1.2659e+00 - variance_output_loss: -1.2659e+00 - output_mean_absolute_error: 0.1542 - output_mean_error: -6.7849e-03 - val_loss: -1.2222e+00 - val_output_loss: -1.2222e+00 - val_variance_output_loss: -1.2222e+00 - val_output_mean_absolute_error: 0.1604 - val_output_mean_error: -9.7327e-03\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 31/60\n",
      " - 9s - loss: -1.2710e+00 - output_loss: -1.2710e+00 - variance_output_loss: -1.2710e+00 - output_mean_absolute_error: 0.1534 - output_mean_error: -6.5499e-03 - val_loss: -1.2165e+00 - val_output_loss: -1.2165e+00 - val_variance_output_loss: -1.2165e+00 - val_output_mean_absolute_error: 0.1633 - val_output_mean_error: -8.4457e-03\n",
      "Epoch 32/60\n",
      " - 9s - loss: -1.2719e+00 - output_loss: -1.2719e+00 - variance_output_loss: -1.2719e+00 - output_mean_absolute_error: 0.1532 - output_mean_error: -7.4190e-03 - val_loss: -1.2041e+00 - val_output_loss: -1.2042e+00 - val_variance_output_loss: -1.2042e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -8.3924e-03\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 33/60\n",
      " - 9s - loss: -1.2620e+00 - output_loss: -1.2621e+00 - variance_output_loss: -1.2621e+00 - output_mean_absolute_error: 0.1547 - output_mean_error: -6.2962e-03 - val_loss: -1.2186e+00 - val_output_loss: -1.2187e+00 - val_variance_output_loss: -1.2187e+00 - val_output_mean_absolute_error: 0.1596 - val_output_mean_error: -3.1411e-03\n",
      "Epoch 34/60\n",
      " - 9s - loss: -1.2724e+00 - output_loss: -1.2725e+00 - variance_output_loss: -1.2725e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -6.3959e-03 - val_loss: -1.2471e+00 - val_output_loss: -1.2472e+00 - val_variance_output_loss: -1.2472e+00 - val_output_mean_absolute_error: 0.1600 - val_output_mean_error: -7.6004e-03\n",
      "Epoch 35/60\n",
      " - 9s - loss: -1.2679e+00 - output_loss: -1.2679e+00 - variance_output_loss: -1.2679e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -7.1840e-03 - val_loss: -1.2291e+00 - val_output_loss: -1.2292e+00 - val_variance_output_loss: -1.2292e+00 - val_output_mean_absolute_error: 0.1637 - val_output_mean_error: -1.2144e-02\n",
      "Epoch 36/60\n",
      " - 9s - loss: -1.2687e+00 - output_loss: -1.2688e+00 - variance_output_loss: -1.2688e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -6.2612e-03 - val_loss: -1.1906e+00 - val_output_loss: -1.1907e+00 - val_variance_output_loss: -1.1907e+00 - val_output_mean_absolute_error: 0.1627 - val_output_mean_error: -7.8267e-03\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 37/60\n",
      " - 9s - loss: -1.2695e+00 - output_loss: -1.2696e+00 - variance_output_loss: -1.2696e+00 - output_mean_absolute_error: 0.1538 - output_mean_error: -6.7028e-03 - val_loss: -1.2173e+00 - val_output_loss: -1.2173e+00 - val_variance_output_loss: -1.2173e+00 - val_output_mean_absolute_error: 0.1615 - val_output_mean_error: -1.1769e-02\n",
      "Epoch 38/60\n",
      " - 9s - loss: -1.2636e+00 - output_loss: -1.2636e+00 - variance_output_loss: -1.2636e+00 - output_mean_absolute_error: 0.1548 - output_mean_error: -7.6880e-03 - val_loss: -1.2226e+00 - val_output_loss: -1.2226e+00 - val_variance_output_loss: -1.2226e+00 - val_output_mean_absolute_error: 0.1617 - val_output_mean_error: -7.7972e-03\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 39/60\n",
      " - 9s - loss: -1.2679e+00 - output_loss: -1.2680e+00 - variance_output_loss: -1.2680e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -5.9196e-03 - val_loss: -1.1879e+00 - val_output_loss: -1.1880e+00 - val_variance_output_loss: -1.1880e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -1.0310e-02\n",
      "Epoch 40/60\n",
      " - 9s - loss: -1.2662e+00 - output_loss: -1.2663e+00 - variance_output_loss: -1.2663e+00 - output_mean_absolute_error: 0.1542 - output_mean_error: -6.6073e-03 - val_loss: -1.2324e+00 - val_output_loss: -1.2324e+00 - val_variance_output_loss: -1.2324e+00 - val_output_mean_absolute_error: 0.1601 - val_output_mean_error: -7.2646e-03\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 41/60\n",
      " - 9s - loss: -1.2697e+00 - output_loss: -1.2698e+00 - variance_output_loss: -1.2698e+00 - output_mean_absolute_error: 0.1535 - output_mean_error: -7.1622e-03 - val_loss: -1.2322e+00 - val_output_loss: -1.2323e+00 - val_variance_output_loss: -1.2323e+00 - val_output_mean_absolute_error: 0.1612 - val_output_mean_error: -1.3201e-02\n",
      "Epoch 42/60\n",
      " - 9s - loss: -1.2653e+00 - output_loss: -1.2653e+00 - variance_output_loss: -1.2653e+00 - output_mean_absolute_error: 0.1544 - output_mean_error: -7.9702e-03 - val_loss: -1.2151e+00 - val_output_loss: -1.2152e+00 - val_variance_output_loss: -1.2152e+00 - val_output_mean_absolute_error: 0.1608 - val_output_mean_error: -1.0185e-02\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 43/60\n",
      " - 9s - loss: -1.2685e+00 - output_loss: -1.2685e+00 - variance_output_loss: -1.2685e+00 - output_mean_absolute_error: 0.1535 - output_mean_error: -6.7677e-03 - val_loss: -1.2171e+00 - val_output_loss: -1.2172e+00 - val_variance_output_loss: -1.2172e+00 - val_output_mean_absolute_error: 0.1620 - val_output_mean_error: -9.0127e-03\n",
      "Epoch 44/60\n",
      " - 9s - loss: -1.2643e+00 - output_loss: -1.2644e+00 - variance_output_loss: -1.2644e+00 - output_mean_absolute_error: 0.1554 - output_mean_error: -7.4679e-03 - val_loss: -1.2177e+00 - val_output_loss: -1.2178e+00 - val_variance_output_loss: -1.2178e+00 - val_output_mean_absolute_error: 0.1612 - val_output_mean_error: -9.1430e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 45/60\n",
      " - 9s - loss: -1.2687e+00 - output_loss: -1.2688e+00 - variance_output_loss: -1.2688e+00 - output_mean_absolute_error: 0.1537 - output_mean_error: -6.9174e-03 - val_loss: -1.2275e+00 - val_output_loss: -1.2276e+00 - val_variance_output_loss: -1.2276e+00 - val_output_mean_absolute_error: 0.1610 - val_output_mean_error: -5.4341e-03\n",
      "Epoch 46/60\n",
      " - 9s - loss: -1.2684e+00 - output_loss: -1.2684e+00 - variance_output_loss: -1.2684e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -7.1442e-03 - val_loss: -1.2125e+00 - val_output_loss: -1.2125e+00 - val_variance_output_loss: -1.2125e+00 - val_output_mean_absolute_error: 0.1640 - val_output_mean_error: -1.5527e-02\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 47/60\n",
      " - 9s - loss: -1.2699e+00 - output_loss: -1.2700e+00 - variance_output_loss: -1.2700e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -6.6905e-03 - val_loss: -1.2080e+00 - val_output_loss: -1.2080e+00 - val_variance_output_loss: -1.2080e+00 - val_output_mean_absolute_error: 0.1628 - val_output_mean_error: -9.3021e-03\n",
      "Epoch 48/60\n",
      " - 9s - loss: -1.2647e+00 - output_loss: -1.2648e+00 - variance_output_loss: -1.2648e+00 - output_mean_absolute_error: 0.1540 - output_mean_error: -6.1355e-03 - val_loss: -1.2378e+00 - val_output_loss: -1.2379e+00 - val_variance_output_loss: -1.2379e+00 - val_output_mean_absolute_error: 0.1597 - val_output_mean_error: -8.4778e-03\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 49/60\n",
      " - 9s - loss: -1.2649e+00 - output_loss: -1.2649e+00 - variance_output_loss: -1.2649e+00 - output_mean_absolute_error: 0.1537 - output_mean_error: -5.9456e-03 - val_loss: -1.2141e+00 - val_output_loss: -1.2142e+00 - val_variance_output_loss: -1.2142e+00 - val_output_mean_absolute_error: 0.1630 - val_output_mean_error: -9.6078e-03\n",
      "Epoch 50/60\n",
      " - 9s - loss: -1.2692e+00 - output_loss: -1.2693e+00 - variance_output_loss: -1.2693e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -7.7391e-03 - val_loss: -1.2213e+00 - val_output_loss: -1.2214e+00 - val_variance_output_loss: -1.2214e+00 - val_output_mean_absolute_error: 0.1623 - val_output_mean_error: -8.3724e-03\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "Epoch 51/60\n",
      " - 9s - loss: -1.2686e+00 - output_loss: -1.2687e+00 - variance_output_loss: -1.2687e+00 - output_mean_absolute_error: 0.1540 - output_mean_error: -7.1530e-03 - val_loss: -1.2152e+00 - val_output_loss: -1.2152e+00 - val_variance_output_loss: -1.2152e+00 - val_output_mean_absolute_error: 0.1624 - val_output_mean_error: -7.3985e-03\n",
      "Epoch 52/60\n",
      " - 9s - loss: -1.2675e+00 - output_loss: -1.2676e+00 - variance_output_loss: -1.2676e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -7.9907e-03 - val_loss: -1.2133e+00 - val_output_loss: -1.2133e+00 - val_variance_output_loss: -1.2133e+00 - val_output_mean_absolute_error: 0.1623 - val_output_mean_error: -8.8896e-03\n",
      "Epoch 53/60\n",
      " - 9s - loss: -1.2680e+00 - output_loss: -1.2680e+00 - variance_output_loss: -1.2680e+00 - output_mean_absolute_error: 0.1538 - output_mean_error: -6.4551e-03 - val_loss: -1.2169e+00 - val_output_loss: -1.2170e+00 - val_variance_output_loss: -1.2170e+00 - val_output_mean_absolute_error: 0.1636 - val_output_mean_error: -8.1578e-03\n",
      "Epoch 54/60\n",
      " - 9s - loss: -1.2637e+00 - output_loss: -1.2638e+00 - variance_output_loss: -1.2638e+00 - output_mean_absolute_error: 0.1544 - output_mean_error: -7.3259e-03 - val_loss: -1.2186e+00 - val_output_loss: -1.2187e+00 - val_variance_output_loss: -1.2187e+00 - val_output_mean_absolute_error: 0.1619 - val_output_mean_error: -6.2379e-03\n",
      "Epoch 55/60\n",
      " - 9s - loss: -1.2678e+00 - output_loss: -1.2679e+00 - variance_output_loss: -1.2679e+00 - output_mean_absolute_error: 0.1540 - output_mean_error: -6.5779e-03 - val_loss: -1.2170e+00 - val_output_loss: -1.2171e+00 - val_variance_output_loss: -1.2171e+00 - val_output_mean_absolute_error: 0.1615 - val_output_mean_error: -6.6991e-03\n",
      "Epoch 56/60\n",
      " - 9s - loss: -1.2676e+00 - output_loss: -1.2677e+00 - variance_output_loss: -1.2677e+00 - output_mean_absolute_error: 0.1541 - output_mean_error: -5.8322e-03 - val_loss: -1.1925e+00 - val_output_loss: -1.1926e+00 - val_variance_output_loss: -1.1926e+00 - val_output_mean_absolute_error: 0.1620 - val_output_mean_error: -9.0764e-03\n",
      "Epoch 57/60\n",
      " - 9s - loss: -1.2674e+00 - output_loss: -1.2674e+00 - variance_output_loss: -1.2674e+00 - output_mean_absolute_error: 0.1545 - output_mean_error: -7.0725e-03 - val_loss: -1.2233e+00 - val_output_loss: -1.2233e+00 - val_variance_output_loss: -1.2233e+00 - val_output_mean_absolute_error: 0.1603 - val_output_mean_error: -5.4786e-03\n",
      "Epoch 58/60\n",
      " - 9s - loss: -1.2701e+00 - output_loss: -1.2702e+00 - variance_output_loss: -1.2702e+00 - output_mean_absolute_error: 0.1536 - output_mean_error: -8.4738e-03 - val_loss: -1.2392e+00 - val_output_loss: -1.2392e+00 - val_variance_output_loss: -1.2392e+00 - val_output_mean_absolute_error: 0.1624 - val_output_mean_error: -7.4900e-03\n",
      "Epoch 59/60\n",
      " - 9s - loss: -1.2673e+00 - output_loss: -1.2674e+00 - variance_output_loss: -1.2674e+00 - output_mean_absolute_error: 0.1539 - output_mean_error: -7.7231e-03 - val_loss: -1.1925e+00 - val_output_loss: -1.1925e+00 - val_variance_output_loss: -1.1925e+00 - val_output_mean_absolute_error: 0.1628 - val_output_mean_error: -5.6812e-03\n",
      "Epoch 60/60\n",
      " - 9s - loss: -1.2679e+00 - output_loss: -1.2680e+00 - variance_output_loss: -1.2680e+00 - output_mean_absolute_error: 0.1543 - output_mean_error: -7.2616e-03 - val_loss: -1.2188e+00 - val_output_loss: -1.2189e+00 - val_variance_output_loss: -1.2189e+00 - val_output_mean_absolute_error: 0.1593 - val_output_mean_error: -6.9268e-03\n",
      "Completed Training, 546.60s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_50/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_50'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/2), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 7516, Number of Validation Data: 835\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 10s - loss: 0.3336 - output_loss: 0.3336 - variance_output_loss: 0.3336 - output_mean_absolute_error: 0.6251 - output_mean_error: -2.1928e-02 - val_loss: 0.1246 - val_output_loss: 0.1246 - val_variance_output_loss: 0.1246 - val_output_mean_absolute_error: 0.4977 - val_output_mean_error: -7.2640e-02\n",
      "Epoch 2/60\n",
      " - 5s - loss: -9.7967e-02 - output_loss: -9.8012e-02 - variance_output_loss: -9.8012e-02 - output_mean_absolute_error: 0.4100 - output_mean_error: -6.2073e-02 - val_loss: -2.3634e-01 - val_output_loss: -2.3638e-01 - val_variance_output_loss: -2.3638e-01 - val_output_mean_absolute_error: 0.3814 - val_output_mean_error: -9.2241e-02\n",
      "Epoch 3/60\n",
      " - 5s - loss: -3.7193e-01 - output_loss: -3.7198e-01 - variance_output_loss: -3.7198e-01 - output_mean_absolute_error: 0.3416 - output_mean_error: -4.9012e-02 - val_loss: -4.5664e-01 - val_output_loss: -4.5668e-01 - val_variance_output_loss: -4.5668e-01 - val_output_mean_absolute_error: 0.3231 - val_output_mean_error: -2.8954e-02\n",
      "Epoch 4/60\n",
      " - 5s - loss: -5.2673e-01 - output_loss: -5.2677e-01 - variance_output_loss: -5.2677e-01 - output_mean_absolute_error: 0.2991 - output_mean_error: -3.6364e-02 - val_loss: -5.8556e-01 - val_output_loss: -5.8561e-01 - val_variance_output_loss: -5.8561e-01 - val_output_mean_absolute_error: 0.2835 - val_output_mean_error: -1.4081e-02\n",
      "Epoch 5/60\n",
      " - 5s - loss: -6.4571e-01 - output_loss: -6.4575e-01 - variance_output_loss: -6.4575e-01 - output_mean_absolute_error: 0.2642 - output_mean_error: -2.1464e-02 - val_loss: -6.6848e-01 - val_output_loss: -6.6853e-01 - val_variance_output_loss: -6.6853e-01 - val_output_mean_absolute_error: 0.2603 - val_output_mean_error: 0.0060\n",
      "Epoch 6/60\n",
      " - 4s - loss: -7.2576e-01 - output_loss: -7.2581e-01 - variance_output_loss: -7.2581e-01 - output_mean_absolute_error: 0.2434 - output_mean_error: -1.6988e-02 - val_loss: -7.6558e-01 - val_output_loss: -7.6563e-01 - val_variance_output_loss: -7.6563e-01 - val_output_mean_absolute_error: 0.2352 - val_output_mean_error: 0.0317\n",
      "Epoch 7/60\n",
      " - 4s - loss: -7.8460e-01 - output_loss: -7.8465e-01 - variance_output_loss: -7.8465e-01 - output_mean_absolute_error: 0.2273 - output_mean_error: -1.2541e-02 - val_loss: -7.5825e-01 - val_output_loss: -7.5829e-01 - val_variance_output_loss: -7.5829e-01 - val_output_mean_absolute_error: 0.2333 - val_output_mean_error: 0.0576\n",
      "Epoch 8/60\n",
      " - 4s - loss: -8.3533e-01 - output_loss: -8.3538e-01 - variance_output_loss: -8.3538e-01 - output_mean_absolute_error: 0.2161 - output_mean_error: -9.3723e-03 - val_loss: -8.0536e-01 - val_output_loss: -8.0541e-01 - val_variance_output_loss: -8.0541e-01 - val_output_mean_absolute_error: 0.2221 - val_output_mean_error: -3.4307e-02\n",
      "Epoch 9/60\n",
      " - 4s - loss: -8.8558e-01 - output_loss: -8.8563e-01 - variance_output_loss: -8.8563e-01 - output_mean_absolute_error: 0.2060 - output_mean_error: -7.7806e-03 - val_loss: -8.7030e-01 - val_output_loss: -8.7035e-01 - val_variance_output_loss: -8.7035e-01 - val_output_mean_absolute_error: 0.2134 - val_output_mean_error: 0.0179\n",
      "Epoch 10/60\n",
      " - 5s - loss: -9.1562e-01 - output_loss: -9.1567e-01 - variance_output_loss: -9.1567e-01 - output_mean_absolute_error: 0.1999 - output_mean_error: -7.4214e-03 - val_loss: -9.1523e-01 - val_output_loss: -9.1528e-01 - val_variance_output_loss: -9.1528e-01 - val_output_mean_absolute_error: 0.2003 - val_output_mean_error: -3.0754e-02\n",
      "Epoch 11/60\n",
      " - 5s - loss: -9.4724e-01 - output_loss: -9.4729e-01 - variance_output_loss: -9.4729e-01 - output_mean_absolute_error: 0.1940 - output_mean_error: -6.9983e-03 - val_loss: -8.9769e-01 - val_output_loss: -8.9774e-01 - val_variance_output_loss: -8.9774e-01 - val_output_mean_absolute_error: 0.2028 - val_output_mean_error: 0.0305\n",
      "Epoch 12/60\n",
      " - 5s - loss: -9.6582e-01 - output_loss: -9.6587e-01 - variance_output_loss: -9.6587e-01 - output_mean_absolute_error: 0.1902 - output_mean_error: -5.0393e-03 - val_loss: -9.5805e-01 - val_output_loss: -9.5810e-01 - val_variance_output_loss: -9.5810e-01 - val_output_mean_absolute_error: 0.1915 - val_output_mean_error: -2.9315e-02\n",
      "Epoch 13/60\n",
      " - 5s - loss: -9.9835e-01 - output_loss: -9.9840e-01 - variance_output_loss: -9.9840e-01 - output_mean_absolute_error: 0.1863 - output_mean_error: -3.7388e-03 - val_loss: -9.2779e-01 - val_output_loss: -9.2784e-01 - val_variance_output_loss: -9.2784e-01 - val_output_mean_absolute_error: 0.2021 - val_output_mean_error: 0.0161\n",
      "Epoch 14/60\n",
      " - 5s - loss: -1.0179e+00 - output_loss: -1.0180e+00 - variance_output_loss: -1.0180e+00 - output_mean_absolute_error: 0.1839 - output_mean_error: -5.0946e-03 - val_loss: -1.0303e+00 - val_output_loss: -1.0303e+00 - val_variance_output_loss: -1.0303e+00 - val_output_mean_absolute_error: 0.1827 - val_output_mean_error: -9.3289e-03\n",
      "Epoch 15/60\n",
      " - 5s - loss: -1.0325e+00 - output_loss: -1.0326e+00 - variance_output_loss: -1.0326e+00 - output_mean_absolute_error: 0.1816 - output_mean_error: -5.5605e-03 - val_loss: -1.0344e+00 - val_output_loss: -1.0344e+00 - val_variance_output_loss: -1.0344e+00 - val_output_mean_absolute_error: 0.1834 - val_output_mean_error: -5.6702e-03\n",
      "Epoch 16/60\n",
      " - 4s - loss: -1.0481e+00 - output_loss: -1.0481e+00 - variance_output_loss: -1.0481e+00 - output_mean_absolute_error: 0.1799 - output_mean_error: -6.5995e-03 - val_loss: -1.0320e+00 - val_output_loss: -1.0321e+00 - val_variance_output_loss: -1.0321e+00 - val_output_mean_absolute_error: 0.1846 - val_output_mean_error: -7.3345e-03\n",
      "Epoch 17/60\n",
      " - 4s - loss: -1.0666e+00 - output_loss: -1.0667e+00 - variance_output_loss: -1.0667e+00 - output_mean_absolute_error: 0.1775 - output_mean_error: -5.3084e-03 - val_loss: -1.0563e+00 - val_output_loss: -1.0563e+00 - val_variance_output_loss: -1.0563e+00 - val_output_mean_absolute_error: 0.1816 - val_output_mean_error: 0.0087\n",
      "Epoch 18/60\n",
      " - 4s - loss: -1.0860e+00 - output_loss: -1.0861e+00 - variance_output_loss: -1.0861e+00 - output_mean_absolute_error: 0.1742 - output_mean_error: -5.0769e-03 - val_loss: -1.0321e+00 - val_output_loss: -1.0322e+00 - val_variance_output_loss: -1.0322e+00 - val_output_mean_absolute_error: 0.1825 - val_output_mean_error: -3.5106e-02\n",
      "Epoch 19/60\n",
      " - 5s - loss: -1.1040e+00 - output_loss: -1.1041e+00 - variance_output_loss: -1.1041e+00 - output_mean_absolute_error: 0.1725 - output_mean_error: -6.1717e-03 - val_loss: -1.0549e+00 - val_output_loss: -1.0550e+00 - val_variance_output_loss: -1.0550e+00 - val_output_mean_absolute_error: 0.1786 - val_output_mean_error: -1.9965e-03\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 20/60\n",
      " - 4s - loss: -1.1265e+00 - output_loss: -1.1266e+00 - variance_output_loss: -1.1266e+00 - output_mean_absolute_error: 0.1701 - output_mean_error: -5.8935e-03 - val_loss: -1.0965e+00 - val_output_loss: -1.0965e+00 - val_variance_output_loss: -1.0965e+00 - val_output_mean_absolute_error: 0.1758 - val_output_mean_error: -2.6856e-02\n",
      "Epoch 21/60\n",
      " - 5s - loss: -1.1429e+00 - output_loss: -1.1429e+00 - variance_output_loss: -1.1429e+00 - output_mean_absolute_error: 0.1682 - output_mean_error: -5.8552e-03 - val_loss: -1.0863e+00 - val_output_loss: -1.0863e+00 - val_variance_output_loss: -1.0863e+00 - val_output_mean_absolute_error: 0.1751 - val_output_mean_error: 0.0170\n",
      "Epoch 22/60\n",
      " - 5s - loss: -1.1349e+00 - output_loss: -1.1349e+00 - variance_output_loss: -1.1349e+00 - output_mean_absolute_error: 0.1680 - output_mean_error: -4.7267e-03 - val_loss: -1.1013e+00 - val_output_loss: -1.1014e+00 - val_variance_output_loss: -1.1014e+00 - val_output_mean_absolute_error: 0.1737 - val_output_mean_error: -1.1743e-02\n",
      "Epoch 23/60\n",
      " - 4s - loss: -1.1463e+00 - output_loss: -1.1464e+00 - variance_output_loss: -1.1464e+00 - output_mean_absolute_error: 0.1686 - output_mean_error: -6.4485e-03 - val_loss: -1.1047e+00 - val_output_loss: -1.1047e+00 - val_variance_output_loss: -1.1047e+00 - val_output_mean_absolute_error: 0.1747 - val_output_mean_error: 2.6419e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      " - 4s - loss: -1.1534e+00 - output_loss: -1.1534e+00 - variance_output_loss: -1.1534e+00 - output_mean_absolute_error: 0.1657 - output_mean_error: -5.7820e-03 - val_loss: -1.1079e+00 - val_output_loss: -1.1080e+00 - val_variance_output_loss: -1.1080e+00 - val_output_mean_absolute_error: 0.1729 - val_output_mean_error: 0.0056\n",
      "Epoch 25/60\n",
      " - 4s - loss: -1.1642e+00 - output_loss: -1.1643e+00 - variance_output_loss: -1.1643e+00 - output_mean_absolute_error: 0.1649 - output_mean_error: -5.8232e-03 - val_loss: -1.1229e+00 - val_output_loss: -1.1230e+00 - val_variance_output_loss: -1.1230e+00 - val_output_mean_absolute_error: 0.1713 - val_output_mean_error: -2.1227e-02\n",
      "Epoch 26/60\n",
      " - 5s - loss: -1.1669e+00 - output_loss: -1.1669e+00 - variance_output_loss: -1.1669e+00 - output_mean_absolute_error: 0.1645 - output_mean_error: -5.3876e-03 - val_loss: -1.1397e+00 - val_output_loss: -1.1397e+00 - val_variance_output_loss: -1.1397e+00 - val_output_mean_absolute_error: 0.1702 - val_output_mean_error: -1.9760e-02\n",
      "Epoch 27/60\n",
      " - 5s - loss: -1.1800e+00 - output_loss: -1.1801e+00 - variance_output_loss: -1.1801e+00 - output_mean_absolute_error: 0.1630 - output_mean_error: -6.1604e-03 - val_loss: -1.1371e+00 - val_output_loss: -1.1371e+00 - val_variance_output_loss: -1.1371e+00 - val_output_mean_absolute_error: 0.1712 - val_output_mean_error: -2.8694e-02\n",
      "Epoch 28/60\n",
      " - 4s - loss: -1.1608e+00 - output_loss: -1.1609e+00 - variance_output_loss: -1.1609e+00 - output_mean_absolute_error: 0.1661 - output_mean_error: -6.4487e-03 - val_loss: -1.1269e+00 - val_output_loss: -1.1270e+00 - val_variance_output_loss: -1.1270e+00 - val_output_mean_absolute_error: 0.1721 - val_output_mean_error: -1.7990e-03\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 29/60\n",
      " - 4s - loss: -1.1823e+00 - output_loss: -1.1824e+00 - variance_output_loss: -1.1824e+00 - output_mean_absolute_error: 0.1628 - output_mean_error: -4.2886e-03 - val_loss: -1.1600e+00 - val_output_loss: -1.1600e+00 - val_variance_output_loss: -1.1600e+00 - val_output_mean_absolute_error: 0.1653 - val_output_mean_error: 0.0157\n",
      "Epoch 30/60\n",
      " - 5s - loss: -1.1933e+00 - output_loss: -1.1934e+00 - variance_output_loss: -1.1934e+00 - output_mean_absolute_error: 0.1616 - output_mean_error: -6.5533e-03 - val_loss: -1.1648e+00 - val_output_loss: -1.1648e+00 - val_variance_output_loss: -1.1648e+00 - val_output_mean_absolute_error: 0.1634 - val_output_mean_error: -2.3764e-03\n",
      "Epoch 31/60\n",
      " - 5s - loss: -1.1934e+00 - output_loss: -1.1934e+00 - variance_output_loss: -1.1934e+00 - output_mean_absolute_error: 0.1613 - output_mean_error: -6.3115e-03 - val_loss: -1.1677e+00 - val_output_loss: -1.1678e+00 - val_variance_output_loss: -1.1678e+00 - val_output_mean_absolute_error: 0.1660 - val_output_mean_error: -1.0782e-02\n",
      "Epoch 32/60\n",
      " - 4s - loss: -1.1946e+00 - output_loss: -1.1947e+00 - variance_output_loss: -1.1947e+00 - output_mean_absolute_error: 0.1615 - output_mean_error: -5.3200e-03 - val_loss: -1.1328e+00 - val_output_loss: -1.1329e+00 - val_variance_output_loss: -1.1329e+00 - val_output_mean_absolute_error: 0.1689 - val_output_mean_error: -2.2390e-02\n",
      "Epoch 33/60\n",
      " - 5s - loss: -1.1965e+00 - output_loss: -1.1966e+00 - variance_output_loss: -1.1966e+00 - output_mean_absolute_error: 0.1614 - output_mean_error: -6.1644e-03 - val_loss: -1.1736e+00 - val_output_loss: -1.1736e+00 - val_variance_output_loss: -1.1736e+00 - val_output_mean_absolute_error: 0.1657 - val_output_mean_error: 0.0127\n",
      "Epoch 34/60\n",
      " - 5s - loss: -1.2085e+00 - output_loss: -1.2086e+00 - variance_output_loss: -1.2086e+00 - output_mean_absolute_error: 0.1601 - output_mean_error: -6.0654e-03 - val_loss: -1.1650e+00 - val_output_loss: -1.1650e+00 - val_variance_output_loss: -1.1650e+00 - val_output_mean_absolute_error: 0.1668 - val_output_mean_error: 0.0071\n",
      "Epoch 35/60\n",
      " - 5s - loss: -1.2081e+00 - output_loss: -1.2081e+00 - variance_output_loss: -1.2081e+00 - output_mean_absolute_error: 0.1604 - output_mean_error: -6.5283e-03 - val_loss: -1.1139e+00 - val_output_loss: -1.1139e+00 - val_variance_output_loss: -1.1139e+00 - val_output_mean_absolute_error: 0.1740 - val_output_mean_error: 0.0034\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 36/60\n",
      " - 5s - loss: -1.2120e+00 - output_loss: -1.2121e+00 - variance_output_loss: -1.2121e+00 - output_mean_absolute_error: 0.1596 - output_mean_error: -4.6962e-03 - val_loss: -1.1626e+00 - val_output_loss: -1.1627e+00 - val_variance_output_loss: -1.1627e+00 - val_output_mean_absolute_error: 0.1675 - val_output_mean_error: -3.7290e-03\n",
      "Epoch 37/60\n",
      " - 5s - loss: -1.2123e+00 - output_loss: -1.2123e+00 - variance_output_loss: -1.2123e+00 - output_mean_absolute_error: 0.1602 - output_mean_error: -5.2038e-03 - val_loss: -1.1303e+00 - val_output_loss: -1.1303e+00 - val_variance_output_loss: -1.1303e+00 - val_output_mean_absolute_error: 0.1737 - val_output_mean_error: -1.6635e-02\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 38/60\n",
      " - 4s - loss: -1.2108e+00 - output_loss: -1.2108e+00 - variance_output_loss: -1.2108e+00 - output_mean_absolute_error: 0.1596 - output_mean_error: -6.0381e-03 - val_loss: -1.1531e+00 - val_output_loss: -1.1532e+00 - val_variance_output_loss: -1.1532e+00 - val_output_mean_absolute_error: 0.1700 - val_output_mean_error: -1.4939e-02\n",
      "Epoch 39/60\n",
      " - 4s - loss: -1.2292e+00 - output_loss: -1.2293e+00 - variance_output_loss: -1.2293e+00 - output_mean_absolute_error: 0.1570 - output_mean_error: -7.2654e-03 - val_loss: -1.1507e+00 - val_output_loss: -1.1507e+00 - val_variance_output_loss: -1.1507e+00 - val_output_mean_absolute_error: 0.1664 - val_output_mean_error: -3.2568e-03\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 40/60\n",
      " - 4s - loss: -1.2175e+00 - output_loss: -1.2176e+00 - variance_output_loss: -1.2176e+00 - output_mean_absolute_error: 0.1598 - output_mean_error: -6.2211e-03 - val_loss: -1.1650e+00 - val_output_loss: -1.1650e+00 - val_variance_output_loss: -1.1650e+00 - val_output_mean_absolute_error: 0.1677 - val_output_mean_error: -6.0767e-03\n",
      "Epoch 41/60\n",
      " - 4s - loss: -1.2277e+00 - output_loss: -1.2278e+00 - variance_output_loss: -1.2278e+00 - output_mean_absolute_error: 0.1559 - output_mean_error: -4.6766e-03 - val_loss: -1.1356e+00 - val_output_loss: -1.1357e+00 - val_variance_output_loss: -1.1357e+00 - val_output_mean_absolute_error: 0.1671 - val_output_mean_error: -9.7732e-04\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 42/60\n",
      " - 4s - loss: -1.2126e+00 - output_loss: -1.2127e+00 - variance_output_loss: -1.2127e+00 - output_mean_absolute_error: 0.1600 - output_mean_error: -7.0283e-03 - val_loss: -1.1645e+00 - val_output_loss: -1.1645e+00 - val_variance_output_loss: -1.1645e+00 - val_output_mean_absolute_error: 0.1691 - val_output_mean_error: -5.0310e-03\n",
      "Epoch 43/60\n",
      " - 5s - loss: -1.2231e+00 - output_loss: -1.2232e+00 - variance_output_loss: -1.2232e+00 - output_mean_absolute_error: 0.1576 - output_mean_error: -5.1369e-03 - val_loss: -1.1697e+00 - val_output_loss: -1.1698e+00 - val_variance_output_loss: -1.1698e+00 - val_output_mean_absolute_error: 0.1662 - val_output_mean_error: -8.4658e-03\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 44/60\n",
      " - 4s - loss: -1.2250e+00 - output_loss: -1.2250e+00 - variance_output_loss: -1.2250e+00 - output_mean_absolute_error: 0.1577 - output_mean_error: -5.8167e-03 - val_loss: -1.1729e+00 - val_output_loss: -1.1729e+00 - val_variance_output_loss: -1.1729e+00 - val_output_mean_absolute_error: 0.1645 - val_output_mean_error: -6.2165e-03\n",
      "Epoch 45/60\n",
      " - 4s - loss: -1.2224e+00 - output_loss: -1.2225e+00 - variance_output_loss: -1.2225e+00 - output_mean_absolute_error: 0.1578 - output_mean_error: -6.5054e-03 - val_loss: -1.1425e+00 - val_output_loss: -1.1425e+00 - val_variance_output_loss: -1.1425e+00 - val_output_mean_absolute_error: 0.1699 - val_output_mean_error: -1.4964e-02\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 46/60\n",
      " - 4s - loss: -1.2176e+00 - output_loss: -1.2177e+00 - variance_output_loss: -1.2177e+00 - output_mean_absolute_error: 0.1580 - output_mean_error: -5.2517e-03 - val_loss: -1.1955e+00 - val_output_loss: -1.1955e+00 - val_variance_output_loss: -1.1955e+00 - val_output_mean_absolute_error: 0.1638 - val_output_mean_error: -9.5697e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      " - 4s - loss: -1.2233e+00 - output_loss: -1.2234e+00 - variance_output_loss: -1.2234e+00 - output_mean_absolute_error: 0.1577 - output_mean_error: -5.8325e-03 - val_loss: -1.1536e+00 - val_output_loss: -1.1536e+00 - val_variance_output_loss: -1.1536e+00 - val_output_mean_absolute_error: 0.1658 - val_output_mean_error: -5.9521e-03\n",
      "Epoch 48/60\n",
      " - 4s - loss: -1.2177e+00 - output_loss: -1.2177e+00 - variance_output_loss: -1.2177e+00 - output_mean_absolute_error: 0.1595 - output_mean_error: -7.0635e-03 - val_loss: -1.1671e+00 - val_output_loss: -1.1671e+00 - val_variance_output_loss: -1.1671e+00 - val_output_mean_absolute_error: 0.1665 - val_output_mean_error: -8.5970e-03\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 49/60\n",
      " - 4s - loss: -1.2250e+00 - output_loss: -1.2250e+00 - variance_output_loss: -1.2250e+00 - output_mean_absolute_error: 0.1573 - output_mean_error: -5.0689e-03 - val_loss: -1.1638e+00 - val_output_loss: -1.1639e+00 - val_variance_output_loss: -1.1639e+00 - val_output_mean_absolute_error: 0.1667 - val_output_mean_error: -6.1507e-03\n",
      "Epoch 50/60\n",
      " - 4s - loss: -1.2248e+00 - output_loss: -1.2248e+00 - variance_output_loss: -1.2248e+00 - output_mean_absolute_error: 0.1578 - output_mean_error: -6.9660e-03 - val_loss: -1.1856e+00 - val_output_loss: -1.1856e+00 - val_variance_output_loss: -1.1856e+00 - val_output_mean_absolute_error: 0.1615 - val_output_mean_error: -1.5237e-03\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 51/60\n",
      " - 5s - loss: -1.2251e+00 - output_loss: -1.2252e+00 - variance_output_loss: -1.2252e+00 - output_mean_absolute_error: 0.1575 - output_mean_error: -6.2238e-03 - val_loss: -1.1791e+00 - val_output_loss: -1.1792e+00 - val_variance_output_loss: -1.1792e+00 - val_output_mean_absolute_error: 0.1675 - val_output_mean_error: -7.2171e-03\n",
      "Epoch 52/60\n",
      " - 5s - loss: -1.2259e+00 - output_loss: -1.2260e+00 - variance_output_loss: -1.2260e+00 - output_mean_absolute_error: 0.1583 - output_mean_error: -6.5885e-03 - val_loss: -1.1882e+00 - val_output_loss: -1.1882e+00 - val_variance_output_loss: -1.1882e+00 - val_output_mean_absolute_error: 0.1633 - val_output_mean_error: -7.8710e-03\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 53/60\n",
      " - 4s - loss: -1.2221e+00 - output_loss: -1.2222e+00 - variance_output_loss: -1.2222e+00 - output_mean_absolute_error: 0.1578 - output_mean_error: -5.5872e-03 - val_loss: -1.1820e+00 - val_output_loss: -1.1820e+00 - val_variance_output_loss: -1.1820e+00 - val_output_mean_absolute_error: 0.1668 - val_output_mean_error: -1.0032e-02\n",
      "Epoch 54/60\n",
      " - 4s - loss: -1.2192e+00 - output_loss: -1.2192e+00 - variance_output_loss: -1.2192e+00 - output_mean_absolute_error: 0.1581 - output_mean_error: -3.0214e-03 - val_loss: -1.1788e+00 - val_output_loss: -1.1789e+00 - val_variance_output_loss: -1.1789e+00 - val_output_mean_absolute_error: 0.1639 - val_output_mean_error: -6.2348e-03\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 55/60\n",
      " - 4s - loss: -1.2185e+00 - output_loss: -1.2186e+00 - variance_output_loss: -1.2186e+00 - output_mean_absolute_error: 0.1592 - output_mean_error: -4.8130e-03 - val_loss: -1.1816e+00 - val_output_loss: -1.1816e+00 - val_variance_output_loss: -1.1816e+00 - val_output_mean_absolute_error: 0.1651 - val_output_mean_error: -8.3036e-03\n",
      "Epoch 56/60\n",
      " - 5s - loss: -1.2289e+00 - output_loss: -1.2289e+00 - variance_output_loss: -1.2289e+00 - output_mean_absolute_error: 0.1580 - output_mean_error: -5.4008e-03 - val_loss: -1.1639e+00 - val_output_loss: -1.1639e+00 - val_variance_output_loss: -1.1639e+00 - val_output_mean_absolute_error: 0.1664 - val_output_mean_error: -5.0749e-03\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 57/60\n",
      " - 4s - loss: -1.2253e+00 - output_loss: -1.2253e+00 - variance_output_loss: -1.2253e+00 - output_mean_absolute_error: 0.1575 - output_mean_error: -6.6607e-03 - val_loss: -1.1796e+00 - val_output_loss: -1.1797e+00 - val_variance_output_loss: -1.1797e+00 - val_output_mean_absolute_error: 0.1639 - val_output_mean_error: -9.4413e-03\n",
      "Epoch 58/60\n",
      " - 4s - loss: -1.2210e+00 - output_loss: -1.2211e+00 - variance_output_loss: -1.2211e+00 - output_mean_absolute_error: 0.1583 - output_mean_error: -6.5592e-03 - val_loss: -1.1708e+00 - val_output_loss: -1.1709e+00 - val_variance_output_loss: -1.1709e+00 - val_output_mean_absolute_error: 0.1641 - val_output_mean_error: -1.8710e-03\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 59/60\n",
      " - 4s - loss: -1.2148e+00 - output_loss: -1.2149e+00 - variance_output_loss: -1.2149e+00 - output_mean_absolute_error: 0.1595 - output_mean_error: -7.1776e-03 - val_loss: -1.1794e+00 - val_output_loss: -1.1795e+00 - val_variance_output_loss: -1.1795e+00 - val_output_mean_absolute_error: 0.1625 - val_output_mean_error: -9.0460e-03\n",
      "Epoch 60/60\n",
      " - 4s - loss: -1.2196e+00 - output_loss: -1.2196e+00 - variance_output_loss: -1.2196e+00 - output_mean_absolute_error: 0.1586 - output_mean_error: -5.3842e-03 - val_loss: -1.1772e+00 - val_output_loss: -1.1773e+00 - val_variance_output_loss: -1.1773e+00 - val_output_mean_absolute_error: 0.1670 - val_output_mean_error: -7.4797e-03\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Completed Training, 279.65s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_25/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_25'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/4), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 3758, Number of Validation Data: 417\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 8s - loss: 0.3842 - output_loss: 0.3842 - variance_output_loss: 0.3842 - output_mean_absolute_error: 0.6283 - output_mean_error: -2.4548e-02 - val_loss: 0.3116 - val_output_loss: 0.3115 - val_variance_output_loss: 0.3115 - val_output_mean_absolute_error: 0.5525 - val_output_mean_error: -6.4697e-02\n",
      "Epoch 2/60\n",
      " - 2s - loss: 0.1690 - output_loss: 0.1689 - variance_output_loss: 0.1689 - output_mean_absolute_error: 0.5009 - output_mean_error: -4.5530e-02 - val_loss: 0.0521 - val_output_loss: 0.0520 - val_variance_output_loss: 0.0520 - val_output_mean_absolute_error: 0.4406 - val_output_mean_error: -7.7326e-03\n",
      "Epoch 3/60\n",
      " - 2s - loss: -4.9196e-02 - output_loss: -4.9241e-02 - variance_output_loss: -4.9241e-02 - output_mean_absolute_error: 0.4141 - output_mean_error: -3.4218e-02 - val_loss: -1.5913e-01 - val_output_loss: -1.5918e-01 - val_variance_output_loss: -1.5918e-01 - val_output_mean_absolute_error: 0.3780 - val_output_mean_error: -3.7097e-02\n",
      "Epoch 4/60\n",
      " - 2s - loss: -2.2725e-01 - output_loss: -2.2729e-01 - variance_output_loss: -2.2729e-01 - output_mean_absolute_error: 0.3743 - output_mean_error: -2.7714e-02 - val_loss: -2.8475e-01 - val_output_loss: -2.8480e-01 - val_variance_output_loss: -2.8480e-01 - val_output_mean_absolute_error: 0.3548 - val_output_mean_error: -3.7382e-02\n",
      "Epoch 5/60\n",
      " - 2s - loss: -3.6693e-01 - output_loss: -3.6698e-01 - variance_output_loss: -3.6698e-01 - output_mean_absolute_error: 0.3375 - output_mean_error: -2.0541e-02 - val_loss: -3.8855e-01 - val_output_loss: -3.8859e-01 - val_variance_output_loss: -3.8859e-01 - val_output_mean_absolute_error: 0.3323 - val_output_mean_error: -5.6551e-02\n",
      "Epoch 6/60\n",
      " - 2s - loss: -4.6549e-01 - output_loss: -4.6554e-01 - variance_output_loss: -4.6554e-01 - output_mean_absolute_error: 0.3118 - output_mean_error: -1.8691e-02 - val_loss: -5.0727e-01 - val_output_loss: -5.0732e-01 - val_variance_output_loss: -5.0732e-01 - val_output_mean_absolute_error: 0.2967 - val_output_mean_error: -8.0704e-03\n",
      "Epoch 7/60\n",
      " - 2s - loss: -5.2841e-01 - output_loss: -5.2846e-01 - variance_output_loss: -5.2846e-01 - output_mean_absolute_error: 0.2935 - output_mean_error: -1.7775e-02 - val_loss: -5.2047e-01 - val_output_loss: -5.2052e-01 - val_variance_output_loss: -5.2052e-01 - val_output_mean_absolute_error: 0.3035 - val_output_mean_error: -5.3648e-02\n",
      "Epoch 8/60\n",
      " - 2s - loss: -5.9966e-01 - output_loss: -5.9971e-01 - variance_output_loss: -5.9971e-01 - output_mean_absolute_error: 0.2730 - output_mean_error: -1.2692e-02 - val_loss: -5.8831e-01 - val_output_loss: -5.8836e-01 - val_variance_output_loss: -5.8836e-01 - val_output_mean_absolute_error: 0.2798 - val_output_mean_error: -5.9223e-02\n",
      "Epoch 9/60\n",
      " - 2s - loss: -6.4985e-01 - output_loss: -6.4990e-01 - variance_output_loss: -6.4990e-01 - output_mean_absolute_error: 0.2618 - output_mean_error: -1.5420e-02 - val_loss: -6.7147e-01 - val_output_loss: -6.7152e-01 - val_variance_output_loss: -6.7152e-01 - val_output_mean_absolute_error: 0.2563 - val_output_mean_error: -3.5672e-02\n",
      "Epoch 10/60\n",
      " - 2s - loss: -6.9783e-01 - output_loss: -6.9788e-01 - variance_output_loss: -6.9788e-01 - output_mean_absolute_error: 0.2490 - output_mean_error: -9.9447e-03 - val_loss: -6.8279e-01 - val_output_loss: -6.8284e-01 - val_variance_output_loss: -6.8284e-01 - val_output_mean_absolute_error: 0.2502 - val_output_mean_error: -4.2199e-02\n",
      "Epoch 11/60\n",
      " - 2s - loss: -7.2516e-01 - output_loss: -7.2521e-01 - variance_output_loss: -7.2521e-01 - output_mean_absolute_error: 0.2430 - output_mean_error: -1.4133e-02 - val_loss: -7.4018e-01 - val_output_loss: -7.4023e-01 - val_variance_output_loss: -7.4023e-01 - val_output_mean_absolute_error: 0.2380 - val_output_mean_error: -4.5638e-02\n",
      "Epoch 12/60\n",
      " - 2s - loss: -7.7436e-01 - output_loss: -7.7441e-01 - variance_output_loss: -7.7441e-01 - output_mean_absolute_error: 0.2322 - output_mean_error: -1.2843e-02 - val_loss: -7.4875e-01 - val_output_loss: -7.4880e-01 - val_variance_output_loss: -7.4880e-01 - val_output_mean_absolute_error: 0.2295 - val_output_mean_error: 0.0062\n",
      "Epoch 13/60\n",
      " - 2s - loss: -7.9746e-01 - output_loss: -7.9751e-01 - variance_output_loss: -7.9751e-01 - output_mean_absolute_error: 0.2274 - output_mean_error: -1.3328e-02 - val_loss: -7.1858e-01 - val_output_loss: -7.1863e-01 - val_variance_output_loss: -7.1863e-01 - val_output_mean_absolute_error: 0.2428 - val_output_mean_error: -6.2389e-02\n",
      "Epoch 14/60\n",
      " - 2s - loss: -8.1677e-01 - output_loss: -8.1682e-01 - variance_output_loss: -8.1682e-01 - output_mean_absolute_error: 0.2233 - output_mean_error: -1.0832e-02 - val_loss: -7.5459e-01 - val_output_loss: -7.5464e-01 - val_variance_output_loss: -7.5464e-01 - val_output_mean_absolute_error: 0.2384 - val_output_mean_error: -7.6253e-02\n",
      "Epoch 15/60\n",
      " - 2s - loss: -8.4725e-01 - output_loss: -8.4730e-01 - variance_output_loss: -8.4730e-01 - output_mean_absolute_error: 0.2169 - output_mean_error: -1.2935e-02 - val_loss: -8.1183e-01 - val_output_loss: -8.1188e-01 - val_variance_output_loss: -8.1188e-01 - val_output_mean_absolute_error: 0.2167 - val_output_mean_error: 0.0237\n",
      "Epoch 16/60\n",
      " - 2s - loss: -8.9089e-01 - output_loss: -8.9094e-01 - variance_output_loss: -8.9094e-01 - output_mean_absolute_error: 0.2085 - output_mean_error: -9.2699e-03 - val_loss: -8.4265e-01 - val_output_loss: -8.4270e-01 - val_variance_output_loss: -8.4270e-01 - val_output_mean_absolute_error: 0.2223 - val_output_mean_error: -1.8327e-02\n",
      "Epoch 17/60\n",
      " - 2s - loss: -9.0736e-01 - output_loss: -9.0741e-01 - variance_output_loss: -9.0741e-01 - output_mean_absolute_error: 0.2055 - output_mean_error: -9.4055e-03 - val_loss: -8.8886e-01 - val_output_loss: -8.8891e-01 - val_variance_output_loss: -8.8891e-01 - val_output_mean_absolute_error: 0.2058 - val_output_mean_error: -2.5665e-02\n",
      "Epoch 18/60\n",
      " - 2s - loss: -9.2775e-01 - output_loss: -9.2780e-01 - variance_output_loss: -9.2780e-01 - output_mean_absolute_error: 0.2024 - output_mean_error: -1.0618e-02 - val_loss: -8.9436e-01 - val_output_loss: -8.9441e-01 - val_variance_output_loss: -8.9441e-01 - val_output_mean_absolute_error: 0.2073 - val_output_mean_error: -1.1726e-02\n",
      "Epoch 19/60\n",
      " - 2s - loss: -9.4683e-01 - output_loss: -9.4688e-01 - variance_output_loss: -9.4688e-01 - output_mean_absolute_error: 0.1993 - output_mean_error: -1.0950e-02 - val_loss: -9.0546e-01 - val_output_loss: -9.0551e-01 - val_variance_output_loss: -9.0551e-01 - val_output_mean_absolute_error: 0.2036 - val_output_mean_error: -1.3554e-02\n",
      "Epoch 20/60\n",
      " - 2s - loss: -9.5733e-01 - output_loss: -9.5738e-01 - variance_output_loss: -9.5738e-01 - output_mean_absolute_error: 0.1972 - output_mean_error: -8.8248e-03 - val_loss: -8.9856e-01 - val_output_loss: -8.9862e-01 - val_variance_output_loss: -8.9862e-01 - val_output_mean_absolute_error: 0.2079 - val_output_mean_error: -8.6442e-02\n",
      "Epoch 21/60\n",
      " - 2s - loss: -9.8637e-01 - output_loss: -9.8642e-01 - variance_output_loss: -9.8642e-01 - output_mean_absolute_error: 0.1912 - output_mean_error: -8.5780e-03 - val_loss: -9.2565e-01 - val_output_loss: -9.2570e-01 - val_variance_output_loss: -9.2570e-01 - val_output_mean_absolute_error: 0.2007 - val_output_mean_error: -4.5157e-02\n",
      "Epoch 22/60\n",
      " - 2s - loss: -1.0054e+00 - output_loss: -1.0054e+00 - variance_output_loss: -1.0054e+00 - output_mean_absolute_error: 0.1899 - output_mean_error: -1.1678e-02 - val_loss: -9.7620e-01 - val_output_loss: -9.7625e-01 - val_variance_output_loss: -9.7625e-01 - val_output_mean_absolute_error: 0.2003 - val_output_mean_error: -1.7063e-02\n",
      "Epoch 23/60\n",
      " - 2s - loss: -1.0180e+00 - output_loss: -1.0180e+00 - variance_output_loss: -1.0180e+00 - output_mean_absolute_error: 0.1880 - output_mean_error: -8.2609e-03 - val_loss: -9.0951e-01 - val_output_loss: -9.0956e-01 - val_variance_output_loss: -9.0956e-01 - val_output_mean_absolute_error: 0.2061 - val_output_mean_error: -4.4496e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      " - 2s - loss: -1.0293e+00 - output_loss: -1.0293e+00 - variance_output_loss: -1.0293e+00 - output_mean_absolute_error: 0.1845 - output_mean_error: -6.8864e-03 - val_loss: -9.1224e-01 - val_output_loss: -9.1229e-01 - val_variance_output_loss: -9.1229e-01 - val_output_mean_absolute_error: 0.1973 - val_output_mean_error: -4.2558e-02\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 25/60\n",
      " - 2s - loss: -1.0479e+00 - output_loss: -1.0479e+00 - variance_output_loss: -1.0479e+00 - output_mean_absolute_error: 0.1841 - output_mean_error: -1.1628e-02 - val_loss: -1.0201e+00 - val_output_loss: -1.0201e+00 - val_variance_output_loss: -1.0201e+00 - val_output_mean_absolute_error: 0.1876 - val_output_mean_error: 0.0031\n",
      "Epoch 26/60\n",
      " - 2s - loss: -1.0663e+00 - output_loss: -1.0663e+00 - variance_output_loss: -1.0663e+00 - output_mean_absolute_error: 0.1803 - output_mean_error: -9.6866e-03 - val_loss: -1.0150e+00 - val_output_loss: -1.0151e+00 - val_variance_output_loss: -1.0151e+00 - val_output_mean_absolute_error: 0.1937 - val_output_mean_error: -9.0252e-03\n",
      "Epoch 27/60\n",
      " - 2s - loss: -1.0735e+00 - output_loss: -1.0736e+00 - variance_output_loss: -1.0736e+00 - output_mean_absolute_error: 0.1795 - output_mean_error: -8.5681e-03 - val_loss: -1.0395e+00 - val_output_loss: -1.0396e+00 - val_variance_output_loss: -1.0396e+00 - val_output_mean_absolute_error: 0.1789 - val_output_mean_error: -1.9537e-02\n",
      "Epoch 28/60\n",
      " - 2s - loss: -1.0816e+00 - output_loss: -1.0817e+00 - variance_output_loss: -1.0817e+00 - output_mean_absolute_error: 0.1766 - output_mean_error: -9.4063e-03 - val_loss: -1.0192e+00 - val_output_loss: -1.0192e+00 - val_variance_output_loss: -1.0192e+00 - val_output_mean_absolute_error: 0.1844 - val_output_mean_error: -1.0422e-02\n",
      "Epoch 29/60\n",
      " - 2s - loss: -1.0821e+00 - output_loss: -1.0822e+00 - variance_output_loss: -1.0822e+00 - output_mean_absolute_error: 0.1789 - output_mean_error: -1.0113e-02 - val_loss: -1.0745e+00 - val_output_loss: -1.0746e+00 - val_variance_output_loss: -1.0746e+00 - val_output_mean_absolute_error: 0.1759 - val_output_mean_error: 8.6055e-04\n",
      "Epoch 30/60\n",
      " - 2s - loss: -1.0892e+00 - output_loss: -1.0892e+00 - variance_output_loss: -1.0892e+00 - output_mean_absolute_error: 0.1779 - output_mean_error: -7.4594e-03 - val_loss: -1.0554e+00 - val_output_loss: -1.0554e+00 - val_variance_output_loss: -1.0554e+00 - val_output_mean_absolute_error: 0.1854 - val_output_mean_error: -2.1346e-02\n",
      "Epoch 31/60\n",
      " - 2s - loss: -1.1073e+00 - output_loss: -1.1074e+00 - variance_output_loss: -1.1074e+00 - output_mean_absolute_error: 0.1735 - output_mean_error: -1.0816e-02 - val_loss: -1.0568e+00 - val_output_loss: -1.0569e+00 - val_variance_output_loss: -1.0569e+00 - val_output_mean_absolute_error: 0.1815 - val_output_mean_error: -2.6119e-02\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 32/60\n",
      " - 2s - loss: -1.1052e+00 - output_loss: -1.1053e+00 - variance_output_loss: -1.1053e+00 - output_mean_absolute_error: 0.1743 - output_mean_error: -8.4881e-03 - val_loss: -1.0961e+00 - val_output_loss: -1.0961e+00 - val_variance_output_loss: -1.0961e+00 - val_output_mean_absolute_error: 0.1719 - val_output_mean_error: -8.2183e-03\n",
      "Epoch 33/60\n",
      " - 2s - loss: -1.1049e+00 - output_loss: -1.1049e+00 - variance_output_loss: -1.1049e+00 - output_mean_absolute_error: 0.1749 - output_mean_error: -9.8245e-03 - val_loss: -1.1066e+00 - val_output_loss: -1.1067e+00 - val_variance_output_loss: -1.1067e+00 - val_output_mean_absolute_error: 0.1738 - val_output_mean_error: -9.7245e-03\n",
      "Epoch 34/60\n",
      " - 2s - loss: -1.1154e+00 - output_loss: -1.1154e+00 - variance_output_loss: -1.1154e+00 - output_mean_absolute_error: 0.1749 - output_mean_error: -1.0359e-02 - val_loss: -1.0385e+00 - val_output_loss: -1.0385e+00 - val_variance_output_loss: -1.0385e+00 - val_output_mean_absolute_error: 0.1853 - val_output_mean_error: -2.2988e-02\n",
      "Epoch 35/60\n",
      " - 2s - loss: -1.1242e+00 - output_loss: -1.1243e+00 - variance_output_loss: -1.1243e+00 - output_mean_absolute_error: 0.1727 - output_mean_error: -8.3304e-03 - val_loss: -1.0935e+00 - val_output_loss: -1.0935e+00 - val_variance_output_loss: -1.0935e+00 - val_output_mean_absolute_error: 0.1775 - val_output_mean_error: -2.5112e-02\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 36/60\n",
      " - 2s - loss: -1.1343e+00 - output_loss: -1.1343e+00 - variance_output_loss: -1.1343e+00 - output_mean_absolute_error: 0.1723 - output_mean_error: -1.1414e-02 - val_loss: -1.0773e+00 - val_output_loss: -1.0773e+00 - val_variance_output_loss: -1.0773e+00 - val_output_mean_absolute_error: 0.1776 - val_output_mean_error: -2.1830e-02\n",
      "Epoch 37/60\n",
      " - 2s - loss: -1.1203e+00 - output_loss: -1.1203e+00 - variance_output_loss: -1.1203e+00 - output_mean_absolute_error: 0.1742 - output_mean_error: -7.8693e-03 - val_loss: -1.0320e+00 - val_output_loss: -1.0321e+00 - val_variance_output_loss: -1.0321e+00 - val_output_mean_absolute_error: 0.1834 - val_output_mean_error: -2.6410e-02\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 38/60\n",
      " - 2s - loss: -1.1360e+00 - output_loss: -1.1360e+00 - variance_output_loss: -1.1360e+00 - output_mean_absolute_error: 0.1720 - output_mean_error: -1.3181e-02 - val_loss: -1.0942e+00 - val_output_loss: -1.0942e+00 - val_variance_output_loss: -1.0942e+00 - val_output_mean_absolute_error: 0.1697 - val_output_mean_error: -1.2205e-02\n",
      "Epoch 39/60\n",
      " - 3s - loss: -1.1416e+00 - output_loss: -1.1416e+00 - variance_output_loss: -1.1416e+00 - output_mean_absolute_error: 0.1680 - output_mean_error: -6.1838e-03 - val_loss: -1.0701e+00 - val_output_loss: -1.0702e+00 - val_variance_output_loss: -1.0702e+00 - val_output_mean_absolute_error: 0.1829 - val_output_mean_error: -2.4805e-02\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 40/60\n",
      " - 2s - loss: -1.1331e+00 - output_loss: -1.1331e+00 - variance_output_loss: -1.1331e+00 - output_mean_absolute_error: 0.1709 - output_mean_error: -9.8291e-03 - val_loss: -1.0866e+00 - val_output_loss: -1.0867e+00 - val_variance_output_loss: -1.0867e+00 - val_output_mean_absolute_error: 0.1772 - val_output_mean_error: -2.1289e-02\n",
      "Epoch 41/60\n",
      " - 2s - loss: -1.1424e+00 - output_loss: -1.1424e+00 - variance_output_loss: -1.1424e+00 - output_mean_absolute_error: 0.1699 - output_mean_error: -1.0603e-02 - val_loss: -1.0608e+00 - val_output_loss: -1.0608e+00 - val_variance_output_loss: -1.0608e+00 - val_output_mean_absolute_error: 0.1856 - val_output_mean_error: -2.0839e-02\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 42/60\n",
      " - 2s - loss: -1.1448e+00 - output_loss: -1.1449e+00 - variance_output_loss: -1.1449e+00 - output_mean_absolute_error: 0.1710 - output_mean_error: -9.7425e-03 - val_loss: -1.0632e+00 - val_output_loss: -1.0632e+00 - val_variance_output_loss: -1.0632e+00 - val_output_mean_absolute_error: 0.1849 - val_output_mean_error: -2.0485e-02\n",
      "Epoch 43/60\n",
      " - 2s - loss: -1.1334e+00 - output_loss: -1.1335e+00 - variance_output_loss: -1.1335e+00 - output_mean_absolute_error: 0.1705 - output_mean_error: -8.4269e-03 - val_loss: -1.0760e+00 - val_output_loss: -1.0760e+00 - val_variance_output_loss: -1.0760e+00 - val_output_mean_absolute_error: 0.1777 - val_output_mean_error: -1.7582e-02\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 44/60\n",
      " - 2s - loss: -1.1307e+00 - output_loss: -1.1308e+00 - variance_output_loss: -1.1308e+00 - output_mean_absolute_error: 0.1726 - output_mean_error: -9.7759e-03 - val_loss: -1.0555e+00 - val_output_loss: -1.0556e+00 - val_variance_output_loss: -1.0556e+00 - val_output_mean_absolute_error: 0.1834 - val_output_mean_error: -2.3400e-02\n",
      "Epoch 45/60\n",
      " - 2s - loss: -1.1386e+00 - output_loss: -1.1387e+00 - variance_output_loss: -1.1387e+00 - output_mean_absolute_error: 0.1705 - output_mean_error: -8.4499e-03 - val_loss: -1.0722e+00 - val_output_loss: -1.0723e+00 - val_variance_output_loss: -1.0723e+00 - val_output_mean_absolute_error: 0.1856 - val_output_mean_error: -2.1502e-02\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 46/60\n",
      " - 2s - loss: -1.1406e+00 - output_loss: -1.1407e+00 - variance_output_loss: -1.1407e+00 - output_mean_absolute_error: 0.1699 - output_mean_error: -9.1234e-03 - val_loss: -1.0959e+00 - val_output_loss: -1.0959e+00 - val_variance_output_loss: -1.0959e+00 - val_output_mean_absolute_error: 0.1757 - val_output_mean_error: -2.3133e-02\n",
      "Epoch 47/60\n",
      " - 2s - loss: -1.1416e+00 - output_loss: -1.1416e+00 - variance_output_loss: -1.1416e+00 - output_mean_absolute_error: 0.1706 - output_mean_error: -1.2100e-02 - val_loss: -1.0475e+00 - val_output_loss: -1.0476e+00 - val_variance_output_loss: -1.0476e+00 - val_output_mean_absolute_error: 0.1944 - val_output_mean_error: -3.4219e-02\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 48/60\n",
      " - 2s - loss: -1.1421e+00 - output_loss: -1.1421e+00 - variance_output_loss: -1.1421e+00 - output_mean_absolute_error: 0.1702 - output_mean_error: -1.0724e-02 - val_loss: -1.1291e+00 - val_output_loss: -1.1292e+00 - val_variance_output_loss: -1.1292e+00 - val_output_mean_absolute_error: 0.1671 - val_output_mean_error: -1.6242e-02\n",
      "Epoch 49/60\n",
      " - 2s - loss: -1.1394e+00 - output_loss: -1.1395e+00 - variance_output_loss: -1.1395e+00 - output_mean_absolute_error: 0.1700 - output_mean_error: -9.7056e-03 - val_loss: -1.0756e+00 - val_output_loss: -1.0757e+00 - val_variance_output_loss: -1.0757e+00 - val_output_mean_absolute_error: 0.1781 - val_output_mean_error: -1.3530e-02\n",
      "Epoch 50/60\n",
      " - 2s - loss: -1.1377e+00 - output_loss: -1.1378e+00 - variance_output_loss: -1.1378e+00 - output_mean_absolute_error: 0.1707 - output_mean_error: -1.0127e-02 - val_loss: -1.0862e+00 - val_output_loss: -1.0863e+00 - val_variance_output_loss: -1.0863e+00 - val_output_mean_absolute_error: 0.1813 - val_output_mean_error: -2.8924e-02\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 51/60\n",
      " - 2s - loss: -1.1386e+00 - output_loss: -1.1387e+00 - variance_output_loss: -1.1387e+00 - output_mean_absolute_error: 0.1701 - output_mean_error: -1.1188e-02 - val_loss: -1.1080e+00 - val_output_loss: -1.1080e+00 - val_variance_output_loss: -1.1080e+00 - val_output_mean_absolute_error: 0.1775 - val_output_mean_error: -1.9039e-02\n",
      "Epoch 52/60\n",
      " - 2s - loss: -1.1410e+00 - output_loss: -1.1411e+00 - variance_output_loss: -1.1411e+00 - output_mean_absolute_error: 0.1709 - output_mean_error: -8.6073e-03 - val_loss: -1.1344e+00 - val_output_loss: -1.1345e+00 - val_variance_output_loss: -1.1345e+00 - val_output_mean_absolute_error: 0.1626 - val_output_mean_error: -1.3311e-02\n",
      "Epoch 53/60\n",
      " - 2s - loss: -1.1429e+00 - output_loss: -1.1430e+00 - variance_output_loss: -1.1430e+00 - output_mean_absolute_error: 0.1703 - output_mean_error: -8.6400e-03 - val_loss: -1.0768e+00 - val_output_loss: -1.0768e+00 - val_variance_output_loss: -1.0768e+00 - val_output_mean_absolute_error: 0.1848 - val_output_mean_error: -2.0573e-02\n",
      "Epoch 54/60\n",
      " - 2s - loss: -1.1356e+00 - output_loss: -1.1356e+00 - variance_output_loss: -1.1356e+00 - output_mean_absolute_error: 0.1718 - output_mean_error: -7.7087e-03 - val_loss: -1.0812e+00 - val_output_loss: -1.0813e+00 - val_variance_output_loss: -1.0813e+00 - val_output_mean_absolute_error: 0.1823 - val_output_mean_error: -2.6663e-02\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 55/60\n",
      " - 2s - loss: -1.1396e+00 - output_loss: -1.1397e+00 - variance_output_loss: -1.1397e+00 - output_mean_absolute_error: 0.1714 - output_mean_error: -1.1278e-02 - val_loss: -1.0982e+00 - val_output_loss: -1.0982e+00 - val_variance_output_loss: -1.0982e+00 - val_output_mean_absolute_error: 0.1751 - val_output_mean_error: -1.7232e-02\n",
      "Epoch 56/60\n",
      " - 2s - loss: -1.1417e+00 - output_loss: -1.1417e+00 - variance_output_loss: -1.1417e+00 - output_mean_absolute_error: 0.1687 - output_mean_error: -6.9109e-03 - val_loss: -1.0589e+00 - val_output_loss: -1.0590e+00 - val_variance_output_loss: -1.0590e+00 - val_output_mean_absolute_error: 0.1796 - val_output_mean_error: -2.4753e-02\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 57/60\n",
      " - 2s - loss: -1.1460e+00 - output_loss: -1.1460e+00 - variance_output_loss: -1.1460e+00 - output_mean_absolute_error: 0.1698 - output_mean_error: -9.2753e-03 - val_loss: -1.0561e+00 - val_output_loss: -1.0561e+00 - val_variance_output_loss: -1.0561e+00 - val_output_mean_absolute_error: 0.1748 - val_output_mean_error: -1.7296e-02\n",
      "Epoch 58/60\n",
      " - 2s - loss: -1.1471e+00 - output_loss: -1.1472e+00 - variance_output_loss: -1.1472e+00 - output_mean_absolute_error: 0.1686 - output_mean_error: -8.6204e-03 - val_loss: -1.0804e+00 - val_output_loss: -1.0804e+00 - val_variance_output_loss: -1.0804e+00 - val_output_mean_absolute_error: 0.1802 - val_output_mean_error: -3.2713e-02\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 59/60\n",
      " - 2s - loss: -1.1316e+00 - output_loss: -1.1316e+00 - variance_output_loss: -1.1316e+00 - output_mean_absolute_error: 0.1730 - output_mean_error: -9.5940e-03 - val_loss: -1.1079e+00 - val_output_loss: -1.1080e+00 - val_variance_output_loss: -1.1080e+00 - val_output_mean_absolute_error: 0.1706 - val_output_mean_error: -1.1242e-02\n",
      "Epoch 60/60\n",
      " - 2s - loss: -1.1411e+00 - output_loss: -1.1412e+00 - variance_output_loss: -1.1412e+00 - output_mean_absolute_error: 0.1700 - output_mean_error: -1.0534e-02 - val_loss: -1.0914e+00 - val_output_loss: -1.0914e+00 - val_variance_output_loss: -1.0914e+00 - val_output_mean_absolute_error: 0.1681 - val_output_mean_error: -1.2959e-02\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Completed Training, 145.63s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_12_5/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_12_5'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/8), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 1879, Number of Validation Data: 208\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 7s - loss: 0.4630 - output_loss: 0.4630 - variance_output_loss: 0.4630 - output_mean_absolute_error: 0.6878 - output_mean_error: -1.6965e-02 - val_loss: 0.4029 - val_output_loss: 0.4028 - val_variance_output_loss: 0.4028 - val_output_mean_absolute_error: 0.6419 - val_output_mean_error: 0.0384\n",
      "Epoch 2/60\n",
      " - 1s - loss: 0.3730 - output_loss: 0.3730 - variance_output_loss: 0.3730 - output_mean_absolute_error: 0.6413 - output_mean_error: 0.0092 - val_loss: 0.3034 - val_output_loss: 0.3033 - val_variance_output_loss: 0.3033 - val_output_mean_absolute_error: 0.6012 - val_output_mean_error: 0.0455\n",
      "Epoch 3/60\n",
      " - 1s - loss: 0.3309 - output_loss: 0.3309 - variance_output_loss: 0.3309 - output_mean_absolute_error: 0.6127 - output_mean_error: -3.6293e-02 - val_loss: 0.3209 - val_output_loss: 0.3209 - val_variance_output_loss: 0.3209 - val_output_mean_absolute_error: 0.5756 - val_output_mean_error: -9.1030e-02\n",
      "Epoch 4/60\n",
      " - 1s - loss: 0.2151 - output_loss: 0.2151 - variance_output_loss: 0.2151 - output_mean_absolute_error: 0.5389 - output_mean_error: -8.2430e-02 - val_loss: 0.0585 - val_output_loss: 0.0584 - val_variance_output_loss: 0.0584 - val_output_mean_absolute_error: 0.4666 - val_output_mean_error: -4.0060e-02\n",
      "Epoch 5/60\n",
      " - 1s - loss: 0.0853 - output_loss: 0.0853 - variance_output_loss: 0.0853 - output_mean_absolute_error: 0.4846 - output_mean_error: -7.3145e-02 - val_loss: 0.0692 - val_output_loss: 0.0691 - val_variance_output_loss: 0.0691 - val_output_mean_absolute_error: 0.4714 - val_output_mean_error: -1.4367e-01\n",
      "Epoch 6/60\n",
      " - 1s - loss: -4.5025e-02 - output_loss: -4.5071e-02 - variance_output_loss: -4.5071e-02 - output_mean_absolute_error: 0.4328 - output_mean_error: -8.2231e-02 - val_loss: -4.9256e-02 - val_output_loss: -4.9301e-02 - val_variance_output_loss: -4.9301e-02 - val_output_mean_absolute_error: 0.4292 - val_output_mean_error: -9.6950e-02\n",
      "Epoch 7/60\n",
      " - 1s - loss: -1.2890e-01 - output_loss: -1.2895e-01 - variance_output_loss: -1.2895e-01 - output_mean_absolute_error: 0.4042 - output_mean_error: -8.3693e-02 - val_loss: -1.4110e-01 - val_output_loss: -1.4115e-01 - val_variance_output_loss: -1.4115e-01 - val_output_mean_absolute_error: 0.3979 - val_output_mean_error: -8.8111e-02\n",
      "Epoch 8/60\n",
      " - 1s - loss: -2.2688e-01 - output_loss: -2.2693e-01 - variance_output_loss: -2.2693e-01 - output_mean_absolute_error: 0.3689 - output_mean_error: -6.0569e-02 - val_loss: -2.6349e-01 - val_output_loss: -2.6353e-01 - val_variance_output_loss: -2.6353e-01 - val_output_mean_absolute_error: 0.3524 - val_output_mean_error: -3.8541e-02\n",
      "Epoch 9/60\n",
      " - 1s - loss: -3.0322e-01 - output_loss: -3.0326e-01 - variance_output_loss: -3.0326e-01 - output_mean_absolute_error: 0.3498 - output_mean_error: -5.7888e-02 - val_loss: -3.1359e-01 - val_output_loss: -3.1363e-01 - val_variance_output_loss: -3.1363e-01 - val_output_mean_absolute_error: 0.3345 - val_output_mean_error: -4.0748e-02\n",
      "Epoch 10/60\n",
      " - 1s - loss: -3.5619e-01 - output_loss: -3.5624e-01 - variance_output_loss: -3.5624e-01 - output_mean_absolute_error: 0.3326 - output_mean_error: -4.3836e-02 - val_loss: -3.3867e-01 - val_output_loss: -3.3872e-01 - val_variance_output_loss: -3.3872e-01 - val_output_mean_absolute_error: 0.3351 - val_output_mean_error: -6.8089e-02\n",
      "Epoch 11/60\n",
      " - 1s - loss: -4.1278e-01 - output_loss: -4.1283e-01 - variance_output_loss: -4.1283e-01 - output_mean_absolute_error: 0.3224 - output_mean_error: -5.1028e-02 - val_loss: -4.0815e-01 - val_output_loss: -4.0819e-01 - val_variance_output_loss: -4.0819e-01 - val_output_mean_absolute_error: 0.3133 - val_output_mean_error: -3.4107e-02\n",
      "Epoch 12/60\n",
      " - 1s - loss: -4.6738e-01 - output_loss: -4.6742e-01 - variance_output_loss: -4.6742e-01 - output_mean_absolute_error: 0.3023 - output_mean_error: -3.6269e-02 - val_loss: -4.6034e-01 - val_output_loss: -4.6039e-01 - val_variance_output_loss: -4.6039e-01 - val_output_mean_absolute_error: 0.3045 - val_output_mean_error: -9.4840e-03\n",
      "Epoch 13/60\n",
      " - 1s - loss: -4.9838e-01 - output_loss: -4.9843e-01 - variance_output_loss: -4.9843e-01 - output_mean_absolute_error: 0.2997 - output_mean_error: -4.2958e-02 - val_loss: -4.4332e-01 - val_output_loss: -4.4337e-01 - val_variance_output_loss: -4.4337e-01 - val_output_mean_absolute_error: 0.3238 - val_output_mean_error: -3.7109e-02\n",
      "Epoch 14/60\n",
      " - 1s - loss: -5.5177e-01 - output_loss: -5.5182e-01 - variance_output_loss: -5.5182e-01 - output_mean_absolute_error: 0.2846 - output_mean_error: -3.6495e-02 - val_loss: -5.0153e-01 - val_output_loss: -5.0157e-01 - val_variance_output_loss: -5.0157e-01 - val_output_mean_absolute_error: 0.3016 - val_output_mean_error: -6.3861e-02\n",
      "Epoch 15/60\n",
      " - 1s - loss: -5.6646e-01 - output_loss: -5.6651e-01 - variance_output_loss: -5.6651e-01 - output_mean_absolute_error: 0.2844 - output_mean_error: -4.1555e-02 - val_loss: -5.2089e-01 - val_output_loss: -5.2094e-01 - val_variance_output_loss: -5.2094e-01 - val_output_mean_absolute_error: 0.2922 - val_output_mean_error: 0.0057\n",
      "Epoch 16/60\n",
      " - 1s - loss: -5.9729e-01 - output_loss: -5.9734e-01 - variance_output_loss: -5.9734e-01 - output_mean_absolute_error: 0.2738 - output_mean_error: -3.1151e-02 - val_loss: -5.8708e-01 - val_output_loss: -5.8713e-01 - val_variance_output_loss: -5.8713e-01 - val_output_mean_absolute_error: 0.2836 - val_output_mean_error: -6.7759e-02\n",
      "Epoch 17/60\n",
      " - 1s - loss: -6.2803e-01 - output_loss: -6.2807e-01 - variance_output_loss: -6.2807e-01 - output_mean_absolute_error: 0.2691 - output_mean_error: -3.6872e-02 - val_loss: -5.9784e-01 - val_output_loss: -5.9789e-01 - val_variance_output_loss: -5.9789e-01 - val_output_mean_absolute_error: 0.2712 - val_output_mean_error: -1.8966e-02\n",
      "Epoch 18/60\n",
      " - 1s - loss: -6.6489e-01 - output_loss: -6.6493e-01 - variance_output_loss: -6.6493e-01 - output_mean_absolute_error: 0.2581 - output_mean_error: -3.4598e-02 - val_loss: -6.0518e-01 - val_output_loss: -6.0523e-01 - val_variance_output_loss: -6.0523e-01 - val_output_mean_absolute_error: 0.2725 - val_output_mean_error: -5.3479e-02\n",
      "Epoch 19/60\n",
      " - 1s - loss: -6.9343e-01 - output_loss: -6.9347e-01 - variance_output_loss: -6.9347e-01 - output_mean_absolute_error: 0.2547 - output_mean_error: -3.4226e-02 - val_loss: -6.6675e-01 - val_output_loss: -6.6680e-01 - val_variance_output_loss: -6.6680e-01 - val_output_mean_absolute_error: 0.2527 - val_output_mean_error: -4.1324e-02\n",
      "Epoch 20/60\n",
      " - 1s - loss: -7.2535e-01 - output_loss: -7.2540e-01 - variance_output_loss: -7.2540e-01 - output_mean_absolute_error: 0.2428 - output_mean_error: -2.8086e-02 - val_loss: -7.0672e-01 - val_output_loss: -7.0677e-01 - val_variance_output_loss: -7.0677e-01 - val_output_mean_absolute_error: 0.2493 - val_output_mean_error: -9.6192e-03\n",
      "Epoch 21/60\n",
      " - 1s - loss: -7.1645e-01 - output_loss: -7.1650e-01 - variance_output_loss: -7.1650e-01 - output_mean_absolute_error: 0.2477 - output_mean_error: -3.1484e-02 - val_loss: -7.2228e-01 - val_output_loss: -7.2233e-01 - val_variance_output_loss: -7.2233e-01 - val_output_mean_absolute_error: 0.2471 - val_output_mean_error: -6.0309e-02\n",
      "Epoch 22/60\n",
      " - 1s - loss: -7.4614e-01 - output_loss: -7.4619e-01 - variance_output_loss: -7.4619e-01 - output_mean_absolute_error: 0.2377 - output_mean_error: -2.7407e-02 - val_loss: -7.0088e-01 - val_output_loss: -7.0093e-01 - val_variance_output_loss: -7.0093e-01 - val_output_mean_absolute_error: 0.2446 - val_output_mean_error: 0.0049\n",
      "Epoch 23/60\n",
      " - 1s - loss: -7.7467e-01 - output_loss: -7.7472e-01 - variance_output_loss: -7.7472e-01 - output_mean_absolute_error: 0.2352 - output_mean_error: -3.0578e-02 - val_loss: -7.2213e-01 - val_output_loss: -7.2218e-01 - val_variance_output_loss: -7.2218e-01 - val_output_mean_absolute_error: 0.2524 - val_output_mean_error: -4.4718e-02\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 24/60\n",
      " - 1s - loss: -8.0586e-01 - output_loss: -8.0591e-01 - variance_output_loss: -8.0591e-01 - output_mean_absolute_error: 0.2264 - output_mean_error: -2.5595e-02 - val_loss: -7.9753e-01 - val_output_loss: -7.9758e-01 - val_variance_output_loss: -7.9758e-01 - val_output_mean_absolute_error: 0.2227 - val_output_mean_error: -2.6394e-02\n",
      "Epoch 25/60\n",
      " - 1s - loss: -8.0176e-01 - output_loss: -8.0181e-01 - variance_output_loss: -8.0181e-01 - output_mean_absolute_error: 0.2302 - output_mean_error: -3.3232e-02 - val_loss: -7.7099e-01 - val_output_loss: -7.7104e-01 - val_variance_output_loss: -7.7104e-01 - val_output_mean_absolute_error: 0.2351 - val_output_mean_error: -1.9732e-02\n",
      "Epoch 26/60\n",
      " - 1s - loss: -8.1148e-01 - output_loss: -8.1153e-01 - variance_output_loss: -8.1153e-01 - output_mean_absolute_error: 0.2267 - output_mean_error: -2.5745e-02 - val_loss: -7.6193e-01 - val_output_loss: -7.6198e-01 - val_variance_output_loss: -7.6198e-01 - val_output_mean_absolute_error: 0.2386 - val_output_mean_error: -3.6202e-02\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 27/60\n",
      " - 1s - loss: -8.3753e-01 - output_loss: -8.3758e-01 - variance_output_loss: -8.3758e-01 - output_mean_absolute_error: 0.2218 - output_mean_error: -2.6462e-02 - val_loss: -7.6361e-01 - val_output_loss: -7.6367e-01 - val_variance_output_loss: -7.6367e-01 - val_output_mean_absolute_error: 0.2336 - val_output_mean_error: -5.5672e-02\n",
      "Epoch 28/60\n",
      " - 1s - loss: -8.2559e-01 - output_loss: -8.2565e-01 - variance_output_loss: -8.2565e-01 - output_mean_absolute_error: 0.2232 - output_mean_error: -2.6512e-02 - val_loss: -7.8509e-01 - val_output_loss: -7.8514e-01 - val_variance_output_loss: -7.8514e-01 - val_output_mean_absolute_error: 0.2306 - val_output_mean_error: -3.3274e-02\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 29/60\n",
      " - 1s - loss: -8.3776e-01 - output_loss: -8.3781e-01 - variance_output_loss: -8.3781e-01 - output_mean_absolute_error: 0.2222 - output_mean_error: -2.8711e-02 - val_loss: -7.6206e-01 - val_output_loss: -7.6211e-01 - val_variance_output_loss: -7.6211e-01 - val_output_mean_absolute_error: 0.2364 - val_output_mean_error: -3.0377e-02\n",
      "Epoch 30/60\n",
      " - 1s - loss: -8.5056e-01 - output_loss: -8.5061e-01 - variance_output_loss: -8.5061e-01 - output_mean_absolute_error: 0.2196 - output_mean_error: -2.7410e-02 - val_loss: -7.9205e-01 - val_output_loss: -7.9210e-01 - val_variance_output_loss: -7.9210e-01 - val_output_mean_absolute_error: 0.2253 - val_output_mean_error: -4.6637e-02\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 31/60\n",
      " - 1s - loss: -8.4316e-01 - output_loss: -8.4321e-01 - variance_output_loss: -8.4321e-01 - output_mean_absolute_error: 0.2203 - output_mean_error: -2.8391e-02 - val_loss: -7.3924e-01 - val_output_loss: -7.3929e-01 - val_variance_output_loss: -7.3929e-01 - val_output_mean_absolute_error: 0.2422 - val_output_mean_error: -2.5078e-02\n",
      "Epoch 32/60\n",
      " - 1s - loss: -8.5373e-01 - output_loss: -8.5378e-01 - variance_output_loss: -8.5378e-01 - output_mean_absolute_error: 0.2186 - output_mean_error: -2.7113e-02 - val_loss: -7.9824e-01 - val_output_loss: -7.9829e-01 - val_variance_output_loss: -7.9829e-01 - val_output_mean_absolute_error: 0.2318 - val_output_mean_error: -3.2333e-02\n",
      "Epoch 33/60\n",
      " - 1s - loss: -8.4921e-01 - output_loss: -8.4926e-01 - variance_output_loss: -8.4926e-01 - output_mean_absolute_error: 0.2221 - output_mean_error: -2.7227e-02 - val_loss: -7.4529e-01 - val_output_loss: -7.4534e-01 - val_variance_output_loss: -7.4534e-01 - val_output_mean_absolute_error: 0.2314 - val_output_mean_error: -8.3097e-03\n",
      "Epoch 34/60\n",
      " - 1s - loss: -8.5486e-01 - output_loss: -8.5491e-01 - variance_output_loss: -8.5491e-01 - output_mean_absolute_error: 0.2175 - output_mean_error: -2.6315e-02 - val_loss: -7.6045e-01 - val_output_loss: -7.6050e-01 - val_variance_output_loss: -7.6050e-01 - val_output_mean_absolute_error: 0.2395 - val_output_mean_error: -5.2022e-02\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 35/60\n",
      " - 1s - loss: -8.4980e-01 - output_loss: -8.4985e-01 - variance_output_loss: -8.4985e-01 - output_mean_absolute_error: 0.2191 - output_mean_error: -2.6480e-02 - val_loss: -8.0367e-01 - val_output_loss: -8.0372e-01 - val_variance_output_loss: -8.0372e-01 - val_output_mean_absolute_error: 0.2304 - val_output_mean_error: 0.0013\n",
      "Epoch 36/60\n",
      " - 1s - loss: -8.5827e-01 - output_loss: -8.5832e-01 - variance_output_loss: -8.5832e-01 - output_mean_absolute_error: 0.2175 - output_mean_error: -2.6187e-02 - val_loss: -8.0854e-01 - val_output_loss: -8.0859e-01 - val_variance_output_loss: -8.0859e-01 - val_output_mean_absolute_error: 0.2262 - val_output_mean_error: -4.6407e-02\n",
      "Epoch 37/60\n",
      " - 1s - loss: -8.4509e-01 - output_loss: -8.4514e-01 - variance_output_loss: -8.4514e-01 - output_mean_absolute_error: 0.2209 - output_mean_error: -2.9792e-02 - val_loss: -8.0884e-01 - val_output_loss: -8.0889e-01 - val_variance_output_loss: -8.0889e-01 - val_output_mean_absolute_error: 0.2224 - val_output_mean_error: -1.0824e-02\n",
      "Epoch 38/60\n",
      " - 1s - loss: -8.5948e-01 - output_loss: -8.5953e-01 - variance_output_loss: -8.5953e-01 - output_mean_absolute_error: 0.2159 - output_mean_error: -2.4522e-02 - val_loss: -8.4230e-01 - val_output_loss: -8.4235e-01 - val_variance_output_loss: -8.4235e-01 - val_output_mean_absolute_error: 0.2200 - val_output_mean_error: -2.7907e-02\n",
      "Epoch 39/60\n",
      " - 1s - loss: -8.5081e-01 - output_loss: -8.5086e-01 - variance_output_loss: -8.5086e-01 - output_mean_absolute_error: 0.2200 - output_mean_error: -2.6984e-02 - val_loss: -7.8203e-01 - val_output_loss: -7.8208e-01 - val_variance_output_loss: -7.8208e-01 - val_output_mean_absolute_error: 0.2346 - val_output_mean_error: -3.0000e-02\n",
      "Epoch 40/60\n",
      " - 1s - loss: -8.6053e-01 - output_loss: -8.6058e-01 - variance_output_loss: -8.6058e-01 - output_mean_absolute_error: 0.2188 - output_mean_error: -2.8619e-02 - val_loss: -8.1763e-01 - val_output_loss: -8.1768e-01 - val_variance_output_loss: -8.1768e-01 - val_output_mean_absolute_error: 0.2273 - val_output_mean_error: -3.4445e-02\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 41/60\n",
      " - 1s - loss: -8.7455e-01 - output_loss: -8.7460e-01 - variance_output_loss: -8.7460e-01 - output_mean_absolute_error: 0.2147 - output_mean_error: -2.2479e-02 - val_loss: -7.8404e-01 - val_output_loss: -7.8409e-01 - val_variance_output_loss: -7.8409e-01 - val_output_mean_absolute_error: 0.2282 - val_output_mean_error: -3.3316e-02\n",
      "Epoch 42/60\n",
      " - 1s - loss: -8.6116e-01 - output_loss: -8.6121e-01 - variance_output_loss: -8.6121e-01 - output_mean_absolute_error: 0.2181 - output_mean_error: -2.7682e-02 - val_loss: -8.0213e-01 - val_output_loss: -8.0218e-01 - val_variance_output_loss: -8.0218e-01 - val_output_mean_absolute_error: 0.2303 - val_output_mean_error: -3.3412e-02\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 43/60\n",
      " - 1s - loss: -8.5276e-01 - output_loss: -8.5281e-01 - variance_output_loss: -8.5281e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.7068e-02 - val_loss: -8.1750e-01 - val_output_loss: -8.1755e-01 - val_variance_output_loss: -8.1755e-01 - val_output_mean_absolute_error: 0.2254 - val_output_mean_error: -3.0011e-02\n",
      "Epoch 44/60\n",
      " - 1s - loss: -8.5653e-01 - output_loss: -8.5658e-01 - variance_output_loss: -8.5658e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.8189e-02 - val_loss: -7.9744e-01 - val_output_loss: -7.9749e-01 - val_variance_output_loss: -7.9749e-01 - val_output_mean_absolute_error: 0.2356 - val_output_mean_error: -3.2064e-02\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 45/60\n",
      " - 1s - loss: -8.6308e-01 - output_loss: -8.6313e-01 - variance_output_loss: -8.6313e-01 - output_mean_absolute_error: 0.2163 - output_mean_error: -2.2857e-02 - val_loss: -8.0846e-01 - val_output_loss: -8.0851e-01 - val_variance_output_loss: -8.0851e-01 - val_output_mean_absolute_error: 0.2250 - val_output_mean_error: -2.9214e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/60\n",
      " - 1s - loss: -8.5248e-01 - output_loss: -8.5253e-01 - variance_output_loss: -8.5253e-01 - output_mean_absolute_error: 0.2189 - output_mean_error: -2.8606e-02 - val_loss: -7.8174e-01 - val_output_loss: -7.8179e-01 - val_variance_output_loss: -7.8179e-01 - val_output_mean_absolute_error: 0.2349 - val_output_mean_error: -2.2638e-02\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 47/60\n",
      " - 1s - loss: -8.5219e-01 - output_loss: -8.5224e-01 - variance_output_loss: -8.5224e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.4259e-02 - val_loss: -8.4288e-01 - val_output_loss: -8.4293e-01 - val_variance_output_loss: -8.4293e-01 - val_output_mean_absolute_error: 0.2190 - val_output_mean_error: -2.6133e-02\n",
      "Epoch 48/60\n",
      " - 1s - loss: -8.6340e-01 - output_loss: -8.6346e-01 - variance_output_loss: -8.6346e-01 - output_mean_absolute_error: 0.2176 - output_mean_error: -3.0914e-02 - val_loss: -7.9581e-01 - val_output_loss: -7.9586e-01 - val_variance_output_loss: -7.9586e-01 - val_output_mean_absolute_error: 0.2273 - val_output_mean_error: -1.1548e-02\n",
      "Epoch 49/60\n",
      " - 1s - loss: -8.4937e-01 - output_loss: -8.4943e-01 - variance_output_loss: -8.4943e-01 - output_mean_absolute_error: 0.2205 - output_mean_error: -3.0583e-02 - val_loss: -7.9666e-01 - val_output_loss: -7.9671e-01 - val_variance_output_loss: -7.9671e-01 - val_output_mean_absolute_error: 0.2322 - val_output_mean_error: -3.8083e-02\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 50/60\n",
      " - 1s - loss: -8.6280e-01 - output_loss: -8.6285e-01 - variance_output_loss: -8.6285e-01 - output_mean_absolute_error: 0.2165 - output_mean_error: -2.4932e-02 - val_loss: -7.8482e-01 - val_output_loss: -7.8488e-01 - val_variance_output_loss: -7.8488e-01 - val_output_mean_absolute_error: 0.2352 - val_output_mean_error: -2.4251e-02\n",
      "Epoch 51/60\n",
      " - 1s - loss: -8.6471e-01 - output_loss: -8.6476e-01 - variance_output_loss: -8.6476e-01 - output_mean_absolute_error: 0.2166 - output_mean_error: -2.6203e-02 - val_loss: -7.8671e-01 - val_output_loss: -7.8676e-01 - val_variance_output_loss: -7.8676e-01 - val_output_mean_absolute_error: 0.2257 - val_output_mean_error: -2.2793e-02\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 52/60\n",
      " - 1s - loss: -8.6474e-01 - output_loss: -8.6479e-01 - variance_output_loss: -8.6479e-01 - output_mean_absolute_error: 0.2173 - output_mean_error: -2.9252e-02 - val_loss: -7.5581e-01 - val_output_loss: -7.5586e-01 - val_variance_output_loss: -7.5586e-01 - val_output_mean_absolute_error: 0.2368 - val_output_mean_error: -3.0232e-02\n",
      "Epoch 53/60\n",
      " - 1s - loss: -8.6116e-01 - output_loss: -8.6121e-01 - variance_output_loss: -8.6121e-01 - output_mean_absolute_error: 0.2169 - output_mean_error: -2.4582e-02 - val_loss: -8.2189e-01 - val_output_loss: -8.2194e-01 - val_variance_output_loss: -8.2194e-01 - val_output_mean_absolute_error: 0.2193 - val_output_mean_error: -2.0764e-02\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 54/60\n",
      " - 1s - loss: -8.6539e-01 - output_loss: -8.6544e-01 - variance_output_loss: -8.6544e-01 - output_mean_absolute_error: 0.2174 - output_mean_error: -2.9423e-02 - val_loss: -8.2636e-01 - val_output_loss: -8.2641e-01 - val_variance_output_loss: -8.2641e-01 - val_output_mean_absolute_error: 0.2195 - val_output_mean_error: -2.7064e-02\n",
      "Epoch 55/60\n",
      " - 1s - loss: -8.4854e-01 - output_loss: -8.4859e-01 - variance_output_loss: -8.4859e-01 - output_mean_absolute_error: 0.2185 - output_mean_error: -2.4577e-02 - val_loss: -8.0316e-01 - val_output_loss: -8.0321e-01 - val_variance_output_loss: -8.0321e-01 - val_output_mean_absolute_error: 0.2347 - val_output_mean_error: -2.4151e-02\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 56/60\n",
      " - 1s - loss: -8.4959e-01 - output_loss: -8.4964e-01 - variance_output_loss: -8.4964e-01 - output_mean_absolute_error: 0.2189 - output_mean_error: -2.8588e-02 - val_loss: -8.1500e-01 - val_output_loss: -8.1505e-01 - val_variance_output_loss: -8.1505e-01 - val_output_mean_absolute_error: 0.2267 - val_output_mean_error: -3.3707e-02\n",
      "Epoch 57/60\n",
      " - 1s - loss: -8.7571e-01 - output_loss: -8.7576e-01 - variance_output_loss: -8.7576e-01 - output_mean_absolute_error: 0.2126 - output_mean_error: -2.3711e-02 - val_loss: -7.7255e-01 - val_output_loss: -7.7260e-01 - val_variance_output_loss: -7.7260e-01 - val_output_mean_absolute_error: 0.2360 - val_output_mean_error: -2.8271e-02\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 58/60\n",
      " - 1s - loss: -8.5666e-01 - output_loss: -8.5671e-01 - variance_output_loss: -8.5671e-01 - output_mean_absolute_error: 0.2197 - output_mean_error: -2.4424e-02 - val_loss: -7.8550e-01 - val_output_loss: -7.8555e-01 - val_variance_output_loss: -7.8555e-01 - val_output_mean_absolute_error: 0.2327 - val_output_mean_error: -2.9433e-02\n",
      "Epoch 59/60\n",
      " - 1s - loss: -8.5500e-01 - output_loss: -8.5505e-01 - variance_output_loss: -8.5505e-01 - output_mean_absolute_error: 0.2182 - output_mean_error: -2.6217e-02 - val_loss: -8.1519e-01 - val_output_loss: -8.1524e-01 - val_variance_output_loss: -8.1524e-01 - val_output_mean_absolute_error: 0.2181 - val_output_mean_error: -3.0092e-02\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 60/60\n",
      " - 1s - loss: -8.5664e-01 - output_loss: -8.5669e-01 - variance_output_loss: -8.5669e-01 - output_mean_absolute_error: 0.2190 - output_mean_error: -2.9202e-02 - val_loss: -8.5742e-01 - val_output_loss: -8.5747e-01 - val_variance_output_loss: -8.5747e-01 - val_output_mean_absolute_error: 0.2175 - val_output_mean_error: -1.8125e-02\n",
      "Completed Training, 79.97s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_model_fixed_6_25/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_6_25'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/16), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 939, Number of Validation Data: 104\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 6s - loss: 0.4819 - output_loss: 0.4818 - variance_output_loss: 0.4818 - output_mean_absolute_error: 0.7017 - output_mean_error: -1.3248e-02 - val_loss: 0.3123 - val_output_loss: 0.3123 - val_variance_output_loss: 0.3123 - val_output_mean_absolute_error: 0.5688 - val_output_mean_error: 0.1058\n",
      "Epoch 2/60\n",
      " - 1s - loss: 0.4943 - output_loss: 0.4943 - variance_output_loss: 0.4943 - output_mean_absolute_error: 0.7097 - output_mean_error: -3.2834e-02 - val_loss: 0.3214 - val_output_loss: 0.3214 - val_variance_output_loss: 0.3214 - val_output_mean_absolute_error: 0.5853 - val_output_mean_error: 0.1485\n",
      "Epoch 3/60\n",
      " - 1s - loss: 0.4216 - output_loss: 0.4216 - variance_output_loss: 0.4216 - output_mean_absolute_error: 0.6613 - output_mean_error: 2.8559e-04 - val_loss: 0.2772 - val_output_loss: 0.2772 - val_variance_output_loss: 0.2772 - val_output_mean_absolute_error: 0.5943 - val_output_mean_error: 0.0958\n",
      "Epoch 4/60\n",
      " - 1s - loss: 0.4263 - output_loss: 0.4262 - variance_output_loss: 0.4262 - output_mean_absolute_error: 0.6677 - output_mean_error: -1.3007e-02 - val_loss: 0.3557 - val_output_loss: 0.3557 - val_variance_output_loss: 0.3557 - val_output_mean_absolute_error: 0.6158 - val_output_mean_error: 0.1037\n",
      "Epoch 5/60\n",
      " - 1s - loss: 0.4606 - output_loss: 0.4605 - variance_output_loss: 0.4605 - output_mean_absolute_error: 0.6763 - output_mean_error: -2.5260e-02 - val_loss: 0.2662 - val_output_loss: 0.2662 - val_variance_output_loss: 0.2662 - val_output_mean_absolute_error: 0.5593 - val_output_mean_error: 0.0353\n",
      "Epoch 6/60\n",
      " - 1s - loss: 0.3704 - output_loss: 0.3704 - variance_output_loss: 0.3704 - output_mean_absolute_error: 0.6203 - output_mean_error: -2.9312e-04 - val_loss: 0.2248 - val_output_loss: 0.2248 - val_variance_output_loss: 0.2248 - val_output_mean_absolute_error: 0.5530 - val_output_mean_error: 0.0982\n",
      "Epoch 7/60\n",
      " - 1s - loss: 0.3301 - output_loss: 0.3301 - variance_output_loss: 0.3301 - output_mean_absolute_error: 0.5980 - output_mean_error: -4.0815e-02 - val_loss: 0.1797 - val_output_loss: 0.1796 - val_variance_output_loss: 0.1796 - val_output_mean_absolute_error: 0.5331 - val_output_mean_error: 0.0693\n",
      "Epoch 8/60\n",
      " - 1s - loss: 0.2657 - output_loss: 0.2656 - variance_output_loss: 0.2656 - output_mean_absolute_error: 0.5735 - output_mean_error: -1.9646e-02 - val_loss: 0.1433 - val_output_loss: 0.1433 - val_variance_output_loss: 0.1433 - val_output_mean_absolute_error: 0.5159 - val_output_mean_error: 0.0285\n",
      "Epoch 9/60\n",
      " - 1s - loss: 0.2135 - output_loss: 0.2134 - variance_output_loss: 0.2134 - output_mean_absolute_error: 0.5436 - output_mean_error: -6.3124e-02 - val_loss: 0.0816 - val_output_loss: 0.0816 - val_variance_output_loss: 0.0816 - val_output_mean_absolute_error: 0.4859 - val_output_mean_error: 0.0258\n",
      "Epoch 10/60\n",
      " - 1s - loss: 0.1302 - output_loss: 0.1301 - variance_output_loss: 0.1301 - output_mean_absolute_error: 0.5178 - output_mean_error: -3.8115e-02 - val_loss: 0.0280 - val_output_loss: 0.0279 - val_variance_output_loss: 0.0279 - val_output_mean_absolute_error: 0.4641 - val_output_mean_error: 0.0908\n",
      "Epoch 11/60\n",
      " - 1s - loss: 0.1017 - output_loss: 0.1016 - variance_output_loss: 0.1016 - output_mean_absolute_error: 0.5104 - output_mean_error: -4.8163e-02 - val_loss: -1.0692e-02 - val_output_loss: -1.0738e-02 - val_variance_output_loss: -1.0738e-02 - val_output_mean_absolute_error: 0.4391 - val_output_mean_error: -1.7737e-02\n",
      "Epoch 12/60\n",
      " - 1s - loss: 0.0199 - output_loss: 0.0199 - variance_output_loss: 0.0199 - output_mean_absolute_error: 0.4753 - output_mean_error: -5.9459e-02 - val_loss: -6.2743e-02 - val_output_loss: -6.2789e-02 - val_variance_output_loss: -6.2789e-02 - val_output_mean_absolute_error: 0.4369 - val_output_mean_error: -1.1720e-02\n",
      "Epoch 13/60\n",
      " - 1s - loss: -1.7830e-02 - output_loss: -1.7875e-02 - variance_output_loss: -1.7875e-02 - output_mean_absolute_error: 0.4658 - output_mean_error: -6.4620e-02 - val_loss: -1.3310e-01 - val_output_loss: -1.3315e-01 - val_variance_output_loss: -1.3315e-01 - val_output_mean_absolute_error: 0.4006 - val_output_mean_error: -1.0067e-03\n",
      "Epoch 14/60\n",
      " - 1s - loss: -6.9499e-02 - output_loss: -6.9545e-02 - variance_output_loss: -6.9545e-02 - output_mean_absolute_error: 0.4461 - output_mean_error: -6.1632e-02 - val_loss: -1.5680e-01 - val_output_loss: -1.5685e-01 - val_variance_output_loss: -1.5685e-01 - val_output_mean_absolute_error: 0.3978 - val_output_mean_error: 0.0206\n",
      "Epoch 15/60\n",
      " - 1s - loss: -9.5932e-02 - output_loss: -9.5978e-02 - variance_output_loss: -9.5978e-02 - output_mean_absolute_error: 0.4455 - output_mean_error: -9.0086e-02 - val_loss: -2.0262e-01 - val_output_loss: -2.0267e-01 - val_variance_output_loss: -2.0267e-01 - val_output_mean_absolute_error: 0.3622 - val_output_mean_error: 0.0118\n",
      "Epoch 16/60\n",
      " - 1s - loss: -1.6332e-01 - output_loss: -1.6337e-01 - variance_output_loss: -1.6337e-01 - output_mean_absolute_error: 0.4176 - output_mean_error: -6.0686e-02 - val_loss: -2.0568e-01 - val_output_loss: -2.0573e-01 - val_variance_output_loss: -2.0573e-01 - val_output_mean_absolute_error: 0.3893 - val_output_mean_error: -4.6918e-02\n",
      "Epoch 17/60\n",
      " - 1s - loss: -1.6616e-01 - output_loss: -1.6620e-01 - variance_output_loss: -1.6620e-01 - output_mean_absolute_error: 0.4225 - output_mean_error: -8.3032e-02 - val_loss: -2.2810e-01 - val_output_loss: -2.2815e-01 - val_variance_output_loss: -2.2815e-01 - val_output_mean_absolute_error: 0.3907 - val_output_mean_error: -4.5269e-02\n",
      "Epoch 18/60\n",
      " - 1s - loss: -2.2477e-01 - output_loss: -2.2482e-01 - variance_output_loss: -2.2482e-01 - output_mean_absolute_error: 0.4000 - output_mean_error: -6.5321e-02 - val_loss: -2.5105e-01 - val_output_loss: -2.5110e-01 - val_variance_output_loss: -2.5110e-01 - val_output_mean_absolute_error: 0.3590 - val_output_mean_error: -3.8811e-02\n",
      "Epoch 19/60\n",
      " - 1s - loss: -2.4958e-01 - output_loss: -2.4962e-01 - variance_output_loss: -2.4962e-01 - output_mean_absolute_error: 0.3924 - output_mean_error: -7.8512e-02 - val_loss: -3.1833e-01 - val_output_loss: -3.1838e-01 - val_variance_output_loss: -3.1838e-01 - val_output_mean_absolute_error: 0.3552 - val_output_mean_error: 0.0195\n",
      "Epoch 20/60\n",
      " - 1s - loss: -2.6593e-01 - output_loss: -2.6598e-01 - variance_output_loss: -2.6598e-01 - output_mean_absolute_error: 0.3857 - output_mean_error: -7.4378e-02 - val_loss: -3.0016e-01 - val_output_loss: -3.0021e-01 - val_variance_output_loss: -3.0021e-01 - val_output_mean_absolute_error: 0.3718 - val_output_mean_error: -5.9437e-02\n",
      "Epoch 21/60\n",
      " - 1s - loss: -2.9294e-01 - output_loss: -2.9298e-01 - variance_output_loss: -2.9298e-01 - output_mean_absolute_error: 0.3794 - output_mean_error: -6.9863e-02 - val_loss: -3.5708e-01 - val_output_loss: -3.5713e-01 - val_variance_output_loss: -3.5713e-01 - val_output_mean_absolute_error: 0.3410 - val_output_mean_error: -3.2643e-02\n",
      "Epoch 22/60\n",
      " - 1s - loss: -3.1864e-01 - output_loss: -3.1869e-01 - variance_output_loss: -3.1869e-01 - output_mean_absolute_error: 0.3710 - output_mean_error: -6.7801e-02 - val_loss: -3.8196e-01 - val_output_loss: -3.8200e-01 - val_variance_output_loss: -3.8200e-01 - val_output_mean_absolute_error: 0.3329 - val_output_mean_error: -1.0257e-02\n",
      "Epoch 23/60\n",
      " - 1s - loss: -3.5316e-01 - output_loss: -3.5321e-01 - variance_output_loss: -3.5321e-01 - output_mean_absolute_error: 0.3577 - output_mean_error: -5.5498e-02 - val_loss: -3.7921e-01 - val_output_loss: -3.7926e-01 - val_variance_output_loss: -3.7926e-01 - val_output_mean_absolute_error: 0.3483 - val_output_mean_error: -4.3060e-02\n",
      "Epoch 24/60\n",
      " - 1s - loss: -3.6394e-01 - output_loss: -3.6398e-01 - variance_output_loss: -3.6398e-01 - output_mean_absolute_error: 0.3587 - output_mean_error: -7.1982e-02 - val_loss: -4.5015e-01 - val_output_loss: -4.5020e-01 - val_variance_output_loss: -4.5020e-01 - val_output_mean_absolute_error: 0.3130 - val_output_mean_error: -6.9040e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      " - 1s - loss: -3.9155e-01 - output_loss: -3.9159e-01 - variance_output_loss: -3.9159e-01 - output_mean_absolute_error: 0.3500 - output_mean_error: -5.5693e-02 - val_loss: -3.6585e-01 - val_output_loss: -3.6589e-01 - val_variance_output_loss: -3.6589e-01 - val_output_mean_absolute_error: 0.3403 - val_output_mean_error: 0.0425\n",
      "Epoch 26/60\n",
      " - 1s - loss: -4.0286e-01 - output_loss: -4.0290e-01 - variance_output_loss: -4.0290e-01 - output_mean_absolute_error: 0.3461 - output_mean_error: -6.3673e-02 - val_loss: -3.7752e-01 - val_output_loss: -3.7757e-01 - val_variance_output_loss: -3.7757e-01 - val_output_mean_absolute_error: 0.3405 - val_output_mean_error: 0.0625\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 27/60\n",
      " - 1s - loss: -4.3230e-01 - output_loss: -4.3234e-01 - variance_output_loss: -4.3234e-01 - output_mean_absolute_error: 0.3341 - output_mean_error: -5.5570e-02 - val_loss: -4.2472e-01 - val_output_loss: -4.2476e-01 - val_variance_output_loss: -4.2476e-01 - val_output_mean_absolute_error: 0.3247 - val_output_mean_error: -2.5207e-02\n",
      "Epoch 28/60\n",
      " - 1s - loss: -4.3255e-01 - output_loss: -4.3260e-01 - variance_output_loss: -4.3260e-01 - output_mean_absolute_error: 0.3346 - output_mean_error: -5.3318e-02 - val_loss: -4.6593e-01 - val_output_loss: -4.6598e-01 - val_variance_output_loss: -4.6598e-01 - val_output_mean_absolute_error: 0.3049 - val_output_mean_error: 3.8070e-04\n",
      "Epoch 29/60\n",
      " - 1s - loss: -4.4733e-01 - output_loss: -4.4738e-01 - variance_output_loss: -4.4738e-01 - output_mean_absolute_error: 0.3338 - output_mean_error: -6.0701e-02 - val_loss: -4.8591e-01 - val_output_loss: -4.8595e-01 - val_variance_output_loss: -4.8595e-01 - val_output_mean_absolute_error: 0.3070 - val_output_mean_error: -8.8801e-03\n",
      "Epoch 30/60\n",
      " - 1s - loss: -4.6619e-01 - output_loss: -4.6624e-01 - variance_output_loss: -4.6624e-01 - output_mean_absolute_error: 0.3263 - output_mean_error: -6.3640e-02 - val_loss: -4.6178e-01 - val_output_loss: -4.6183e-01 - val_variance_output_loss: -4.6183e-01 - val_output_mean_absolute_error: 0.3140 - val_output_mean_error: 0.0047\n",
      "Epoch 31/60\n",
      " - 1s - loss: -4.7116e-01 - output_loss: -4.7120e-01 - variance_output_loss: -4.7120e-01 - output_mean_absolute_error: 0.3214 - output_mean_error: -3.8253e-02 - val_loss: -4.4829e-01 - val_output_loss: -4.4834e-01 - val_variance_output_loss: -4.4834e-01 - val_output_mean_absolute_error: 0.3299 - val_output_mean_error: -5.1166e-02\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 32/60\n",
      " - 1s - loss: -4.7837e-01 - output_loss: -4.7842e-01 - variance_output_loss: -4.7842e-01 - output_mean_absolute_error: 0.3233 - output_mean_error: -5.9977e-02 - val_loss: -5.4922e-01 - val_output_loss: -5.4927e-01 - val_variance_output_loss: -5.4927e-01 - val_output_mean_absolute_error: 0.2923 - val_output_mean_error: -1.4871e-02\n",
      "Epoch 33/60\n",
      " - 1s - loss: -4.7344e-01 - output_loss: -4.7348e-01 - variance_output_loss: -4.7348e-01 - output_mean_absolute_error: 0.3228 - output_mean_error: -4.8075e-02 - val_loss: -4.5497e-01 - val_output_loss: -4.5502e-01 - val_variance_output_loss: -4.5502e-01 - val_output_mean_absolute_error: 0.3094 - val_output_mean_error: -3.4269e-02\n",
      "Epoch 34/60\n",
      " - 1s - loss: -4.7747e-01 - output_loss: -4.7752e-01 - variance_output_loss: -4.7752e-01 - output_mean_absolute_error: 0.3239 - output_mean_error: -6.1079e-02 - val_loss: -4.9368e-01 - val_output_loss: -4.9373e-01 - val_variance_output_loss: -4.9373e-01 - val_output_mean_absolute_error: 0.2996 - val_output_mean_error: -2.3666e-02\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 35/60\n",
      " - 1s - loss: -5.0255e-01 - output_loss: -5.0260e-01 - variance_output_loss: -5.0260e-01 - output_mean_absolute_error: 0.3103 - output_mean_error: -3.5684e-02 - val_loss: -5.3201e-01 - val_output_loss: -5.3206e-01 - val_variance_output_loss: -5.3206e-01 - val_output_mean_absolute_error: 0.2864 - val_output_mean_error: -4.4030e-02\n",
      "Epoch 36/60\n",
      " - 1s - loss: -4.8141e-01 - output_loss: -4.8146e-01 - variance_output_loss: -4.8146e-01 - output_mean_absolute_error: 0.3252 - output_mean_error: -6.2617e-02 - val_loss: -4.7752e-01 - val_output_loss: -4.7757e-01 - val_variance_output_loss: -4.7757e-01 - val_output_mean_absolute_error: 0.2981 - val_output_mean_error: -1.4426e-02\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 37/60\n",
      " - 1s - loss: -4.9291e-01 - output_loss: -4.9296e-01 - variance_output_loss: -4.9296e-01 - output_mean_absolute_error: 0.3157 - output_mean_error: -5.0730e-02 - val_loss: -4.9534e-01 - val_output_loss: -4.9539e-01 - val_variance_output_loss: -4.9539e-01 - val_output_mean_absolute_error: 0.3034 - val_output_mean_error: 0.0026\n",
      "Epoch 38/60\n",
      " - 1s - loss: -5.0091e-01 - output_loss: -5.0096e-01 - variance_output_loss: -5.0096e-01 - output_mean_absolute_error: 0.3135 - output_mean_error: -4.3708e-02 - val_loss: -4.8732e-01 - val_output_loss: -4.8737e-01 - val_variance_output_loss: -4.8737e-01 - val_output_mean_absolute_error: 0.3181 - val_output_mean_error: -3.9015e-02\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 39/60\n",
      " - 1s - loss: -4.9591e-01 - output_loss: -4.9596e-01 - variance_output_loss: -4.9596e-01 - output_mean_absolute_error: 0.3158 - output_mean_error: -5.3267e-02 - val_loss: -4.6304e-01 - val_output_loss: -4.6309e-01 - val_variance_output_loss: -4.6309e-01 - val_output_mean_absolute_error: 0.3124 - val_output_mean_error: -1.7426e-02\n",
      "Epoch 40/60\n",
      " - 1s - loss: -4.9733e-01 - output_loss: -4.9738e-01 - variance_output_loss: -4.9738e-01 - output_mean_absolute_error: 0.3177 - output_mean_error: -5.4160e-02 - val_loss: -4.8406e-01 - val_output_loss: -4.8411e-01 - val_variance_output_loss: -4.8411e-01 - val_output_mean_absolute_error: 0.2986 - val_output_mean_error: -7.4843e-03\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 41/60\n",
      " - 1s - loss: -4.8962e-01 - output_loss: -4.8966e-01 - variance_output_loss: -4.8966e-01 - output_mean_absolute_error: 0.3158 - output_mean_error: -4.6726e-02 - val_loss: -5.3549e-01 - val_output_loss: -5.3554e-01 - val_variance_output_loss: -5.3554e-01 - val_output_mean_absolute_error: 0.2890 - val_output_mean_error: -3.8561e-03\n",
      "Epoch 42/60\n",
      " - 1s - loss: -5.1477e-01 - output_loss: -5.1481e-01 - variance_output_loss: -5.1481e-01 - output_mean_absolute_error: 0.3105 - output_mean_error: -5.4747e-02 - val_loss: -5.6296e-01 - val_output_loss: -5.6300e-01 - val_variance_output_loss: -5.6300e-01 - val_output_mean_absolute_error: 0.2868 - val_output_mean_error: -3.0884e-02\n",
      "Epoch 43/60\n",
      " - 1s - loss: -4.9731e-01 - output_loss: -4.9736e-01 - variance_output_loss: -4.9736e-01 - output_mean_absolute_error: 0.3183 - output_mean_error: -5.4092e-02 - val_loss: -4.5754e-01 - val_output_loss: -4.5758e-01 - val_variance_output_loss: -4.5758e-01 - val_output_mean_absolute_error: 0.3043 - val_output_mean_error: -1.3168e-02\n",
      "Epoch 44/60\n",
      " - 1s - loss: -5.0740e-01 - output_loss: -5.0745e-01 - variance_output_loss: -5.0745e-01 - output_mean_absolute_error: 0.3126 - output_mean_error: -4.6624e-02 - val_loss: -5.2231e-01 - val_output_loss: -5.2236e-01 - val_variance_output_loss: -5.2236e-01 - val_output_mean_absolute_error: 0.3122 - val_output_mean_error: -3.6513e-02\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 45/60\n",
      " - 1s - loss: -5.0443e-01 - output_loss: -5.0448e-01 - variance_output_loss: -5.0448e-01 - output_mean_absolute_error: 0.3157 - output_mean_error: -5.6487e-02 - val_loss: -5.0937e-01 - val_output_loss: -5.0942e-01 - val_variance_output_loss: -5.0942e-01 - val_output_mean_absolute_error: 0.2945 - val_output_mean_error: -7.8778e-03\n",
      "Epoch 46/60\n",
      " - 1s - loss: -4.9401e-01 - output_loss: -4.9405e-01 - variance_output_loss: -4.9405e-01 - output_mean_absolute_error: 0.3202 - output_mean_error: -6.1656e-02 - val_loss: -5.0086e-01 - val_output_loss: -5.0090e-01 - val_variance_output_loss: -5.0090e-01 - val_output_mean_absolute_error: 0.2982 - val_output_mean_error: 0.0047\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 47/60\n",
      " - 1s - loss: -4.9778e-01 - output_loss: -4.9783e-01 - variance_output_loss: -4.9783e-01 - output_mean_absolute_error: 0.3133 - output_mean_error: -4.7610e-02 - val_loss: -5.1586e-01 - val_output_loss: -5.1591e-01 - val_variance_output_loss: -5.1591e-01 - val_output_mean_absolute_error: 0.3034 - val_output_mean_error: -3.8256e-02\n",
      "Epoch 48/60\n",
      " - 1s - loss: -5.0118e-01 - output_loss: -5.0123e-01 - variance_output_loss: -5.0123e-01 - output_mean_absolute_error: 0.3108 - output_mean_error: -4.7081e-02 - val_loss: -4.9944e-01 - val_output_loss: -4.9949e-01 - val_variance_output_loss: -4.9949e-01 - val_output_mean_absolute_error: 0.3030 - val_output_mean_error: -2.4089e-02\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 49/60\n",
      " - 1s - loss: -4.8121e-01 - output_loss: -4.8126e-01 - variance_output_loss: -4.8126e-01 - output_mean_absolute_error: 0.3236 - output_mean_error: -5.4614e-02 - val_loss: -5.0913e-01 - val_output_loss: -5.0918e-01 - val_variance_output_loss: -5.0918e-01 - val_output_mean_absolute_error: 0.3025 - val_output_mean_error: -3.0631e-02\n",
      "Epoch 50/60\n",
      " - 1s - loss: -5.0957e-01 - output_loss: -5.0962e-01 - variance_output_loss: -5.0962e-01 - output_mean_absolute_error: 0.3113 - output_mean_error: -5.4415e-02 - val_loss: -5.2001e-01 - val_output_loss: -5.2006e-01 - val_variance_output_loss: -5.2006e-01 - val_output_mean_absolute_error: 0.3023 - val_output_mean_error: -2.8331e-02\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 51/60\n",
      " - 1s - loss: -4.9922e-01 - output_loss: -4.9927e-01 - variance_output_loss: -4.9927e-01 - output_mean_absolute_error: 0.3171 - output_mean_error: -5.8330e-02 - val_loss: -5.3667e-01 - val_output_loss: -5.3672e-01 - val_variance_output_loss: -5.3672e-01 - val_output_mean_absolute_error: 0.2887 - val_output_mean_error: -3.8947e-02\n",
      "Epoch 52/60\n",
      " - 1s - loss: -4.8920e-01 - output_loss: -4.8924e-01 - variance_output_loss: -4.8924e-01 - output_mean_absolute_error: 0.3175 - output_mean_error: -5.0056e-02 - val_loss: -5.1326e-01 - val_output_loss: -5.1331e-01 - val_variance_output_loss: -5.1331e-01 - val_output_mean_absolute_error: 0.3062 - val_output_mean_error: -2.3995e-02\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 53/60\n",
      " - 1s - loss: -5.0437e-01 - output_loss: -5.0442e-01 - variance_output_loss: -5.0442e-01 - output_mean_absolute_error: 0.3136 - output_mean_error: -5.7288e-02 - val_loss: -5.5612e-01 - val_output_loss: -5.5616e-01 - val_variance_output_loss: -5.5616e-01 - val_output_mean_absolute_error: 0.2842 - val_output_mean_error: -8.4786e-03\n",
      "Epoch 54/60\n",
      " - 1s - loss: -4.9956e-01 - output_loss: -4.9961e-01 - variance_output_loss: -4.9961e-01 - output_mean_absolute_error: 0.3166 - output_mean_error: -4.9170e-02 - val_loss: -5.3616e-01 - val_output_loss: -5.3621e-01 - val_variance_output_loss: -5.3621e-01 - val_output_mean_absolute_error: 0.2952 - val_output_mean_error: -2.8191e-02\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 55/60\n",
      " - 1s - loss: -4.9695e-01 - output_loss: -4.9700e-01 - variance_output_loss: -4.9700e-01 - output_mean_absolute_error: 0.3169 - output_mean_error: -5.5658e-02 - val_loss: -4.6742e-01 - val_output_loss: -4.6747e-01 - val_variance_output_loss: -4.6747e-01 - val_output_mean_absolute_error: 0.3099 - val_output_mean_error: -9.5522e-03\n",
      "Epoch 56/60\n",
      " - 1s - loss: -5.0825e-01 - output_loss: -5.0829e-01 - variance_output_loss: -5.0829e-01 - output_mean_absolute_error: 0.3092 - output_mean_error: -4.9394e-02 - val_loss: -5.2277e-01 - val_output_loss: -5.2282e-01 - val_variance_output_loss: -5.2282e-01 - val_output_mean_absolute_error: 0.2989 - val_output_mean_error: -3.2881e-02\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 57/60\n",
      " - 1s - loss: -4.9849e-01 - output_loss: -4.9853e-01 - variance_output_loss: -4.9853e-01 - output_mean_absolute_error: 0.3180 - output_mean_error: -5.5852e-02 - val_loss: -4.8574e-01 - val_output_loss: -4.8579e-01 - val_variance_output_loss: -4.8579e-01 - val_output_mean_absolute_error: 0.3074 - val_output_mean_error: -1.7344e-02\n",
      "Epoch 58/60\n",
      " - 1s - loss: -5.0945e-01 - output_loss: -5.0950e-01 - variance_output_loss: -5.0950e-01 - output_mean_absolute_error: 0.3115 - output_mean_error: -4.7934e-02 - val_loss: -4.9841e-01 - val_output_loss: -4.9846e-01 - val_variance_output_loss: -4.9846e-01 - val_output_mean_absolute_error: 0.3116 - val_output_mean_error: -2.9869e-02\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 59/60\n",
      " - 1s - loss: -4.9243e-01 - output_loss: -4.9248e-01 - variance_output_loss: -4.9248e-01 - output_mean_absolute_error: 0.3188 - output_mean_error: -5.5068e-02 - val_loss: -5.2097e-01 - val_output_loss: -5.2102e-01 - val_variance_output_loss: -5.2102e-01 - val_output_mean_absolute_error: 0.3036 - val_output_mean_error: -2.9526e-02\n",
      "Epoch 60/60\n",
      " - 1s - loss: -5.0795e-01 - output_loss: -5.0800e-01 - variance_output_loss: -5.0800e-01 - output_mean_absolute_error: 0.3122 - output_mean_error: -4.8119e-02 - val_loss: -4.8745e-01 - val_output_loss: -4.8750e-01 - val_variance_output_loss: -4.8750e-01 - val_output_mean_absolute_error: 0.3085 - val_output_mean_error: -2.2517e-02\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Completed Training, 44.04s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_fixed_3_125/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [192, 64, 32, 16, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_fixed_3_125'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/32), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 109.43s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 108.15s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 108.61s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 110.26s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 109.92s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 110.23s elapsed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Data</th>\n",
       "      <th>Scatter</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30067</td>\n",
       "      <td>0.172124</td>\n",
       "      <td>-0.017152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15033</td>\n",
       "      <td>0.186913</td>\n",
       "      <td>-0.017570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7516</td>\n",
       "      <td>0.193223</td>\n",
       "      <td>-0.018622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3758</td>\n",
       "      <td>0.205817</td>\n",
       "      <td>-0.023268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1879</td>\n",
       "      <td>0.245651</td>\n",
       "      <td>-0.001448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>939</td>\n",
       "      <td>0.309125</td>\n",
       "      <td>-0.007424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Data   Scatter      Bias\n",
       "0           30067  0.172124 -0.017152\n",
       "1           15033  0.186913 -0.017570\n",
       "2            7516  0.193223 -0.018622\n",
       "3            3758  0.205817 -0.023268\n",
       "4            1879  0.245651 -0.001448\n",
       "5             939  0.309125 -0.007424"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.stats import mad_std\n",
    "\n",
    "from astroNN.models import load_folder\n",
    "from astroNN.datasets import H5Loader\n",
    "\n",
    "loader = H5Loader('_highsnr_test')  # continuum normalized dataset\n",
    "loader.load_err = False\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y = loader.load()\n",
    "\n",
    "mae = []\n",
    "me = []\n",
    "\n",
    "net_100 = load_folder(\"astroNN_0617_run001\")  # this is the main model we used\n",
    "net_100_pred, err = net_100.test(x)\n",
    "residue = ((net_100_pred - y) / net_100.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_50 = load_folder(\"small_data_fixed_50\")\n",
    "net_50_pred, err = net_50.test(x)\n",
    "residue = ((net_50_pred - y) / net_50.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_25 = load_folder(\"small_data_fixed_25\")\n",
    "net_25_pred, err = net_25.test(x)\n",
    "residue = ((net_25_pred - y) / net_25.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_12_5 = load_folder(\"small_data_fixed_12_5\")\n",
    "net_12_5_pred, err = net_12_5.test(x)\n",
    "residue = ((net_12_5_pred - y) / net_12_5.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_6_25 = load_folder(\"small_data_fixed_6_25\")\n",
    "net_6_25_pred, err = net_6_25.test(x)\n",
    "residue = ((net_6_25_pred - y) / net_6_25.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_3_125 = load_folder(\"small_data_fixed_3_125\")\n",
    "net_3_125_pred, err = net_3_125.test(x)\n",
    "residue = ((net_3_125_pred - y) / net_3_125.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "\n",
    "d = {'Number of Data': [30067, 15033, 7516, 3758, 1879, 939], 'Scatter': mae, 'Bias': me}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 3758, Number of Validation Data: 417\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 8s - loss: 0.4236 - output_loss: 0.4236 - variance_output_loss: 0.4236 - output_mean_absolute_error: 0.6785 - output_mean_error: -1.4760e-02 - val_loss: 0.4453 - val_output_loss: 0.4453 - val_variance_output_loss: 0.4453 - val_output_mean_absolute_error: 0.6616 - val_output_mean_error: -3.9038e-02\n",
      "Epoch 2/60\n",
      " - 2s - loss: 0.2573 - output_loss: 0.2573 - variance_output_loss: 0.2573 - output_mean_absolute_error: 0.5753 - output_mean_error: -1.6956e-02 - val_loss: 0.3036 - val_output_loss: 0.3035 - val_variance_output_loss: 0.3035 - val_output_mean_absolute_error: 0.5714 - val_output_mean_error: -5.2652e-02\n",
      "Epoch 3/60\n",
      " - 2s - loss: 0.0661 - output_loss: 0.0661 - variance_output_loss: 0.0661 - output_mean_absolute_error: 0.4805 - output_mean_error: -3.6465e-02 - val_loss: -1.8735e-02 - val_output_loss: -1.8777e-02 - val_variance_output_loss: -1.8777e-02 - val_output_mean_absolute_error: 0.4463 - val_output_mean_error: -9.8173e-03\n",
      "Epoch 4/60\n",
      " - 2s - loss: -1.1983e-01 - output_loss: -1.1987e-01 - variance_output_loss: -1.1987e-01 - output_mean_absolute_error: 0.4176 - output_mean_error: -3.1422e-02 - val_loss: -1.9446e-01 - val_output_loss: -1.9450e-01 - val_variance_output_loss: -1.9450e-01 - val_output_mean_absolute_error: 0.3909 - val_output_mean_error: -3.6929e-02\n",
      "Epoch 5/60\n",
      " - 2s - loss: -2.5779e-01 - output_loss: -2.5784e-01 - variance_output_loss: -2.5784e-01 - output_mean_absolute_error: 0.3730 - output_mean_error: -2.4985e-02 - val_loss: -2.6392e-01 - val_output_loss: -2.6396e-01 - val_variance_output_loss: -2.6396e-01 - val_output_mean_absolute_error: 0.3715 - val_output_mean_error: -1.0476e-02\n",
      "Epoch 6/60\n",
      " - 2s - loss: -3.4683e-01 - output_loss: -3.4688e-01 - variance_output_loss: -3.4688e-01 - output_mean_absolute_error: 0.3438 - output_mean_error: -1.6033e-02 - val_loss: -3.5890e-01 - val_output_loss: -3.5894e-01 - val_variance_output_loss: -3.5894e-01 - val_output_mean_absolute_error: 0.3448 - val_output_mean_error: -2.2053e-02\n",
      "Epoch 7/60\n",
      " - 2s - loss: -4.0983e-01 - output_loss: -4.0987e-01 - variance_output_loss: -4.0987e-01 - output_mean_absolute_error: 0.3257 - output_mean_error: -1.0485e-02 - val_loss: -3.9688e-01 - val_output_loss: -3.9692e-01 - val_variance_output_loss: -3.9692e-01 - val_output_mean_absolute_error: 0.3256 - val_output_mean_error: 0.0183\n",
      "Epoch 8/60\n",
      " - 2s - loss: -4.7564e-01 - output_loss: -4.7569e-01 - variance_output_loss: -4.7569e-01 - output_mean_absolute_error: 0.3063 - output_mean_error: -7.5421e-03 - val_loss: -4.5254e-01 - val_output_loss: -4.5258e-01 - val_variance_output_loss: -4.5258e-01 - val_output_mean_absolute_error: 0.3066 - val_output_mean_error: -2.4418e-02\n",
      "Epoch 9/60\n",
      " - 2s - loss: -5.2774e-01 - output_loss: -5.2779e-01 - variance_output_loss: -5.2779e-01 - output_mean_absolute_error: 0.2926 - output_mean_error: -2.1982e-03 - val_loss: -5.1976e-01 - val_output_loss: -5.1980e-01 - val_variance_output_loss: -5.1980e-01 - val_output_mean_absolute_error: 0.2914 - val_output_mean_error: -3.2389e-02\n",
      "Epoch 10/60\n",
      " - 2s - loss: -5.6960e-01 - output_loss: -5.6964e-01 - variance_output_loss: -5.6964e-01 - output_mean_absolute_error: 0.2823 - output_mean_error: -5.4699e-03 - val_loss: -5.5291e-01 - val_output_loss: -5.5296e-01 - val_variance_output_loss: -5.5296e-01 - val_output_mean_absolute_error: 0.2886 - val_output_mean_error: 0.0068\n",
      "Epoch 11/60\n",
      " - 2s - loss: -6.0631e-01 - output_loss: -6.0635e-01 - variance_output_loss: -6.0635e-01 - output_mean_absolute_error: 0.2757 - output_mean_error: -6.5075e-03 - val_loss: -5.9401e-01 - val_output_loss: -5.9406e-01 - val_variance_output_loss: -5.9406e-01 - val_output_mean_absolute_error: 0.2735 - val_output_mean_error: -2.6530e-02\n",
      "Epoch 12/60\n",
      " - 2s - loss: -6.6139e-01 - output_loss: -6.6144e-01 - variance_output_loss: -6.6144e-01 - output_mean_absolute_error: 0.2587 - output_mean_error: -1.5148e-03 - val_loss: -6.5890e-01 - val_output_loss: -6.5894e-01 - val_variance_output_loss: -6.5894e-01 - val_output_mean_absolute_error: 0.2539 - val_output_mean_error: 0.0302\n",
      "Epoch 13/60\n",
      " - 2s - loss: -6.7226e-01 - output_loss: -6.7230e-01 - variance_output_loss: -6.7230e-01 - output_mean_absolute_error: 0.2584 - output_mean_error: -6.3171e-03 - val_loss: -6.7462e-01 - val_output_loss: -6.7466e-01 - val_variance_output_loss: -6.7466e-01 - val_output_mean_absolute_error: 0.2533 - val_output_mean_error: -4.5610e-03\n",
      "Epoch 14/60\n",
      " - 2s - loss: -7.3081e-01 - output_loss: -7.3085e-01 - variance_output_loss: -7.3085e-01 - output_mean_absolute_error: 0.2437 - output_mean_error: -3.8600e-03 - val_loss: -7.4072e-01 - val_output_loss: -7.4077e-01 - val_variance_output_loss: -7.4077e-01 - val_output_mean_absolute_error: 0.2450 - val_output_mean_error: 0.0094\n",
      "Epoch 15/60\n",
      " - 2s - loss: -7.4757e-01 - output_loss: -7.4762e-01 - variance_output_loss: -7.4762e-01 - output_mean_absolute_error: 0.2407 - output_mean_error: -3.7072e-03 - val_loss: -7.4395e-01 - val_output_loss: -7.4400e-01 - val_variance_output_loss: -7.4400e-01 - val_output_mean_absolute_error: 0.2465 - val_output_mean_error: -3.8350e-03\n",
      "Epoch 16/60\n",
      " - 2s - loss: -7.7461e-01 - output_loss: -7.7466e-01 - variance_output_loss: -7.7466e-01 - output_mean_absolute_error: 0.2349 - output_mean_error: -3.7171e-03 - val_loss: -7.7168e-01 - val_output_loss: -7.7173e-01 - val_variance_output_loss: -7.7173e-01 - val_output_mean_absolute_error: 0.2397 - val_output_mean_error: 0.0344\n",
      "Epoch 17/60\n",
      " - 2s - loss: -8.1689e-01 - output_loss: -8.1694e-01 - variance_output_loss: -8.1694e-01 - output_mean_absolute_error: 0.2261 - output_mean_error: -3.3233e-03 - val_loss: -8.1076e-01 - val_output_loss: -8.1081e-01 - val_variance_output_loss: -8.1081e-01 - val_output_mean_absolute_error: 0.2304 - val_output_mean_error: -2.3147e-02\n",
      "Epoch 18/60\n",
      " - 2s - loss: -8.4310e-01 - output_loss: -8.4315e-01 - variance_output_loss: -8.4315e-01 - output_mean_absolute_error: 0.2207 - output_mean_error: -4.7059e-03 - val_loss: -8.3760e-01 - val_output_loss: -8.3765e-01 - val_variance_output_loss: -8.3765e-01 - val_output_mean_absolute_error: 0.2233 - val_output_mean_error: 0.0284\n",
      "Epoch 19/60\n",
      " - 2s - loss: -8.4955e-01 - output_loss: -8.4959e-01 - variance_output_loss: -8.4959e-01 - output_mean_absolute_error: 0.2198 - output_mean_error: -3.8115e-03 - val_loss: -8.5447e-01 - val_output_loss: -8.5452e-01 - val_variance_output_loss: -8.5452e-01 - val_output_mean_absolute_error: 0.2223 - val_output_mean_error: 0.0111\n",
      "Epoch 20/60\n",
      " - 2s - loss: -8.7000e-01 - output_loss: -8.7005e-01 - variance_output_loss: -8.7005e-01 - output_mean_absolute_error: 0.2161 - output_mean_error: -4.8697e-03 - val_loss: -7.9866e-01 - val_output_loss: -7.9871e-01 - val_variance_output_loss: -7.9871e-01 - val_output_mean_absolute_error: 0.2309 - val_output_mean_error: 0.0510\n",
      "Epoch 21/60\n",
      " - 2s - loss: -9.0677e-01 - output_loss: -9.0682e-01 - variance_output_loss: -9.0682e-01 - output_mean_absolute_error: 0.2109 - output_mean_error: -6.8870e-03 - val_loss: -8.8812e-01 - val_output_loss: -8.8817e-01 - val_variance_output_loss: -8.8817e-01 - val_output_mean_absolute_error: 0.2203 - val_output_mean_error: 3.2572e-04\n",
      "Epoch 22/60\n",
      " - 2s - loss: -9.1206e-01 - output_loss: -9.1211e-01 - variance_output_loss: -9.1211e-01 - output_mean_absolute_error: 0.2078 - output_mean_error: -3.9809e-03 - val_loss: -8.9630e-01 - val_output_loss: -8.9635e-01 - val_variance_output_loss: -8.9635e-01 - val_output_mean_absolute_error: 0.2143 - val_output_mean_error: -3.7408e-02\n",
      "Epoch 23/60\n",
      " - 2s - loss: -9.3160e-01 - output_loss: -9.3165e-01 - variance_output_loss: -9.3165e-01 - output_mean_absolute_error: 0.2054 - output_mean_error: -4.6324e-03 - val_loss: -9.0809e-01 - val_output_loss: -9.0814e-01 - val_variance_output_loss: -9.0814e-01 - val_output_mean_absolute_error: 0.2071 - val_output_mean_error: -2.4054e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      " - 2s - loss: -9.4908e-01 - output_loss: -9.4913e-01 - variance_output_loss: -9.4913e-01 - output_mean_absolute_error: 0.2031 - output_mean_error: -8.0418e-03 - val_loss: -9.5041e-01 - val_output_loss: -9.5046e-01 - val_variance_output_loss: -9.5046e-01 - val_output_mean_absolute_error: 0.2018 - val_output_mean_error: 0.0127\n",
      "Epoch 25/60\n",
      " - 2s - loss: -9.5957e-01 - output_loss: -9.5962e-01 - variance_output_loss: -9.5962e-01 - output_mean_absolute_error: 0.2000 - output_mean_error: -4.1495e-03 - val_loss: -9.8065e-01 - val_output_loss: -9.8070e-01 - val_variance_output_loss: -9.8070e-01 - val_output_mean_absolute_error: 0.1983 - val_output_mean_error: -1.7390e-02\n",
      "Epoch 26/60\n",
      " - 2s - loss: -9.7411e-01 - output_loss: -9.7416e-01 - variance_output_loss: -9.7416e-01 - output_mean_absolute_error: 0.1983 - output_mean_error: -6.1365e-03 - val_loss: -9.6121e-01 - val_output_loss: -9.6126e-01 - val_variance_output_loss: -9.6126e-01 - val_output_mean_absolute_error: 0.2073 - val_output_mean_error: -1.8828e-02\n",
      "Epoch 27/60\n",
      " - 2s - loss: -1.0020e+00 - output_loss: -1.0020e+00 - variance_output_loss: -1.0020e+00 - output_mean_absolute_error: 0.1927 - output_mean_error: -7.4363e-03 - val_loss: -9.7236e-01 - val_output_loss: -9.7242e-01 - val_variance_output_loss: -9.7242e-01 - val_output_mean_absolute_error: 0.2044 - val_output_mean_error: -3.7447e-02\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 28/60\n",
      " - 2s - loss: -1.0129e+00 - output_loss: -1.0129e+00 - variance_output_loss: -1.0129e+00 - output_mean_absolute_error: 0.1941 - output_mean_error: -7.0517e-03 - val_loss: -9.6675e-01 - val_output_loss: -9.6680e-01 - val_variance_output_loss: -9.6680e-01 - val_output_mean_absolute_error: 0.2045 - val_output_mean_error: -2.5008e-02\n",
      "Epoch 29/60\n",
      " - 2s - loss: -1.0184e+00 - output_loss: -1.0184e+00 - variance_output_loss: -1.0184e+00 - output_mean_absolute_error: 0.1892 - output_mean_error: -7.9417e-03 - val_loss: -9.7640e-01 - val_output_loss: -9.7645e-01 - val_variance_output_loss: -9.7645e-01 - val_output_mean_absolute_error: 0.2026 - val_output_mean_error: -2.1046e-03\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 30/60\n",
      " - 2s - loss: -1.0313e+00 - output_loss: -1.0313e+00 - variance_output_loss: -1.0313e+00 - output_mean_absolute_error: 0.1886 - output_mean_error: -4.2649e-03 - val_loss: -1.0070e+00 - val_output_loss: -1.0070e+00 - val_variance_output_loss: -1.0070e+00 - val_output_mean_absolute_error: 0.1967 - val_output_mean_error: -6.5931e-03\n",
      "Epoch 31/60\n",
      " - 2s - loss: -1.0367e+00 - output_loss: -1.0368e+00 - variance_output_loss: -1.0368e+00 - output_mean_absolute_error: 0.1903 - output_mean_error: -7.8731e-03 - val_loss: -9.8648e-01 - val_output_loss: -9.8654e-01 - val_variance_output_loss: -9.8654e-01 - val_output_mean_absolute_error: 0.2057 - val_output_mean_error: -1.4492e-02\n",
      "Epoch 32/60\n",
      " - 2s - loss: -1.0569e+00 - output_loss: -1.0569e+00 - variance_output_loss: -1.0569e+00 - output_mean_absolute_error: 0.1835 - output_mean_error: -5.5500e-03 - val_loss: -1.0173e+00 - val_output_loss: -1.0173e+00 - val_variance_output_loss: -1.0173e+00 - val_output_mean_absolute_error: 0.1963 - val_output_mean_error: -3.3330e-03\n",
      "Epoch 33/60\n",
      " - 2s - loss: -1.0453e+00 - output_loss: -1.0453e+00 - variance_output_loss: -1.0453e+00 - output_mean_absolute_error: 0.1884 - output_mean_error: -6.6844e-03 - val_loss: -9.8776e-01 - val_output_loss: -9.8781e-01 - val_variance_output_loss: -9.8781e-01 - val_output_mean_absolute_error: 0.1965 - val_output_mean_error: 0.0186\n",
      "Epoch 34/60\n",
      " - 2s - loss: -1.0467e+00 - output_loss: -1.0468e+00 - variance_output_loss: -1.0468e+00 - output_mean_absolute_error: 0.1871 - output_mean_error: -6.0077e-03 - val_loss: -1.0211e+00 - val_output_loss: -1.0211e+00 - val_variance_output_loss: -1.0211e+00 - val_output_mean_absolute_error: 0.1914 - val_output_mean_error: 0.0036\n",
      "Epoch 35/60\n",
      " - 2s - loss: -1.0458e+00 - output_loss: -1.0459e+00 - variance_output_loss: -1.0459e+00 - output_mean_absolute_error: 0.1870 - output_mean_error: -4.8526e-03 - val_loss: -1.0200e+00 - val_output_loss: -1.0200e+00 - val_variance_output_loss: -1.0200e+00 - val_output_mean_absolute_error: 0.1882 - val_output_mean_error: -1.9904e-02\n",
      "Epoch 36/60\n",
      " - 2s - loss: -1.0517e+00 - output_loss: -1.0517e+00 - variance_output_loss: -1.0517e+00 - output_mean_absolute_error: 0.1863 - output_mean_error: -6.2428e-03 - val_loss: -1.0178e+00 - val_output_loss: -1.0179e+00 - val_variance_output_loss: -1.0179e+00 - val_output_mean_absolute_error: 0.1960 - val_output_mean_error: -1.8156e-02\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 37/60\n",
      " - 2s - loss: -1.0590e+00 - output_loss: -1.0590e+00 - variance_output_loss: -1.0590e+00 - output_mean_absolute_error: 0.1840 - output_mean_error: -6.7760e-03 - val_loss: -1.0305e+00 - val_output_loss: -1.0305e+00 - val_variance_output_loss: -1.0305e+00 - val_output_mean_absolute_error: 0.1940 - val_output_mean_error: 0.0082\n",
      "Epoch 38/60\n",
      " - 2s - loss: -1.0594e+00 - output_loss: -1.0594e+00 - variance_output_loss: -1.0594e+00 - output_mean_absolute_error: 0.1851 - output_mean_error: -6.8744e-03 - val_loss: -9.7581e-01 - val_output_loss: -9.7586e-01 - val_variance_output_loss: -9.7586e-01 - val_output_mean_absolute_error: 0.2071 - val_output_mean_error: -1.2459e-02\n",
      "Epoch 39/60\n",
      " - 2s - loss: -1.0611e+00 - output_loss: -1.0612e+00 - variance_output_loss: -1.0612e+00 - output_mean_absolute_error: 0.1847 - output_mean_error: -5.0437e-03 - val_loss: -9.9699e-01 - val_output_loss: -9.9704e-01 - val_variance_output_loss: -9.9704e-01 - val_output_mean_absolute_error: 0.2030 - val_output_mean_error: -1.9508e-02\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 40/60\n",
      " - 2s - loss: -1.0644e+00 - output_loss: -1.0645e+00 - variance_output_loss: -1.0645e+00 - output_mean_absolute_error: 0.1834 - output_mean_error: -5.8806e-03 - val_loss: -1.0321e+00 - val_output_loss: -1.0321e+00 - val_variance_output_loss: -1.0321e+00 - val_output_mean_absolute_error: 0.2008 - val_output_mean_error: -1.3966e-02\n",
      "Epoch 41/60\n",
      " - 2s - loss: -1.0635e+00 - output_loss: -1.0636e+00 - variance_output_loss: -1.0636e+00 - output_mean_absolute_error: 0.1840 - output_mean_error: -7.0277e-03 - val_loss: -1.0077e+00 - val_output_loss: -1.0077e+00 - val_variance_output_loss: -1.0077e+00 - val_output_mean_absolute_error: 0.1930 - val_output_mean_error: -1.4442e-02\n",
      "Epoch 42/60\n",
      " - 2s - loss: -1.0702e+00 - output_loss: -1.0702e+00 - variance_output_loss: -1.0702e+00 - output_mean_absolute_error: 0.1830 - output_mean_error: -3.6145e-03 - val_loss: -1.0088e+00 - val_output_loss: -1.0088e+00 - val_variance_output_loss: -1.0088e+00 - val_output_mean_absolute_error: 0.1950 - val_output_mean_error: -1.1660e-02\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 43/60\n",
      " - 2s - loss: -1.0668e+00 - output_loss: -1.0669e+00 - variance_output_loss: -1.0669e+00 - output_mean_absolute_error: 0.1847 - output_mean_error: -8.4474e-03 - val_loss: -1.0424e+00 - val_output_loss: -1.0424e+00 - val_variance_output_loss: -1.0424e+00 - val_output_mean_absolute_error: 0.1866 - val_output_mean_error: -2.2814e-02\n",
      "Epoch 44/60\n",
      " - 2s - loss: -1.0687e+00 - output_loss: -1.0687e+00 - variance_output_loss: -1.0687e+00 - output_mean_absolute_error: 0.1834 - output_mean_error: -9.3813e-03 - val_loss: -1.0190e+00 - val_output_loss: -1.0190e+00 - val_variance_output_loss: -1.0190e+00 - val_output_mean_absolute_error: 0.1938 - val_output_mean_error: -1.5113e-02\n",
      "Epoch 45/60\n",
      " - 2s - loss: -1.0702e+00 - output_loss: -1.0703e+00 - variance_output_loss: -1.0703e+00 - output_mean_absolute_error: 0.1828 - output_mean_error: -4.4657e-03 - val_loss: -1.0404e+00 - val_output_loss: -1.0404e+00 - val_variance_output_loss: -1.0404e+00 - val_output_mean_absolute_error: 0.1879 - val_output_mean_error: 9.7810e-04\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 46/60\n",
      " - 2s - loss: -1.0818e+00 - output_loss: -1.0819e+00 - variance_output_loss: -1.0819e+00 - output_mean_absolute_error: 0.1807 - output_mean_error: -5.7402e-03 - val_loss: -1.0384e+00 - val_output_loss: -1.0385e+00 - val_variance_output_loss: -1.0385e+00 - val_output_mean_absolute_error: 0.1883 - val_output_mean_error: -1.4915e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      " - 2s - loss: -1.0760e+00 - output_loss: -1.0761e+00 - variance_output_loss: -1.0761e+00 - output_mean_absolute_error: 0.1811 - output_mean_error: -5.3630e-03 - val_loss: -1.0147e+00 - val_output_loss: -1.0148e+00 - val_variance_output_loss: -1.0148e+00 - val_output_mean_absolute_error: 0.1966 - val_output_mean_error: -1.0728e-02\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 48/60\n",
      " - 2s - loss: -1.0688e+00 - output_loss: -1.0689e+00 - variance_output_loss: -1.0689e+00 - output_mean_absolute_error: 0.1851 - output_mean_error: -7.8469e-03 - val_loss: -1.0242e+00 - val_output_loss: -1.0243e+00 - val_variance_output_loss: -1.0243e+00 - val_output_mean_absolute_error: 0.1959 - val_output_mean_error: -3.7583e-03\n",
      "Epoch 49/60\n",
      " - 2s - loss: -1.0746e+00 - output_loss: -1.0746e+00 - variance_output_loss: -1.0746e+00 - output_mean_absolute_error: 0.1817 - output_mean_error: -5.4842e-03 - val_loss: -1.0322e+00 - val_output_loss: -1.0323e+00 - val_variance_output_loss: -1.0323e+00 - val_output_mean_absolute_error: 0.1930 - val_output_mean_error: 0.0017\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 50/60\n",
      " - 2s - loss: -1.0695e+00 - output_loss: -1.0695e+00 - variance_output_loss: -1.0695e+00 - output_mean_absolute_error: 0.1846 - output_mean_error: -5.9361e-03 - val_loss: -1.0048e+00 - val_output_loss: -1.0049e+00 - val_variance_output_loss: -1.0049e+00 - val_output_mean_absolute_error: 0.1991 - val_output_mean_error: -1.8504e-02\n",
      "Epoch 51/60\n",
      " - 2s - loss: -1.0724e+00 - output_loss: -1.0724e+00 - variance_output_loss: -1.0724e+00 - output_mean_absolute_error: 0.1838 - output_mean_error: -4.7480e-03 - val_loss: -1.0143e+00 - val_output_loss: -1.0144e+00 - val_variance_output_loss: -1.0144e+00 - val_output_mean_absolute_error: 0.1920 - val_output_mean_error: 0.0011\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 52/60\n",
      " - 2s - loss: -1.0777e+00 - output_loss: -1.0778e+00 - variance_output_loss: -1.0778e+00 - output_mean_absolute_error: 0.1825 - output_mean_error: -5.6945e-03 - val_loss: -1.0303e+00 - val_output_loss: -1.0304e+00 - val_variance_output_loss: -1.0304e+00 - val_output_mean_absolute_error: 0.1975 - val_output_mean_error: -1.5560e-02\n",
      "Epoch 53/60\n",
      " - 2s - loss: -1.0790e+00 - output_loss: -1.0791e+00 - variance_output_loss: -1.0791e+00 - output_mean_absolute_error: 0.1825 - output_mean_error: -3.5988e-03 - val_loss: -1.0187e+00 - val_output_loss: -1.0188e+00 - val_variance_output_loss: -1.0188e+00 - val_output_mean_absolute_error: 0.1948 - val_output_mean_error: -1.1391e-02\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 54/60\n",
      " - 2s - loss: -1.0765e+00 - output_loss: -1.0765e+00 - variance_output_loss: -1.0765e+00 - output_mean_absolute_error: 0.1833 - output_mean_error: -5.4363e-03 - val_loss: -1.0248e+00 - val_output_loss: -1.0249e+00 - val_variance_output_loss: -1.0249e+00 - val_output_mean_absolute_error: 0.1895 - val_output_mean_error: -2.2066e-02\n",
      "Epoch 55/60\n",
      " - 2s - loss: -1.0570e+00 - output_loss: -1.0571e+00 - variance_output_loss: -1.0571e+00 - output_mean_absolute_error: 0.1857 - output_mean_error: -4.9391e-03 - val_loss: -1.0133e+00 - val_output_loss: -1.0134e+00 - val_variance_output_loss: -1.0134e+00 - val_output_mean_absolute_error: 0.2008 - val_output_mean_error: -1.8775e-02\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 56/60\n",
      " - 2s - loss: -1.0693e+00 - output_loss: -1.0694e+00 - variance_output_loss: -1.0694e+00 - output_mean_absolute_error: 0.1844 - output_mean_error: -4.8852e-03 - val_loss: -1.0430e+00 - val_output_loss: -1.0431e+00 - val_variance_output_loss: -1.0431e+00 - val_output_mean_absolute_error: 0.1919 - val_output_mean_error: -1.4493e-02\n",
      "Epoch 57/60\n",
      " - 2s - loss: -1.0738e+00 - output_loss: -1.0738e+00 - variance_output_loss: -1.0738e+00 - output_mean_absolute_error: 0.1824 - output_mean_error: -8.3044e-03 - val_loss: -1.0094e+00 - val_output_loss: -1.0095e+00 - val_variance_output_loss: -1.0095e+00 - val_output_mean_absolute_error: 0.2035 - val_output_mean_error: -2.7400e-02\n",
      "Epoch 58/60\n",
      " - 2s - loss: -1.0678e+00 - output_loss: -1.0678e+00 - variance_output_loss: -1.0678e+00 - output_mean_absolute_error: 0.1852 - output_mean_error: -5.8403e-03 - val_loss: -1.0507e+00 - val_output_loss: -1.0507e+00 - val_variance_output_loss: -1.0507e+00 - val_output_mean_absolute_error: 0.1794 - val_output_mean_error: -2.1597e-04\n",
      "Epoch 59/60\n",
      " - 2s - loss: -1.0645e+00 - output_loss: -1.0645e+00 - variance_output_loss: -1.0645e+00 - output_mean_absolute_error: 0.1843 - output_mean_error: -6.7344e-03 - val_loss: -1.0462e+00 - val_output_loss: -1.0462e+00 - val_variance_output_loss: -1.0462e+00 - val_output_mean_absolute_error: 0.1823 - val_output_mean_error: -9.0949e-03\n",
      "Epoch 60/60\n",
      " - 2s - loss: -1.0745e+00 - output_loss: -1.0746e+00 - variance_output_loss: -1.0746e+00 - output_mean_absolute_error: 0.1831 - output_mean_error: -4.0843e-03 - val_loss: -1.0098e+00 - val_output_loss: -1.0099e+00 - val_variance_output_loss: -1.0099e+00 - val_output_mean_absolute_error: 0.1970 - val_output_mean_error: -2.4402e-02\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Completed Training, 145.96s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_adaptive_12_5/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [160, 48, 32, 16, 2]  # reduced size\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_adaptive_12_5'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/8), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 1879, Number of Validation Data: 208\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 7s - loss: 0.4419 - output_loss: 0.4419 - variance_output_loss: 0.4419 - output_mean_absolute_error: 0.6829 - output_mean_error: 0.0184 - val_loss: 0.5748 - val_output_loss: 0.5748 - val_variance_output_loss: 0.5748 - val_output_mean_absolute_error: 0.7303 - val_output_mean_error: -6.5581e-02\n",
      "Epoch 2/60\n",
      " - 1s - loss: 0.4348 - output_loss: 0.4348 - variance_output_loss: 0.4348 - output_mean_absolute_error: 0.6590 - output_mean_error: -1.2866e-02 - val_loss: 0.6000 - val_output_loss: 0.6000 - val_variance_output_loss: 0.6000 - val_output_mean_absolute_error: 0.7598 - val_output_mean_error: -1.1669e-01\n",
      "Epoch 3/60\n",
      " - 1s - loss: 0.4255 - output_loss: 0.4255 - variance_output_loss: 0.4255 - output_mean_absolute_error: 0.6563 - output_mean_error: -1.0410e-02 - val_loss: 0.4040 - val_output_loss: 0.4039 - val_variance_output_loss: 0.4039 - val_output_mean_absolute_error: 0.6566 - val_output_mean_error: -1.9903e-02\n",
      "Epoch 4/60\n",
      " - 1s - loss: 0.2716 - output_loss: 0.2716 - variance_output_loss: 0.2716 - output_mean_absolute_error: 0.5894 - output_mean_error: -1.6161e-02 - val_loss: 0.3226 - val_output_loss: 0.3226 - val_variance_output_loss: 0.3226 - val_output_mean_absolute_error: 0.6144 - val_output_mean_error: -7.0527e-02\n",
      "Epoch 5/60\n",
      " - 1s - loss: 0.2008 - output_loss: 0.2007 - variance_output_loss: 0.2007 - output_mean_absolute_error: 0.5549 - output_mean_error: -2.1611e-02 - val_loss: 0.2197 - val_output_loss: 0.2197 - val_variance_output_loss: 0.2197 - val_output_mean_absolute_error: 0.5685 - val_output_mean_error: -4.8202e-02\n",
      "Epoch 6/60\n",
      " - 1s - loss: 0.0902 - output_loss: 0.0902 - variance_output_loss: 0.0902 - output_mean_absolute_error: 0.5044 - output_mean_error: -1.9918e-02 - val_loss: 0.0927 - val_output_loss: 0.0927 - val_variance_output_loss: 0.0927 - val_output_mean_absolute_error: 0.5090 - val_output_mean_error: -2.2215e-02\n",
      "Epoch 7/60\n",
      " - 1s - loss: 0.0092 - output_loss: 0.0092 - variance_output_loss: 0.0092 - output_mean_absolute_error: 0.4694 - output_mean_error: -3.9647e-02 - val_loss: 0.0808 - val_output_loss: 0.0807 - val_variance_output_loss: 0.0807 - val_output_mean_absolute_error: 0.5164 - val_output_mean_error: -5.5713e-02\n",
      "Epoch 8/60\n",
      " - 1s - loss: -6.9044e-02 - output_loss: -6.9077e-02 - variance_output_loss: -6.9077e-02 - output_mean_absolute_error: 0.4361 - output_mean_error: -3.8736e-02 - val_loss: 0.0253 - val_output_loss: 0.0253 - val_variance_output_loss: 0.0253 - val_output_mean_absolute_error: 0.5131 - val_output_mean_error: -1.2846e-01\n",
      "Epoch 9/60\n",
      " - 1s - loss: -1.5789e-01 - output_loss: -1.5792e-01 - variance_output_loss: -1.5792e-01 - output_mean_absolute_error: 0.3967 - output_mean_error: -3.4859e-02 - val_loss: -1.3946e-01 - val_output_loss: -1.3950e-01 - val_variance_output_loss: -1.3950e-01 - val_output_mean_absolute_error: 0.4216 - val_output_mean_error: -8.3807e-02\n",
      "Epoch 10/60\n",
      " - 1s - loss: -2.2676e-01 - output_loss: -2.2679e-01 - variance_output_loss: -2.2679e-01 - output_mean_absolute_error: 0.3782 - output_mean_error: -3.9316e-02 - val_loss: -1.8583e-01 - val_output_loss: -1.8587e-01 - val_variance_output_loss: -1.8587e-01 - val_output_mean_absolute_error: 0.3987 - val_output_mean_error: -6.6885e-02\n",
      "Epoch 11/60\n",
      " - 1s - loss: -2.5274e-01 - output_loss: -2.5278e-01 - variance_output_loss: -2.5278e-01 - output_mean_absolute_error: 0.3738 - output_mean_error: -5.4577e-02 - val_loss: -2.6916e-01 - val_output_loss: -2.6919e-01 - val_variance_output_loss: -2.6919e-01 - val_output_mean_absolute_error: 0.3730 - val_output_mean_error: -3.3788e-02\n",
      "Epoch 12/60\n",
      " - 1s - loss: -3.3930e-01 - output_loss: -3.3934e-01 - variance_output_loss: -3.3934e-01 - output_mean_absolute_error: 0.3429 - output_mean_error: -3.0454e-02 - val_loss: -2.5830e-01 - val_output_loss: -2.5834e-01 - val_variance_output_loss: -2.5834e-01 - val_output_mean_absolute_error: 0.3731 - val_output_mean_error: -1.4189e-02\n",
      "Epoch 13/60\n",
      " - 1s - loss: -3.5146e-01 - output_loss: -3.5149e-01 - variance_output_loss: -3.5149e-01 - output_mean_absolute_error: 0.3446 - output_mean_error: -4.6633e-02 - val_loss: -3.2221e-01 - val_output_loss: -3.2225e-01 - val_variance_output_loss: -3.2225e-01 - val_output_mean_absolute_error: 0.3691 - val_output_mean_error: -8.4789e-02\n",
      "Epoch 14/60\n",
      " - 1s - loss: -3.9589e-01 - output_loss: -3.9593e-01 - variance_output_loss: -3.9593e-01 - output_mean_absolute_error: 0.3328 - output_mean_error: -4.1000e-02 - val_loss: -3.4804e-01 - val_output_loss: -3.4808e-01 - val_variance_output_loss: -3.4808e-01 - val_output_mean_absolute_error: 0.3511 - val_output_mean_error: -9.7375e-02\n",
      "Epoch 15/60\n",
      " - 1s - loss: -4.2484e-01 - output_loss: -4.2487e-01 - variance_output_loss: -4.2487e-01 - output_mean_absolute_error: 0.3220 - output_mean_error: -4.3515e-02 - val_loss: -3.5130e-01 - val_output_loss: -3.5134e-01 - val_variance_output_loss: -3.5134e-01 - val_output_mean_absolute_error: 0.3554 - val_output_mean_error: -6.6348e-02\n",
      "Epoch 16/60\n",
      " - 1s - loss: -4.7062e-01 - output_loss: -4.7066e-01 - variance_output_loss: -4.7066e-01 - output_mean_absolute_error: 0.3103 - output_mean_error: -4.5811e-02 - val_loss: -4.3612e-01 - val_output_loss: -4.3616e-01 - val_variance_output_loss: -4.3616e-01 - val_output_mean_absolute_error: 0.3229 - val_output_mean_error: -5.0163e-02\n",
      "Epoch 17/60\n",
      " - 1s - loss: -4.7652e-01 - output_loss: -4.7656e-01 - variance_output_loss: -4.7656e-01 - output_mean_absolute_error: 0.3115 - output_mean_error: -4.5380e-02 - val_loss: -4.5304e-01 - val_output_loss: -4.5308e-01 - val_variance_output_loss: -4.5308e-01 - val_output_mean_absolute_error: 0.3193 - val_output_mean_error: -3.9451e-02\n",
      "Epoch 18/60\n",
      " - 1s - loss: -4.9698e-01 - output_loss: -4.9702e-01 - variance_output_loss: -4.9702e-01 - output_mean_absolute_error: 0.3022 - output_mean_error: -4.3623e-02 - val_loss: -5.4620e-01 - val_output_loss: -5.4624e-01 - val_variance_output_loss: -5.4624e-01 - val_output_mean_absolute_error: 0.2952 - val_output_mean_error: -7.2464e-02\n",
      "Epoch 19/60\n",
      " - 1s - loss: -5.2812e-01 - output_loss: -5.2815e-01 - variance_output_loss: -5.2815e-01 - output_mean_absolute_error: 0.2946 - output_mean_error: -3.9589e-02 - val_loss: -4.8046e-01 - val_output_loss: -4.8050e-01 - val_variance_output_loss: -4.8050e-01 - val_output_mean_absolute_error: 0.3204 - val_output_mean_error: -8.3050e-02\n",
      "Epoch 20/60\n",
      " - 1s - loss: -5.4005e-01 - output_loss: -5.4009e-01 - variance_output_loss: -5.4009e-01 - output_mean_absolute_error: 0.2935 - output_mean_error: -4.6693e-02 - val_loss: -5.4248e-01 - val_output_loss: -5.4251e-01 - val_variance_output_loss: -5.4251e-01 - val_output_mean_absolute_error: 0.2996 - val_output_mean_error: -7.0579e-02\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 21/60\n",
      " - 1s - loss: -5.6359e-01 - output_loss: -5.6362e-01 - variance_output_loss: -5.6362e-01 - output_mean_absolute_error: 0.2911 - output_mean_error: -5.0466e-02 - val_loss: -5.5487e-01 - val_output_loss: -5.5490e-01 - val_variance_output_loss: -5.5490e-01 - val_output_mean_absolute_error: 0.2979 - val_output_mean_error: -5.8315e-02\n",
      "Epoch 22/60\n",
      " - 1s - loss: -5.9380e-01 - output_loss: -5.9384e-01 - variance_output_loss: -5.9384e-01 - output_mean_absolute_error: 0.2812 - output_mean_error: -4.6592e-02 - val_loss: -5.7216e-01 - val_output_loss: -5.7220e-01 - val_variance_output_loss: -5.7220e-01 - val_output_mean_absolute_error: 0.2862 - val_output_mean_error: -3.1567e-02\n",
      "Epoch 23/60\n",
      " - 1s - loss: -5.9068e-01 - output_loss: -5.9072e-01 - variance_output_loss: -5.9072e-01 - output_mean_absolute_error: 0.2831 - output_mean_error: -4.6690e-02 - val_loss: -5.7360e-01 - val_output_loss: -5.7364e-01 - val_variance_output_loss: -5.7364e-01 - val_output_mean_absolute_error: 0.2945 - val_output_mean_error: -7.7808e-02\n",
      "Epoch 24/60\n",
      " - 1s - loss: -6.1886e-01 - output_loss: -6.1890e-01 - variance_output_loss: -6.1890e-01 - output_mean_absolute_error: 0.2753 - output_mean_error: -4.7970e-02 - val_loss: -5.8481e-01 - val_output_loss: -5.8484e-01 - val_variance_output_loss: -5.8484e-01 - val_output_mean_absolute_error: 0.2912 - val_output_mean_error: -6.0367e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      " - 1s - loss: -6.1999e-01 - output_loss: -6.2002e-01 - variance_output_loss: -6.2002e-01 - output_mean_absolute_error: 0.2770 - output_mean_error: -4.7253e-02 - val_loss: -5.7606e-01 - val_output_loss: -5.7610e-01 - val_variance_output_loss: -5.7610e-01 - val_output_mean_absolute_error: 0.2799 - val_output_mean_error: -1.5074e-02\n",
      "Epoch 26/60\n",
      " - 1s - loss: -6.4233e-01 - output_loss: -6.4237e-01 - variance_output_loss: -6.4237e-01 - output_mean_absolute_error: 0.2702 - output_mean_error: -4.9055e-02 - val_loss: -5.9083e-01 - val_output_loss: -5.9087e-01 - val_variance_output_loss: -5.9087e-01 - val_output_mean_absolute_error: 0.2864 - val_output_mean_error: -6.1571e-02\n",
      "Epoch 27/60\n",
      " - 1s - loss: -6.3771e-01 - output_loss: -6.3774e-01 - variance_output_loss: -6.3774e-01 - output_mean_absolute_error: 0.2727 - output_mean_error: -4.5161e-02 - val_loss: -5.5470e-01 - val_output_loss: -5.5474e-01 - val_variance_output_loss: -5.5474e-01 - val_output_mean_absolute_error: 0.2904 - val_output_mean_error: -8.3731e-02\n",
      "Epoch 28/60\n",
      " - 1s - loss: -6.5524e-01 - output_loss: -6.5527e-01 - variance_output_loss: -6.5527e-01 - output_mean_absolute_error: 0.2685 - output_mean_error: -5.1841e-02 - val_loss: -6.2623e-01 - val_output_loss: -6.2627e-01 - val_variance_output_loss: -6.2627e-01 - val_output_mean_absolute_error: 0.2747 - val_output_mean_error: -3.2007e-02\n",
      "Epoch 29/60\n",
      " - 1s - loss: -6.6836e-01 - output_loss: -6.6839e-01 - variance_output_loss: -6.6839e-01 - output_mean_absolute_error: 0.2671 - output_mean_error: -5.1056e-02 - val_loss: -6.3817e-01 - val_output_loss: -6.3820e-01 - val_variance_output_loss: -6.3820e-01 - val_output_mean_absolute_error: 0.2742 - val_output_mean_error: -4.6757e-02\n",
      "Epoch 30/60\n",
      " - 1s - loss: -6.7357e-01 - output_loss: -6.7361e-01 - variance_output_loss: -6.7361e-01 - output_mean_absolute_error: 0.2625 - output_mean_error: -4.1177e-02 - val_loss: -5.8641e-01 - val_output_loss: -5.8644e-01 - val_variance_output_loss: -5.8644e-01 - val_output_mean_absolute_error: 0.2869 - val_output_mean_error: -6.1830e-02\n",
      "Epoch 31/60\n",
      " - 1s - loss: -6.7191e-01 - output_loss: -6.7195e-01 - variance_output_loss: -6.7195e-01 - output_mean_absolute_error: 0.2649 - output_mean_error: -4.6891e-02 - val_loss: -6.1020e-01 - val_output_loss: -6.1024e-01 - val_variance_output_loss: -6.1024e-01 - val_output_mean_absolute_error: 0.2859 - val_output_mean_error: -4.5396e-02\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 32/60\n",
      " - 1s - loss: -6.7710e-01 - output_loss: -6.7713e-01 - variance_output_loss: -6.7713e-01 - output_mean_absolute_error: 0.2634 - output_mean_error: -4.8855e-02 - val_loss: -6.6557e-01 - val_output_loss: -6.6561e-01 - val_variance_output_loss: -6.6561e-01 - val_output_mean_absolute_error: 0.2701 - val_output_mean_error: -6.7951e-02\n",
      "Epoch 33/60\n",
      " - 1s - loss: -6.8976e-01 - output_loss: -6.8980e-01 - variance_output_loss: -6.8980e-01 - output_mean_absolute_error: 0.2563 - output_mean_error: -4.2479e-02 - val_loss: -6.4562e-01 - val_output_loss: -6.4566e-01 - val_variance_output_loss: -6.4566e-01 - val_output_mean_absolute_error: 0.2714 - val_output_mean_error: -6.1143e-02\n",
      "Epoch 34/60\n",
      " - 1s - loss: -7.0055e-01 - output_loss: -7.0059e-01 - variance_output_loss: -7.0059e-01 - output_mean_absolute_error: 0.2604 - output_mean_error: -4.9759e-02 - val_loss: -6.4239e-01 - val_output_loss: -6.4243e-01 - val_variance_output_loss: -6.4243e-01 - val_output_mean_absolute_error: 0.2760 - val_output_mean_error: -6.5576e-02\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 35/60\n",
      " - 1s - loss: -6.9963e-01 - output_loss: -6.9967e-01 - variance_output_loss: -6.9967e-01 - output_mean_absolute_error: 0.2592 - output_mean_error: -5.0124e-02 - val_loss: -6.5920e-01 - val_output_loss: -6.5923e-01 - val_variance_output_loss: -6.5923e-01 - val_output_mean_absolute_error: 0.2676 - val_output_mean_error: -5.6165e-02\n",
      "Epoch 36/60\n",
      " - 1s - loss: -6.9475e-01 - output_loss: -6.9479e-01 - variance_output_loss: -6.9479e-01 - output_mean_absolute_error: 0.2610 - output_mean_error: -4.9005e-02 - val_loss: -6.7184e-01 - val_output_loss: -6.7187e-01 - val_variance_output_loss: -6.7187e-01 - val_output_mean_absolute_error: 0.2658 - val_output_mean_error: -5.5591e-02\n",
      "Epoch 37/60\n",
      " - 1s - loss: -7.1592e-01 - output_loss: -7.1596e-01 - variance_output_loss: -7.1596e-01 - output_mean_absolute_error: 0.2548 - output_mean_error: -4.5856e-02 - val_loss: -6.0038e-01 - val_output_loss: -6.0042e-01 - val_variance_output_loss: -6.0042e-01 - val_output_mean_absolute_error: 0.2924 - val_output_mean_error: -9.9091e-02\n",
      "Epoch 38/60\n",
      " - 1s - loss: -7.1783e-01 - output_loss: -7.1786e-01 - variance_output_loss: -7.1786e-01 - output_mean_absolute_error: 0.2543 - output_mean_error: -4.7130e-02 - val_loss: -6.4248e-01 - val_output_loss: -6.4252e-01 - val_variance_output_loss: -6.4252e-01 - val_output_mean_absolute_error: 0.2757 - val_output_mean_error: -6.8485e-02\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 39/60\n",
      " - 1s - loss: -7.0825e-01 - output_loss: -7.0828e-01 - variance_output_loss: -7.0828e-01 - output_mean_absolute_error: 0.2577 - output_mean_error: -5.2510e-02 - val_loss: -6.2695e-01 - val_output_loss: -6.2699e-01 - val_variance_output_loss: -6.2699e-01 - val_output_mean_absolute_error: 0.2821 - val_output_mean_error: -5.6494e-02\n",
      "Epoch 40/60\n",
      " - 1s - loss: -7.1154e-01 - output_loss: -7.1158e-01 - variance_output_loss: -7.1158e-01 - output_mean_absolute_error: 0.2561 - output_mean_error: -4.8627e-02 - val_loss: -6.7928e-01 - val_output_loss: -6.7932e-01 - val_variance_output_loss: -6.7932e-01 - val_output_mean_absolute_error: 0.2616 - val_output_mean_error: -4.4266e-02\n",
      "Epoch 41/60\n",
      " - 1s - loss: -7.1739e-01 - output_loss: -7.1743e-01 - variance_output_loss: -7.1743e-01 - output_mean_absolute_error: 0.2543 - output_mean_error: -4.3517e-02 - val_loss: -6.8675e-01 - val_output_loss: -6.8679e-01 - val_variance_output_loss: -6.8679e-01 - val_output_mean_absolute_error: 0.2664 - val_output_mean_error: -6.6413e-02\n",
      "Epoch 42/60\n",
      " - 1s - loss: -7.1428e-01 - output_loss: -7.1431e-01 - variance_output_loss: -7.1431e-01 - output_mean_absolute_error: 0.2562 - output_mean_error: -4.7282e-02 - val_loss: -6.9843e-01 - val_output_loss: -6.9846e-01 - val_variance_output_loss: -6.9846e-01 - val_output_mean_absolute_error: 0.2610 - val_output_mean_error: -5.0114e-02\n",
      "Epoch 43/60\n",
      " - 1s - loss: -7.1004e-01 - output_loss: -7.1007e-01 - variance_output_loss: -7.1007e-01 - output_mean_absolute_error: 0.2571 - output_mean_error: -4.9552e-02 - val_loss: -7.1167e-01 - val_output_loss: -7.1170e-01 - val_variance_output_loss: -7.1170e-01 - val_output_mean_absolute_error: 0.2492 - val_output_mean_error: -3.5249e-02\n",
      "Epoch 44/60\n",
      " - 1s - loss: -7.1416e-01 - output_loss: -7.1420e-01 - variance_output_loss: -7.1420e-01 - output_mean_absolute_error: 0.2555 - output_mean_error: -4.8074e-02 - val_loss: -6.8667e-01 - val_output_loss: -6.8671e-01 - val_variance_output_loss: -6.8671e-01 - val_output_mean_absolute_error: 0.2677 - val_output_mean_error: -8.1437e-02\n",
      "Epoch 45/60\n",
      " - 1s - loss: -7.1271e-01 - output_loss: -7.1275e-01 - variance_output_loss: -7.1275e-01 - output_mean_absolute_error: 0.2561 - output_mean_error: -4.9583e-02 - val_loss: -6.6597e-01 - val_output_loss: -6.6601e-01 - val_variance_output_loss: -6.6601e-01 - val_output_mean_absolute_error: 0.2770 - val_output_mean_error: -5.1167e-02\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 46/60\n",
      " - 1s - loss: -7.2295e-01 - output_loss: -7.2299e-01 - variance_output_loss: -7.2299e-01 - output_mean_absolute_error: 0.2556 - output_mean_error: -4.6373e-02 - val_loss: -7.0761e-01 - val_output_loss: -7.0764e-01 - val_variance_output_loss: -7.0764e-01 - val_output_mean_absolute_error: 0.2528 - val_output_mean_error: -5.6872e-02\n",
      "Epoch 47/60\n",
      " - 1s - loss: -7.2566e-01 - output_loss: -7.2570e-01 - variance_output_loss: -7.2570e-01 - output_mean_absolute_error: 0.2535 - output_mean_error: -4.6778e-02 - val_loss: -6.6340e-01 - val_output_loss: -6.6344e-01 - val_variance_output_loss: -6.6344e-01 - val_output_mean_absolute_error: 0.2759 - val_output_mean_error: -6.0379e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 48/60\n",
      " - 1s - loss: -7.2763e-01 - output_loss: -7.2766e-01 - variance_output_loss: -7.2766e-01 - output_mean_absolute_error: 0.2531 - output_mean_error: -4.6364e-02 - val_loss: -6.7975e-01 - val_output_loss: -6.7979e-01 - val_variance_output_loss: -6.7979e-01 - val_output_mean_absolute_error: 0.2610 - val_output_mean_error: -4.3606e-02\n",
      "Epoch 49/60\n",
      " - 1s - loss: -7.1042e-01 - output_loss: -7.1045e-01 - variance_output_loss: -7.1045e-01 - output_mean_absolute_error: 0.2556 - output_mean_error: -4.7519e-02 - val_loss: -6.8541e-01 - val_output_loss: -6.8545e-01 - val_variance_output_loss: -6.8545e-01 - val_output_mean_absolute_error: 0.2628 - val_output_mean_error: -4.3982e-02\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 50/60\n",
      " - 1s - loss: -7.2705e-01 - output_loss: -7.2708e-01 - variance_output_loss: -7.2708e-01 - output_mean_absolute_error: 0.2516 - output_mean_error: -4.8473e-02 - val_loss: -6.7938e-01 - val_output_loss: -6.7942e-01 - val_variance_output_loss: -6.7942e-01 - val_output_mean_absolute_error: 0.2586 - val_output_mean_error: -4.5497e-02\n",
      "Epoch 51/60\n",
      " - 1s - loss: -7.3315e-01 - output_loss: -7.3319e-01 - variance_output_loss: -7.3319e-01 - output_mean_absolute_error: 0.2516 - output_mean_error: -4.7689e-02 - val_loss: -6.9292e-01 - val_output_loss: -6.9295e-01 - val_variance_output_loss: -6.9295e-01 - val_output_mean_absolute_error: 0.2628 - val_output_mean_error: -7.6161e-02\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 52/60\n",
      " - 1s - loss: -7.1679e-01 - output_loss: -7.1683e-01 - variance_output_loss: -7.1683e-01 - output_mean_absolute_error: 0.2559 - output_mean_error: -4.4887e-02 - val_loss: -6.9563e-01 - val_output_loss: -6.9567e-01 - val_variance_output_loss: -6.9567e-01 - val_output_mean_absolute_error: 0.2604 - val_output_mean_error: -6.6911e-02\n",
      "Epoch 53/60\n",
      " - 1s - loss: -7.2338e-01 - output_loss: -7.2341e-01 - variance_output_loss: -7.2341e-01 - output_mean_absolute_error: 0.2561 - output_mean_error: -5.0355e-02 - val_loss: -6.7056e-01 - val_output_loss: -6.7059e-01 - val_variance_output_loss: -6.7059e-01 - val_output_mean_absolute_error: 0.2701 - val_output_mean_error: -5.1736e-02\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 54/60\n",
      " - 1s - loss: -7.3201e-01 - output_loss: -7.3205e-01 - variance_output_loss: -7.3205e-01 - output_mean_absolute_error: 0.2507 - output_mean_error: -4.1544e-02 - val_loss: -6.6218e-01 - val_output_loss: -6.6222e-01 - val_variance_output_loss: -6.6222e-01 - val_output_mean_absolute_error: 0.2768 - val_output_mean_error: -5.9612e-02\n",
      "Epoch 55/60\n",
      " - 1s - loss: -7.2595e-01 - output_loss: -7.2599e-01 - variance_output_loss: -7.2599e-01 - output_mean_absolute_error: 0.2525 - output_mean_error: -4.4214e-02 - val_loss: -6.1947e-01 - val_output_loss: -6.1950e-01 - val_variance_output_loss: -6.1950e-01 - val_output_mean_absolute_error: 0.2859 - val_output_mean_error: -6.4901e-02\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 56/60\n",
      " - 1s - loss: -7.2270e-01 - output_loss: -7.2273e-01 - variance_output_loss: -7.2273e-01 - output_mean_absolute_error: 0.2545 - output_mean_error: -5.1423e-02 - val_loss: -6.7558e-01 - val_output_loss: -6.7562e-01 - val_variance_output_loss: -6.7562e-01 - val_output_mean_absolute_error: 0.2617 - val_output_mean_error: -4.5484e-02\n",
      "Epoch 57/60\n",
      " - 1s - loss: -7.3636e-01 - output_loss: -7.3640e-01 - variance_output_loss: -7.3640e-01 - output_mean_absolute_error: 0.2489 - output_mean_error: -4.4060e-02 - val_loss: -6.7112e-01 - val_output_loss: -6.7116e-01 - val_variance_output_loss: -6.7116e-01 - val_output_mean_absolute_error: 0.2747 - val_output_mean_error: -7.2268e-02\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 58/60\n",
      " - 1s - loss: -7.0662e-01 - output_loss: -7.0665e-01 - variance_output_loss: -7.0665e-01 - output_mean_absolute_error: 0.2574 - output_mean_error: -4.7206e-02 - val_loss: -6.4640e-01 - val_output_loss: -6.4644e-01 - val_variance_output_loss: -6.4644e-01 - val_output_mean_absolute_error: 0.2769 - val_output_mean_error: -4.2072e-02\n",
      "Epoch 59/60\n",
      " - 1s - loss: -7.1546e-01 - output_loss: -7.1549e-01 - variance_output_loss: -7.1549e-01 - output_mean_absolute_error: 0.2546 - output_mean_error: -4.4289e-02 - val_loss: -6.2130e-01 - val_output_loss: -6.2134e-01 - val_variance_output_loss: -6.2134e-01 - val_output_mean_absolute_error: 0.2733 - val_output_mean_error: -7.0757e-02\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 60/60\n",
      " - 1s - loss: -7.2503e-01 - output_loss: -7.2507e-01 - variance_output_loss: -7.2507e-01 - output_mean_absolute_error: 0.2532 - output_mean_error: -4.7736e-02 - val_loss: -7.0365e-01 - val_output_loss: -7.0368e-01 - val_variance_output_loss: -7.0368e-01 - val_output_mean_absolute_error: 0.2518 - val_output_mean_error: -4.6315e-02\n",
      "Completed Training, 78.48s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_adaptive_6_25/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [128, 48, 24, 12, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_adaptive_6_25'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/16), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 939, Number of Validation Data: 104\n",
      "====Message from Normalizer====\n",
      "You selected mode: 3\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: False\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "====Message from Normalizer====\n",
      "You selected mode: 2\n",
      "Featurewise Center: True\n",
      "Datawise Center: False\n",
      "Featurewise std Center: True\n",
      "Datawise std Center: False\n",
      "====Message ends====\n",
      "Epoch 1/60\n",
      " - 6s - loss: 0.4702 - output_loss: 0.4702 - variance_output_loss: 0.4702 - output_mean_absolute_error: 0.6985 - output_mean_error: 0.0070 - val_loss: 0.5654 - val_output_loss: 0.5654 - val_variance_output_loss: 0.5654 - val_output_mean_absolute_error: 0.7411 - val_output_mean_error: -8.1072e-02\n",
      "Epoch 2/60\n",
      " - 1s - loss: 0.4721 - output_loss: 0.4720 - variance_output_loss: 0.4720 - output_mean_absolute_error: 0.6961 - output_mean_error: -1.5609e-02 - val_loss: 0.5563 - val_output_loss: 0.5563 - val_variance_output_loss: 0.5563 - val_output_mean_absolute_error: 0.7070 - val_output_mean_error: -2.0103e-01\n",
      "Epoch 3/60\n",
      " - 1s - loss: 0.4345 - output_loss: 0.4345 - variance_output_loss: 0.4345 - output_mean_absolute_error: 0.6673 - output_mean_error: -3.4875e-02 - val_loss: 0.5412 - val_output_loss: 0.5412 - val_variance_output_loss: 0.5412 - val_output_mean_absolute_error: 0.7242 - val_output_mean_error: -2.1289e-01\n",
      "Epoch 4/60\n",
      " - 1s - loss: 0.4071 - output_loss: 0.4071 - variance_output_loss: 0.4071 - output_mean_absolute_error: 0.6471 - output_mean_error: -1.3065e-03 - val_loss: 0.4862 - val_output_loss: 0.4862 - val_variance_output_loss: 0.4862 - val_output_mean_absolute_error: 0.6668 - val_output_mean_error: -8.8254e-02\n",
      "Epoch 5/60\n",
      " - 1s - loss: 0.4624 - output_loss: 0.4623 - variance_output_loss: 0.4623 - output_mean_absolute_error: 0.6804 - output_mean_error: -1.8865e-02 - val_loss: 0.5154 - val_output_loss: 0.5154 - val_variance_output_loss: 0.5154 - val_output_mean_absolute_error: 0.6777 - val_output_mean_error: -8.8144e-02\n",
      "Epoch 6/60\n",
      " - 1s - loss: 0.4331 - output_loss: 0.4331 - variance_output_loss: 0.4331 - output_mean_absolute_error: 0.6305 - output_mean_error: 0.0211 - val_loss: 0.4674 - val_output_loss: 0.4673 - val_variance_output_loss: 0.4673 - val_output_mean_absolute_error: 0.6494 - val_output_mean_error: -3.8058e-02\n",
      "Epoch 7/60\n",
      " - 1s - loss: 0.4274 - output_loss: 0.4274 - variance_output_loss: 0.4274 - output_mean_absolute_error: 0.6456 - output_mean_error: 0.0022 - val_loss: 0.4208 - val_output_loss: 0.4208 - val_variance_output_loss: 0.4208 - val_output_mean_absolute_error: 0.6333 - val_output_mean_error: -5.7178e-02\n",
      "Epoch 8/60\n",
      " - 1s - loss: 0.3172 - output_loss: 0.3171 - variance_output_loss: 0.3171 - output_mean_absolute_error: 0.5938 - output_mean_error: 0.0278 - val_loss: 0.3388 - val_output_loss: 0.3388 - val_variance_output_loss: 0.3388 - val_output_mean_absolute_error: 0.6161 - val_output_mean_error: -9.6494e-02\n",
      "Epoch 9/60\n",
      " - 1s - loss: 0.3031 - output_loss: 0.3030 - variance_output_loss: 0.3030 - output_mean_absolute_error: 0.6000 - output_mean_error: 0.0194 - val_loss: 0.2597 - val_output_loss: 0.2597 - val_variance_output_loss: 0.2597 - val_output_mean_absolute_error: 0.5966 - val_output_mean_error: -1.3064e-01\n",
      "Epoch 10/60\n",
      " - 1s - loss: 0.2573 - output_loss: 0.2572 - variance_output_loss: 0.2572 - output_mean_absolute_error: 0.5761 - output_mean_error: -1.3565e-02 - val_loss: 0.2290 - val_output_loss: 0.2290 - val_variance_output_loss: 0.2290 - val_output_mean_absolute_error: 0.5585 - val_output_mean_error: -5.8656e-02\n",
      "Epoch 11/60\n",
      " - 1s - loss: 0.2042 - output_loss: 0.2042 - variance_output_loss: 0.2042 - output_mean_absolute_error: 0.5530 - output_mean_error: -3.6337e-03 - val_loss: 0.1745 - val_output_loss: 0.1744 - val_variance_output_loss: 0.1744 - val_output_mean_absolute_error: 0.5244 - val_output_mean_error: 0.0125\n",
      "Epoch 12/60\n",
      " - 1s - loss: 0.1594 - output_loss: 0.1594 - variance_output_loss: 0.1594 - output_mean_absolute_error: 0.5278 - output_mean_error: -1.9879e-02 - val_loss: 0.1555 - val_output_loss: 0.1555 - val_variance_output_loss: 0.1555 - val_output_mean_absolute_error: 0.5134 - val_output_mean_error: -5.1147e-02\n",
      "Epoch 13/60\n",
      " - 1s - loss: 0.1484 - output_loss: 0.1484 - variance_output_loss: 0.1484 - output_mean_absolute_error: 0.5186 - output_mean_error: -1.2578e-02 - val_loss: 0.0731 - val_output_loss: 0.0730 - val_variance_output_loss: 0.0730 - val_output_mean_absolute_error: 0.4969 - val_output_mean_error: -1.4282e-01\n",
      "Epoch 14/60\n",
      " - 1s - loss: 0.1162 - output_loss: 0.1161 - variance_output_loss: 0.1161 - output_mean_absolute_error: 0.5047 - output_mean_error: -4.3581e-02 - val_loss: 0.1547 - val_output_loss: 0.1547 - val_variance_output_loss: 0.1547 - val_output_mean_absolute_error: 0.5106 - val_output_mean_error: 0.0307\n",
      "Epoch 15/60\n",
      " - 1s - loss: 0.0582 - output_loss: 0.0582 - variance_output_loss: 0.0582 - output_mean_absolute_error: 0.4693 - output_mean_error: 5.2059e-04 - val_loss: 0.0050 - val_output_loss: 0.0050 - val_variance_output_loss: 0.0050 - val_output_mean_absolute_error: 0.4519 - val_output_mean_error: -9.1165e-02\n",
      "Epoch 16/60\n",
      " - 1s - loss: 0.0400 - output_loss: 0.0400 - variance_output_loss: 0.0400 - output_mean_absolute_error: 0.4677 - output_mean_error: -3.1751e-02 - val_loss: -4.3598e-02 - val_output_loss: -4.3622e-02 - val_variance_output_loss: -4.3622e-02 - val_output_mean_absolute_error: 0.3933 - val_output_mean_error: 0.0330\n",
      "Epoch 17/60\n",
      " - 1s - loss: 0.0175 - output_loss: 0.0175 - variance_output_loss: 0.0175 - output_mean_absolute_error: 0.4551 - output_mean_error: -1.7920e-02 - val_loss: -1.7925e-02 - val_output_loss: -1.7949e-02 - val_variance_output_loss: -1.7949e-02 - val_output_mean_absolute_error: 0.4310 - val_output_mean_error: -4.8365e-02\n",
      "Epoch 18/60\n",
      " - 1s - loss: -6.8029e-03 - output_loss: -6.8269e-03 - variance_output_loss: -6.8269e-03 - output_mean_absolute_error: 0.4472 - output_mean_error: -3.7846e-02 - val_loss: -6.7034e-03 - val_output_loss: -6.7274e-03 - val_variance_output_loss: -6.7274e-03 - val_output_mean_absolute_error: 0.4620 - val_output_mean_error: -1.3561e-02\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/60\n",
      " - 1s - loss: -4.9825e-02 - output_loss: -4.9849e-02 - variance_output_loss: -4.9849e-02 - output_mean_absolute_error: 0.4265 - output_mean_error: -3.1459e-02 - val_loss: 0.0258 - val_output_loss: 0.0258 - val_variance_output_loss: 0.0258 - val_output_mean_absolute_error: 0.4698 - val_output_mean_error: -7.2050e-02\n",
      "Epoch 20/60\n",
      " - 1s - loss: -3.9432e-02 - output_loss: -3.9456e-02 - variance_output_loss: -3.9456e-02 - output_mean_absolute_error: 0.4322 - output_mean_error: -2.3497e-02 - val_loss: -3.3634e-02 - val_output_loss: -3.3659e-02 - val_variance_output_loss: -3.3659e-02 - val_output_mean_absolute_error: 0.4485 - val_output_mean_error: -9.7328e-02\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 21/60\n",
      " - 1s - loss: -6.1959e-02 - output_loss: -6.1983e-02 - variance_output_loss: -6.1983e-02 - output_mean_absolute_error: 0.4257 - output_mean_error: -5.3121e-02 - val_loss: 0.0022 - val_output_loss: 0.0022 - val_variance_output_loss: 0.0022 - val_output_mean_absolute_error: 0.4638 - val_output_mean_error: -1.0686e-01\n",
      "Epoch 22/60\n",
      " - 1s - loss: -7.4321e-02 - output_loss: -7.4345e-02 - variance_output_loss: -7.4345e-02 - output_mean_absolute_error: 0.4218 - output_mean_error: -3.6412e-02 - val_loss: -8.9803e-02 - val_output_loss: -8.9827e-02 - val_variance_output_loss: -8.9827e-02 - val_output_mean_absolute_error: 0.3998 - val_output_mean_error: -5.8993e-02\n",
      "Epoch 23/60\n",
      " - 1s - loss: -7.5505e-02 - output_loss: -7.5530e-02 - variance_output_loss: -7.5530e-02 - output_mean_absolute_error: 0.4166 - output_mean_error: -3.6991e-02 - val_loss: -1.6753e-02 - val_output_loss: -1.6777e-02 - val_variance_output_loss: -1.6777e-02 - val_output_mean_absolute_error: 0.4253 - val_output_mean_error: -1.5790e-02\n",
      "Epoch 24/60\n",
      " - 1s - loss: -6.3862e-02 - output_loss: -6.3887e-02 - variance_output_loss: -6.3887e-02 - output_mean_absolute_error: 0.4275 - output_mean_error: -4.5461e-02 - val_loss: -5.1243e-02 - val_output_loss: -5.1267e-02 - val_variance_output_loss: -5.1267e-02 - val_output_mean_absolute_error: 0.4326 - val_output_mean_error: -7.9013e-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 25/60\n",
      " - 1s - loss: -7.7261e-02 - output_loss: -7.7285e-02 - variance_output_loss: -7.7285e-02 - output_mean_absolute_error: 0.4195 - output_mean_error: -4.3163e-02 - val_loss: 0.0060 - val_output_loss: 0.0060 - val_variance_output_loss: 0.0060 - val_output_mean_absolute_error: 0.4795 - val_output_mean_error: -1.1291e-01\n",
      "Epoch 26/60\n",
      " - 1s - loss: -8.1956e-02 - output_loss: -8.1980e-02 - variance_output_loss: -8.1980e-02 - output_mean_absolute_error: 0.4151 - output_mean_error: -4.0504e-02 - val_loss: -6.1774e-02 - val_output_loss: -6.1798e-02 - val_variance_output_loss: -6.1798e-02 - val_output_mean_absolute_error: 0.4255 - val_output_mean_error: -1.3252e-01\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 27/60\n",
      " - 1s - loss: -7.4838e-02 - output_loss: -7.4862e-02 - variance_output_loss: -7.4862e-02 - output_mean_absolute_error: 0.4176 - output_mean_error: -3.6058e-02 - val_loss: -1.4880e-02 - val_output_loss: -1.4905e-02 - val_variance_output_loss: -1.4905e-02 - val_output_mean_absolute_error: 0.4254 - val_output_mean_error: -4.4931e-02\n",
      "Epoch 28/60\n",
      " - 1s - loss: -8.4649e-02 - output_loss: -8.4674e-02 - variance_output_loss: -8.4674e-02 - output_mean_absolute_error: 0.4180 - output_mean_error: -4.5166e-02 - val_loss: -7.3901e-02 - val_output_loss: -7.3925e-02 - val_variance_output_loss: -7.3925e-02 - val_output_mean_absolute_error: 0.4049 - val_output_mean_error: -5.5512e-02\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 29/60\n",
      " - 1s - loss: -9.9692e-02 - output_loss: -9.9716e-02 - variance_output_loss: -9.9716e-02 - output_mean_absolute_error: 0.4094 - output_mean_error: -3.8057e-02 - val_loss: -6.4064e-02 - val_output_loss: -6.4088e-02 - val_variance_output_loss: -6.4088e-02 - val_output_mean_absolute_error: 0.4349 - val_output_mean_error: -5.6630e-02\n",
      "Epoch 30/60\n",
      " - 1s - loss: -8.3757e-02 - output_loss: -8.3781e-02 - variance_output_loss: -8.3781e-02 - output_mean_absolute_error: 0.4135 - output_mean_error: -3.2001e-02 - val_loss: -6.5574e-02 - val_output_loss: -6.5598e-02 - val_variance_output_loss: -6.5598e-02 - val_output_mean_absolute_error: 0.4173 - val_output_mean_error: -2.7537e-02\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 31/60\n",
      " - 1s - loss: -8.6502e-02 - output_loss: -8.6526e-02 - variance_output_loss: -8.6526e-02 - output_mean_absolute_error: 0.4224 - output_mean_error: -5.7681e-02 - val_loss: -9.8927e-02 - val_output_loss: -9.8951e-02 - val_variance_output_loss: -9.8951e-02 - val_output_mean_absolute_error: 0.3952 - val_output_mean_error: -1.1321e-02\n",
      "Epoch 32/60\n",
      " - 1s - loss: -7.9353e-02 - output_loss: -7.9378e-02 - variance_output_loss: -7.9378e-02 - output_mean_absolute_error: 0.4119 - output_mean_error: -2.8961e-02 - val_loss: -2.2965e-02 - val_output_loss: -2.2989e-02 - val_variance_output_loss: -2.2989e-02 - val_output_mean_absolute_error: 0.4592 - val_output_mean_error: -6.7754e-02\n",
      "Epoch 33/60\n",
      " - 1s - loss: -8.6423e-02 - output_loss: -8.6447e-02 - variance_output_loss: -8.6447e-02 - output_mean_absolute_error: 0.4153 - output_mean_error: -3.7533e-02 - val_loss: -3.2443e-02 - val_output_loss: -3.2467e-02 - val_variance_output_loss: -3.2467e-02 - val_output_mean_absolute_error: 0.4484 - val_output_mean_error: -5.8024e-02\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 34/60\n",
      " - 1s - loss: -7.8449e-02 - output_loss: -7.8474e-02 - variance_output_loss: -7.8474e-02 - output_mean_absolute_error: 0.4177 - output_mean_error: -5.5511e-02 - val_loss: -5.8511e-03 - val_output_loss: -5.8754e-03 - val_variance_output_loss: -5.8754e-03 - val_output_mean_absolute_error: 0.4497 - val_output_mean_error: -1.0247e-01\n",
      "Epoch 35/60\n",
      " - 1s - loss: -9.7502e-02 - output_loss: -9.7526e-02 - variance_output_loss: -9.7526e-02 - output_mean_absolute_error: 0.4082 - output_mean_error: -3.9810e-02 - val_loss: -4.5232e-02 - val_output_loss: -4.5256e-02 - val_variance_output_loss: -4.5256e-02 - val_output_mean_absolute_error: 0.4346 - val_output_mean_error: -5.8944e-02\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 36/60\n",
      " - 1s - loss: -7.5525e-02 - output_loss: -7.5549e-02 - variance_output_loss: -7.5549e-02 - output_mean_absolute_error: 0.4184 - output_mean_error: -3.5361e-02 - val_loss: -2.5875e-02 - val_output_loss: -2.5900e-02 - val_variance_output_loss: -2.5900e-02 - val_output_mean_absolute_error: 0.4502 - val_output_mean_error: -6.2656e-02\n",
      "Epoch 37/60\n",
      " - 1s - loss: -8.3190e-02 - output_loss: -8.3214e-02 - variance_output_loss: -8.3214e-02 - output_mean_absolute_error: 0.4085 - output_mean_error: -3.2393e-02 - val_loss: -6.7465e-02 - val_output_loss: -6.7489e-02 - val_variance_output_loss: -6.7489e-02 - val_output_mean_absolute_error: 0.4292 - val_output_mean_error: -8.8962e-02\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 38/60\n",
      " - 1s - loss: -9.5933e-02 - output_loss: -9.5957e-02 - variance_output_loss: -9.5957e-02 - output_mean_absolute_error: 0.4106 - output_mean_error: -4.2700e-02 - val_loss: -7.7870e-02 - val_output_loss: -7.7894e-02 - val_variance_output_loss: -7.7894e-02 - val_output_mean_absolute_error: 0.4093 - val_output_mean_error: -5.0053e-02\n",
      "Epoch 39/60\n",
      " - 1s - loss: -8.6384e-02 - output_loss: -8.6408e-02 - variance_output_loss: -8.6408e-02 - output_mean_absolute_error: 0.4175 - output_mean_error: -4.7692e-02 - val_loss: -7.2822e-02 - val_output_loss: -7.2846e-02 - val_variance_output_loss: -7.2846e-02 - val_output_mean_absolute_error: 0.4056 - val_output_mean_error: -2.4213e-02\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 40/60\n",
      " - 1s - loss: -9.2657e-02 - output_loss: -9.2681e-02 - variance_output_loss: -9.2681e-02 - output_mean_absolute_error: 0.4104 - output_mean_error: -4.2252e-02 - val_loss: -8.5407e-02 - val_output_loss: -8.5432e-02 - val_variance_output_loss: -8.5432e-02 - val_output_mean_absolute_error: 0.4087 - val_output_mean_error: -9.7826e-02\n",
      "Epoch 41/60\n",
      " - 1s - loss: -8.3768e-02 - output_loss: -8.3792e-02 - variance_output_loss: -8.3792e-02 - output_mean_absolute_error: 0.4163 - output_mean_error: -4.4968e-02 - val_loss: -3.8966e-02 - val_output_loss: -3.8990e-02 - val_variance_output_loss: -3.8990e-02 - val_output_mean_absolute_error: 0.4436 - val_output_mean_error: -8.9658e-02\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 42/60\n",
      " - 1s - loss: -9.2187e-02 - output_loss: -9.2211e-02 - variance_output_loss: -9.2211e-02 - output_mean_absolute_error: 0.4106 - output_mean_error: -3.6953e-02 - val_loss: -8.6588e-02 - val_output_loss: -8.6612e-02 - val_variance_output_loss: -8.6612e-02 - val_output_mean_absolute_error: 0.3994 - val_output_mean_error: -1.7296e-02\n",
      "Epoch 43/60\n",
      " - 1s - loss: -9.7498e-02 - output_loss: -9.7523e-02 - variance_output_loss: -9.7523e-02 - output_mean_absolute_error: 0.4049 - output_mean_error: -3.5690e-02 - val_loss: -7.4883e-02 - val_output_loss: -7.4908e-02 - val_variance_output_loss: -7.4908e-02 - val_output_mean_absolute_error: 0.4132 - val_output_mean_error: -3.0051e-02\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 44/60\n",
      " - 1s - loss: -7.7588e-02 - output_loss: -7.7613e-02 - variance_output_loss: -7.7613e-02 - output_mean_absolute_error: 0.4154 - output_mean_error: -3.8728e-02 - val_loss: -5.3953e-02 - val_output_loss: -5.3977e-02 - val_variance_output_loss: -5.3977e-02 - val_output_mean_absolute_error: 0.4348 - val_output_mean_error: -7.3824e-02\n",
      "Epoch 45/60\n",
      " - 1s - loss: -8.1684e-02 - output_loss: -8.1709e-02 - variance_output_loss: -8.1709e-02 - output_mean_absolute_error: 0.4129 - output_mean_error: -4.1726e-02 - val_loss: -6.8290e-02 - val_output_loss: -6.8314e-02 - val_variance_output_loss: -6.8314e-02 - val_output_mean_absolute_error: 0.4167 - val_output_mean_error: -2.0585e-02\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 46/60\n",
      " - 1s - loss: -7.6823e-02 - output_loss: -7.6848e-02 - variance_output_loss: -7.6848e-02 - output_mean_absolute_error: 0.4233 - output_mean_error: -5.0703e-02 - val_loss: -1.9097e-02 - val_output_loss: -1.9121e-02 - val_variance_output_loss: -1.9121e-02 - val_output_mean_absolute_error: 0.4568 - val_output_mean_error: -1.2133e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      " - 1s - loss: -9.8598e-02 - output_loss: -9.8622e-02 - variance_output_loss: -9.8622e-02 - output_mean_absolute_error: 0.4085 - output_mean_error: -3.8240e-02 - val_loss: -5.5680e-02 - val_output_loss: -5.5705e-02 - val_variance_output_loss: -5.5705e-02 - val_output_mean_absolute_error: 0.4393 - val_output_mean_error: -9.2254e-02\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 48/60\n",
      " - 1s - loss: -8.3559e-02 - output_loss: -8.3583e-02 - variance_output_loss: -8.3583e-02 - output_mean_absolute_error: 0.4116 - output_mean_error: -5.4606e-02 - val_loss: -3.1459e-02 - val_output_loss: -3.1484e-02 - val_variance_output_loss: -3.1484e-02 - val_output_mean_absolute_error: 0.4577 - val_output_mean_error: -9.9469e-02\n",
      "Epoch 49/60\n",
      " - 1s - loss: -9.4751e-02 - output_loss: -9.4775e-02 - variance_output_loss: -9.4775e-02 - output_mean_absolute_error: 0.4115 - output_mean_error: -3.3957e-02 - val_loss: -6.2870e-02 - val_output_loss: -6.2894e-02 - val_variance_output_loss: -6.2894e-02 - val_output_mean_absolute_error: 0.4058 - val_output_mean_error: -2.9947e-02\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 50/60\n",
      " - 1s - loss: -8.2971e-02 - output_loss: -8.2995e-02 - variance_output_loss: -8.2995e-02 - output_mean_absolute_error: 0.4157 - output_mean_error: -4.4403e-02 - val_loss: -6.0044e-02 - val_output_loss: -6.0068e-02 - val_variance_output_loss: -6.0068e-02 - val_output_mean_absolute_error: 0.4304 - val_output_mean_error: -9.8082e-02\n",
      "Epoch 51/60\n",
      " - 1s - loss: -9.1160e-02 - output_loss: -9.1184e-02 - variance_output_loss: -9.1184e-02 - output_mean_absolute_error: 0.4129 - output_mean_error: -4.7797e-02 - val_loss: -9.2266e-02 - val_output_loss: -9.2290e-02 - val_variance_output_loss: -9.2290e-02 - val_output_mean_absolute_error: 0.4129 - val_output_mean_error: -4.6071e-02\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
      "Epoch 52/60\n",
      " - 1s - loss: -8.8130e-02 - output_loss: -8.8154e-02 - variance_output_loss: -8.8154e-02 - output_mean_absolute_error: 0.4119 - output_mean_error: -4.2459e-02 - val_loss: 8.4395e-04 - val_output_loss: 8.1966e-04 - val_variance_output_loss: 8.1966e-04 - val_output_mean_absolute_error: 0.4578 - val_output_mean_error: -7.2216e-02\n",
      "Epoch 53/60\n",
      " - 1s - loss: -9.5176e-02 - output_loss: -9.5200e-02 - variance_output_loss: -9.5200e-02 - output_mean_absolute_error: 0.4095 - output_mean_error: -3.8670e-02 - val_loss: -2.1017e-02 - val_output_loss: -2.1042e-02 - val_variance_output_loss: -2.1042e-02 - val_output_mean_absolute_error: 0.4557 - val_output_mean_error: -9.6711e-02\n",
      "Epoch 54/60\n",
      " - 1s - loss: -8.7573e-02 - output_loss: -8.7597e-02 - variance_output_loss: -8.7597e-02 - output_mean_absolute_error: 0.4180 - output_mean_error: -4.8905e-02 - val_loss: -8.2392e-02 - val_output_loss: -8.2416e-02 - val_variance_output_loss: -8.2416e-02 - val_output_mean_absolute_error: 0.3987 - val_output_mean_error: -1.0152e-02\n",
      "Epoch 55/60\n",
      " - 1s - loss: -8.3442e-02 - output_loss: -8.3466e-02 - variance_output_loss: -8.3466e-02 - output_mean_absolute_error: 0.4109 - output_mean_error: -4.0770e-02 - val_loss: -8.6938e-02 - val_output_loss: -8.6963e-02 - val_variance_output_loss: -8.6963e-02 - val_output_mean_absolute_error: 0.4056 - val_output_mean_error: -6.0933e-02\n",
      "Epoch 56/60\n",
      " - 1s - loss: -9.8761e-02 - output_loss: -9.8785e-02 - variance_output_loss: -9.8785e-02 - output_mean_absolute_error: 0.4068 - output_mean_error: -4.4788e-02 - val_loss: -3.7743e-02 - val_output_loss: -3.7767e-02 - val_variance_output_loss: -3.7767e-02 - val_output_mean_absolute_error: 0.4463 - val_output_mean_error: -9.9572e-02\n",
      "Epoch 57/60\n",
      " - 1s - loss: -8.5701e-02 - output_loss: -8.5726e-02 - variance_output_loss: -8.5726e-02 - output_mean_absolute_error: 0.4136 - output_mean_error: -2.9196e-02 - val_loss: -4.5837e-02 - val_output_loss: -4.5862e-02 - val_variance_output_loss: -4.5862e-02 - val_output_mean_absolute_error: 0.4525 - val_output_mean_error: -8.5722e-02\n",
      "Epoch 58/60\n",
      " - 1s - loss: -9.2291e-02 - output_loss: -9.2316e-02 - variance_output_loss: -9.2316e-02 - output_mean_absolute_error: 0.4151 - output_mean_error: -5.0729e-02 - val_loss: -1.1346e-01 - val_output_loss: -1.1348e-01 - val_variance_output_loss: -1.1348e-01 - val_output_mean_absolute_error: 0.4076 - val_output_mean_error: -2.6760e-02\n",
      "Epoch 59/60\n",
      " - 1s - loss: -8.9954e-02 - output_loss: -8.9978e-02 - variance_output_loss: -8.9978e-02 - output_mean_absolute_error: 0.4159 - output_mean_error: -4.5068e-02 - val_loss: -1.0015e-01 - val_output_loss: -1.0017e-01 - val_variance_output_loss: -1.0017e-01 - val_output_mean_absolute_error: 0.3934 - val_output_mean_error: -2.9055e-02\n",
      "Epoch 60/60\n",
      " - 1s - loss: -7.5229e-02 - output_loss: -7.5253e-02 - variance_output_loss: -7.5253e-02 - output_mean_absolute_error: 0.4170 - output_mean_error: -3.5900e-02 - val_loss: -6.2621e-02 - val_output_loss: -6.2645e-02 - val_variance_output_loss: -6.2645e-02 - val_output_mean_absolute_error: 0.4273 - val_output_mean_error: -5.8237e-02\n",
      "Completed Training, 42.83s in total\n",
      "model_weights.h5 saved to D:\\University\\AST425\\astroNN_spectra_paper_figures\\small_data_adaptive_3_125/model_weights.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from astroNN.datasets import H5Loader\n",
    "from astroNN.apogee import aspcap_mask\n",
    "from astroNN.models import ApogeeBCNNCensored\n",
    "\n",
    "loader = H5Loader('__train')  # continuum normalized dataset\n",
    "loader.load_err = True\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y, x_err, y_err = loader.load()\n",
    "\n",
    "bcnn = ApogeeBCNNCensored()\n",
    "bcnn.num_hidden = [96, 32, 16, 6, 2]  # default model size used in the paper\n",
    "bcnn.max_epochs = 60  # default max epochs used in the paper\n",
    "bcnn.autosave = True\n",
    "bcnn.folder_name = 'small_data_adaptive_3_125'\n",
    "\n",
    "rand_train_idx = np.random.choice(np.arange(x.shape[0]), int(x.shape[0]/32), replace=False)\n",
    "bcnn.train(x[rand_train_idx], y[rand_train_idx], labels_err=y_err[rand_train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 109.95s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 106.87s elapsed\n",
      "========================================================\n",
      "Loaded astroNN model, model type: Bayesian Convolutional Neural Network -> ApogeeBCNNCensored\n",
      "========================================================\n",
      "Starting Dropout Variational Inference\n",
      "Completed Dropout Variational Inference with 100 forward passes, 105.89s elapsed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Data</th>\n",
       "      <th>Scatter</th>\n",
       "      <th>Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3758</td>\n",
       "      <td>0.221780</td>\n",
       "      <td>-0.022680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1879</td>\n",
       "      <td>0.263140</td>\n",
       "      <td>-0.001169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>939</td>\n",
       "      <td>0.426591</td>\n",
       "      <td>-0.000090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Data   Scatter      Bias\n",
       "0            3758  0.221780 -0.022680\n",
       "1            1879  0.263140 -0.001169\n",
       "2             939  0.426591 -0.000090"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy.stats import mad_std\n",
    "\n",
    "from astroNN.models import load_folder\n",
    "from astroNN.datasets import H5Loader\n",
    "\n",
    "loader = H5Loader('_highsnr_test')  # continuum normalized dataset\n",
    "loader.load_err = False\n",
    "loader.target = ['teff', 'logg', 'C', 'C1', 'N', 'O', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'K',\n",
    "                 'Ca', 'Ti', 'Ti2', 'V', 'Cr', 'Mn', 'Fe','Co', 'Ni']\n",
    "x, y = loader.load()\n",
    "\n",
    "mae = []\n",
    "me = []\n",
    "\n",
    "net_12_5 = load_folder(\"small_data_adaptive_12_5\")\n",
    "net_12_5_pred, err = net_12_5.test(x)\n",
    "residue = ((net_12_5_pred - y) / net_12_5.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_6_25 = load_folder(\"small_data_adaptive_6_25\")\n",
    "net_6_25_pred, err = net_6_25.test(x)\n",
    "residue = ((net_6_25_pred - y) / net_6_25.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "net_3_125 = load_folder(\"small_data_adaptive_3_125\")\n",
    "net_3_125_pred, err = net_3_125.test(x)\n",
    "residue = ((net_3_125_pred - y) / net_3_125.labels_std)\n",
    "mae.append(mad_std(residue))\n",
    "me.append(np.median(residue))\n",
    "\n",
    "\n",
    "d = {'Number of Data': [3758, 1879, 939], 'Scatter': mae, 'Bias': me}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x750 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from matplotlib.ticker import NullFormatter,MultipleLocator, FormatStrFormatter\n",
    "\n",
    "plt.rc('font',**{'family': 'serif', 'weight':'medium', 'size':20})\n",
    "\n",
    "f, ax = plt.subplots(2, figsize=(15,7.5), dpi=100)\n",
    "ax[0].plot([0.0172124, 0.186913, 0.193223, 0.205817, 0.245651, 0.309125], linewidth=3., label='Fixed Model Size')\n",
    "ax[0].plot([3, 4, 5], [0.221780, 0.263140, 0.426591], linewidth=3., label='Adaptive Model Size')\n",
    "# ax.plot(m13_nn_scatter, ls='steps-mid', linewidth=3., label='NN with Mean Confidence Intereval')\n",
    "# ax.errorbar(np.arange(20), m13_nn_scatter, yerr=m13_nn_m_uncer, linestyle='None', capsize=5, elinewidth=2., capthick=2.)\n",
    "ax[0].legend(loc='upper left', fontsize=23, ncol=2)\n",
    "# ax[0].set_xlabel('Number of Training Spectra', fontsize=25)\n",
    "ax[0].set_ylabel('Scattering', fontsize=25)\n",
    "ax[0].set_xticks(np.arange(len(['30067', '15033', '7516', '3758', '1879', '939'])))\n",
    "ax[0].set_xticklabels(['30067', '15033', '7516', '3758', '1879', '939'])\n",
    "ax[0].tick_params(labelsize=20, width=2.5, length=15, which='major')\n",
    "ax[0].xaxis.set_major_formatter(NullFormatter())\n",
    "\n",
    "ax[1].plot([0.017152, 0.017570, 0.018622, 0.023268, 0.001448, 0.007424], linewidth=3., label='Fixed Model Size')\n",
    "ax[1].plot([3, 4, 5], [0.022680, 0.001169, 0.000090], linewidth=3., label='Adaptive Model Size')\n",
    "# ax.plot(m13_nn_scatter, ls='steps-mid', linewidth=3., label='NN with Mean Confidence Intereval')\n",
    "# ax.errorbar(np.arange(20), m13_nn_scatter, yerr=m13_nn_m_uncer, linestyle='None', capsize=5, elinewidth=2., capthick=2.)\n",
    "# ax[1].legend(loc='lower left', fontsize=23, ncol=2)\n",
    "ax[1].set_xlabel('Number of Training Spectra', fontsize=25)\n",
    "ax[1].set_ylabel('Bias', fontsize=25)\n",
    "ax[1].set_xticks(np.arange(len(['30067', '15033', '7516', '3758', '1879', '939'])))\n",
    "ax[1].set_xticklabels(['30067', '15033', '7516', '3758', '1879', '939'])\n",
    "ax[1].tick_params(labelsize=20, width=2.5, length=15, which='major')\n",
    "f.subplots_adjust(wspace=0,hspace=0)\n",
    "f.savefig('small_data_test_result.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
